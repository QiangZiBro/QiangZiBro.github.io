<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>QiangZiBro的随笔</title>
  
  <subtitle>CS postgraduate/Guitarist</subtitle>
  <link href="https://qiangzibro.com/atom.xml" rel="self"/>
  
  <link href="https://qiangzibro.com/"/>
  <updated>2021-12-10T13:13:58.253Z</updated>
  <id>https://qiangzibro.com/</id>
  
  <author>
    <name>QiangZiBro</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>嵌入式视觉AI实践——从训练到部署</title>
    <link href="https://qiangzibro.com/2021/12/01/cvaio/"/>
    <id>https://qiangzibro.com/2021/12/01/cvaio/</id>
    <published>2021-12-01T04:47:56.000Z</published>
    <updated>2021-12-10T13:13:58.253Z</updated>
    
    <content type="html"><![CDATA[<p><font color="green">作者申明：该文章仅在微信平台授权给公众号Datawhale（ID：Datawhale）首发原创，其他平台暂无授权。</font></p><p>如何将深度学习算法部署到嵌入式设备？本文将带给你一个从Pytorch平台训练，到部署到嵌入式设备K210的完整方案。章节之间跨度大，知识点相对独立，欢迎点赞收藏慢慢看！跟着本文做完，你也可以做一个自己的嵌入式AI小产品！</p><span id="more"></span><blockquote><p>作者介绍：张强，DataWhale成员，宁波大学研究生，研究方向计算机视觉与深度学习</p></blockquote><h2 id="零、前言"><a href="#零、前言" class="headerlink" title="零、前言"></a>零、前言</h2><p>随着硬件尤其是显卡性能升级，以及Pytorch，TensorFlow深度学习框架日趋完善，视觉AI算法在多个领域遍地开花。嵌入式设备是一种微型处理器，它的关键单元就是内部小小的计算芯片。嵌入式设备和我们日常用的电脑相比体积小，只包含必要外设。一些针对特定任务的嵌入式设备往往不会运载我们常用的比如Windows、Linux系统，而是直接将代码烧录进去运行。</p><p>在嵌入式设备上部署深度学习算法的尝试，从遥远的1989年，一家叫做ALVIVN的公司将神经网络用在汽车上就开始了。现如今，工程师们将其用在安防、机器人、自动驾驶等领域。因此，懂的如何设计、训练深度学习算法，又能将其部署到边缘硬件产品上，能帮助我们实现许多产品的想法。</p><p>但是，视觉算法部署在产品中仍有许多难点，比如（1）模型通常需要在CPU/GPU/NPU/FPGA等各种各样不同类型的平台上部署（2）嵌入式算力/内存/存储空间都非常有限；跑在云端服务器上，需要实时联网又不很优雅（3）模型训练时可能会使用不同的AI框架（比如Pytorch/TensorFlow等）、不同硬件（比如GPU、NPU），相互适配产生问题[1]。</p><p>因此笔者开始思考下列问题：</p><ul><li>有什么亲民价格的芯片能处理部署视觉AI算法？</li><li>如何将深度学习算法部署到嵌入式设备上？</li></ul><p>对第一个问题，在经过调研后，还真有这样的芯片，那就是嘉楠科技的K210芯片。一个芯片几十元，对应的开发板在某宝上两百多就可以买到。根据嘉楠官方的描述，K210具有双核 64-bit RISC-V RV64IMAFDC (RV64GC) CPU / 400MHz（可超频到600MHz），双精度 FPU，8MiB 64bit 片上 SRAM（6MiB通用SRAM+2MiB的AI专用SRAM）。关于这块芯片更详细的介绍可以参考[2] 。</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/v2-eba8e31edcb60852a9a625ec3031ef23_1440w.jpg" alt="img" style="zoom: 50%;" /><p>市面上有许多搭载K210的开发板，笔者这里选了雅博一款功能较全的K210开发板，开始了嵌入式AI的折腾之路</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/board1.jpg" style="zoom:50%;" /><p>对于第二个问题，方法就多了，不同深度学习框架，不同硬件选型都决定着不同技术路线。基本路线可以为<strong>深度学习平台训练 –&gt; 模型剪枝、量化 –&gt; 参数转换 –&gt;转换为硬件平台上能运行的模型</strong> 。对深度学习平台选型，笔者决定选用当下最流行的Pytorch平台。最后一步往往取决于这个硬件的生态，如果没有相关生态支持，可能需要手写C语言代码加载参数运行。调研发现，K210有一个深度网络优化平台<strong>NNCASE</strong>，能加速深度模型部署。</p><p>调研过程中发现在这块板子上部署模型大多数都是从Keras、TensorFlow开始训练并最终部署，而研究者常用的Pytorch竟然没有教程，于是将尝试做这个事。</p><p>接下来，我们从使用Pytorch训练手写体识别的例子开始，打通从训练到嵌入式平台部署的流程。</p><h2 id="一、使用Pytorch训练分类网络模型"><a href="#一、使用Pytorch训练分类网络模型" class="headerlink" title="一、使用Pytorch训练分类网络模型"></a>一、使用Pytorch训练分类网络模型</h2><p>必要软件包安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorbay pillow torch torchvision numpy</span><br></pre></td></tr></table></figure><h3 id="数据集获取"><a href="#数据集获取" class="headerlink" title="数据集获取"></a>数据集获取</h3><blockquote><p>一个AccessKey获取所有数据集</p></blockquote><p>我们使用一个开源数据集平台：<a href="https://gas.graviti.cn/%EF%BC%8C%E8%BF%99%E4%B8%AA%E7%BD%91%E7%AB%99%E6%B1%87%E6%80%BB%E4%BA%86AI%E5%BC%80%E5%8F%91%E8%80%85%E5%B8%B8%E8%A7%81%E7%9A%84%E5%85%AC%E5%BC%80%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%8C%E8%B0%83%E7%94%A8%E5%85%B6SDK%E5%B0%B1%E8%83%BD%E7%9B%B4%E6%8E%A5%E5%9C%A8%E7%BA%BF%E8%AE%AD%E7%BB%83%EF%BC%8C%E6%9B%B4%E6%96%B9%E4%BE%BF%E7%9A%84%E6%98%AF%EF%BC%8C%E8%AE%B8%E5%A4%9A%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9B%B4%E6%8E%A5%E5%9C%A8%E5%9B%BD%E5%86%85%E7%BD%91%E7%BB%9C%E4%B8%8B%E8%BF%9E%E6%8E%A5%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%EF%BC%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E5%88%B0%E5%9B%BD%E5%A4%96%E7%BD%91%E7%AB%99%E8%BF%9B%E8%A1%8C%E4%B8%8B%E8%BD%BD%EF%BC%8C%E8%BF%98%E6%98%AF%E9%9D%9E%E5%B8%B8%E6%96%B9%E4%BE%BF%E7%9A%84%EF%BC%81">https://gas.graviti.cn/，这个网站汇总了AI开发者常见的公开数据集，调用其SDK就能直接在线训练，更方便的是，许多数据集直接在国内网络下连接直接使用，不需要到国外网站进行下载，还是非常方便的！</a></p><p>a. 打开本文对应数据集链接 <a href="https://gas.graviti.cn/dataset/qiangzibro/MNIST">https://gas.graviti.cn/dataset/qiangzibro/MNIST</a></p><p>b. 右上角注册登录</p><p>c. fork数据集</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/fork.png" alt="image-20210915170201901" style="zoom:67%;" /><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/fork2.png" alt="image-20210915170228705" style="zoom:67%;" /><p>d. 点击网页上方开发者工具，获取使用SDK所需的AccessKey，获取到 AccessKey 后，将其存在项目根目录的<code>gas_key.py</code>里：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KEY = <span class="string">&quot;&lt;Your-Key&gt;&quot;</span></span><br></pre></td></tr></table></figure><p>然后即可以通过AccessKey可以上传数据、读取数据、使用数据，灵活对接模型开发和训练，与数据pipeline快速集成。</p><p>e. AccessKey写入后就可以写代码读取数据了，读完了一行下载代码就可以进行下载。将下载后的数据放在<code>data</code>文件夹下</p><p>获取到AccessKey后，我们便能自由地操作数据了：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorbay <span class="keyword">import</span> GAS</span><br><span class="line"><span class="keyword">from</span> tensorbay.dataset <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">from</span> tensorbay.dataset <span class="keyword">import</span> Segment</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_gas_image</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="keyword">with</span> data.<span class="built_in">open</span>() <span class="keyword">as</span> fp:</span><br><span class="line">        image = Image.<span class="built_in">open</span>(fp)</span><br><span class="line">    <span class="keyword">return</span> np.array(image)</span><br><span class="line">  </span><br><span class="line">KEY = <span class="string">&quot;用你的Key替换掉这个字符串&quot;</span></span><br><span class="line"><span class="comment"># Authorize a GAS client.</span></span><br><span class="line">gas = GAS(KEY)</span><br><span class="line"><span class="comment"># Get a dataset.</span></span><br><span class="line">dataset = Dataset(<span class="string">&quot;MNIST&quot;</span>, gas)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启下行语句在当前路径下的data目录缓存数据</span></span><br><span class="line"><span class="comment"># dataset.enable_cache(&quot;data&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List dataset segments.</span></span><br><span class="line">segments = dataset.keys()</span><br><span class="line"><span class="comment"># Get a segment by name</span></span><br><span class="line">segment = dataset[<span class="string">&quot;train&quot;</span>]</span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> segment:</span><br><span class="line">    <span class="comment"># 图片数据</span></span><br><span class="line">    image = read_gas_image(data)</span><br><span class="line">    <span class="comment"># 标签数据</span></span><br><span class="line">    label = data.label.classification.category</span><br></pre></td></tr></table></figure><p>怎么把这个数据集集成到Pytorch里呢？官方文档也为了写了不少例子[4]。笔者尝试过觉得挺方便，在为不同任务训练嵌入式AI模型时，更换数据集的名字，就能下载，不需要再打开浏览器、等待下载以及处理很久了。有了数据集之后，我们接下来用其训练一个分类任务模型。</p><h3 id="深度网络模型选型"><a href="#深度网络模型选型" class="headerlink" title="深度网络模型选型"></a>深度网络模型选型</h3><blockquote><p>结合硬件特点设计网络</p></blockquote><p>在考虑硬件部署的任务时，网络的设计就要受到些许限制。</p><p>首先，大而深的模型是不行的，K210的RAM是6M，这意味着模型+程序都要烧到这个空间。当然我们可以放到内存卡中，但实时性要受影响。</p><p>其次，还要考虑AI编译器对特定算子的优化，以K210 NNCASE为例[3]，其支持三个平台的算子：</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20211203135620075.png" alt="image-20211203135620075" style="zoom:50%;" /><p>打开对应平台，能够到具体有哪些算子已经实现了低层优化。可以看到对ONNX算子优化还是比较多的。如果所选用的网络算子较新，抑或是模型太大，都要在本步多加思考与设计。</p><p>如果如果最后部署不成功，往往需要回到这一步考虑网络的设计。为了尽可能减少算子的使用，本文设计一个只基于卷积+ReLU+Pool的CNN：</p><p><strong>代码文件名：</strong><code>models/net.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.relu1 = nn.ReLU()</span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.relu2 = nn.ReLU()</span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, <span class="number">4</span>)</span><br><span class="line">        self.relu3 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv4 = nn.Conv2d(<span class="number">32</span>, <span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">        self.relu4 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv5 = nn.Conv2d(<span class="number">64</span>, <span class="number">32</span>, <span class="number">1</span>)</span><br><span class="line">        self.relu5 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">        self.conv6 = nn.Conv2d(<span class="number">32</span>, <span class="number">10</span>, <span class="number">1</span>)</span><br><span class="line">        self.relu6 = nn.ReLU()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        y = self.conv1(x)</span><br><span class="line">        y = self.relu1(y)</span><br><span class="line">        y = self.pool1(y)</span><br><span class="line">        y = self.conv2(y)</span><br><span class="line">        y = self.relu2(y)</span><br><span class="line">        y = self.pool2(y)</span><br><span class="line">        y = self.conv3(y)</span><br><span class="line">        y = self.relu3(y)</span><br><span class="line">        y = self.conv4(y)</span><br><span class="line">        y = self.relu4(y)</span><br><span class="line">        y = self.conv5(y)</span><br><span class="line">        y = self.relu6(y)</span><br><span class="line">        y = self.conv6(y)</span><br><span class="line">        y = self.relu6(y)</span><br><span class="line"></span><br><span class="line">        y = y.view(y.shape[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="网络训练"><a href="#网络训练" class="headerlink" title="网络训练"></a>网络训练</h3><p>设计好模型后，使用如下脚本进行训练。接下来脚本文件大致浏览一下，明白其中的工作原理即可。</p><p><strong>代码文件名：</strong><code>1.train.py</code></p><p>注意将其中的<code>ACCESS_KEY</code>替成你自己的AccessKey。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> StepLR</span><br><span class="line"><span class="keyword">from</span> models.net <span class="keyword">import</span> Net</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorbay <span class="keyword">import</span> GAS</span><br><span class="line"><span class="keyword">from</span> tensorbay.dataset <span class="keyword">import</span> Dataset <span class="keyword">as</span> TensorBayDataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MNISTSegment</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;class for wrapping a MNIST segment.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, gas, segment_name, transform, cache=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.dataset = TensorBayDataset(<span class="string">&quot;MNIST&quot;</span>, gas)</span><br><span class="line">        <span class="keyword">if</span> cache:</span><br><span class="line">            self.dataset.enable_cache(<span class="string">&quot;data&quot;</span>)</span><br><span class="line">        self.segment = self.dataset[segment_name]</span><br><span class="line">        self.category_to_index = self.dataset.catalog.classification.get_category_to_index()</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.segment)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        data = self.segment[idx]</span><br><span class="line">        <span class="keyword">with</span> data.<span class="built_in">open</span>() <span class="keyword">as</span> fp:</span><br><span class="line">            image_tensor = self.transform(Image.<span class="built_in">open</span>(fp))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> image_tensor, self.category_to_index[data.label.classification.category]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_loader</span>(<span class="params">key</span>):</span></span><br><span class="line">    to_tensor = transforms.ToTensor()</span><br><span class="line">    normalization = transforms.Normalize(mean=[<span class="number">0.485</span>], std=[<span class="number">0.229</span>])</span><br><span class="line">    my_transforms = transforms.Compose([to_tensor, normalization])</span><br><span class="line"></span><br><span class="line">    train_segment = MNISTSegment(GAS(key), segment_name=<span class="string">&quot;train&quot;</span>, transform=my_transforms)</span><br><span class="line">    train_dataloader = DataLoader(train_segment, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">    test_segment = MNISTSegment(GAS(key), segment_name=<span class="string">&quot;test&quot;</span>, transform=my_transforms)</span><br><span class="line">    test_dataloader = DataLoader(test_segment, batch_size=<span class="number">4</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> train_dataloader, test_dataloader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">args, model, device, train_loader, optimizer, epoch</span>):</span></span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.cross_entropy(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % args.log_interval == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train Epoch: &#123;&#125; [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                epoch, batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                       <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line">            <span class="keyword">if</span> args.dry_run:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">model, device, test_loader</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line">            output = model(data)</span><br><span class="line">            test_loss += F.cross_entropy(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item()  <span class="comment"># sum up batch loss</span></span><br><span class="line">            pred = output.argmax(dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)  <span class="comment"># get the index of the max log-probability</span></span><br><span class="line">            correct += pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment"># Training settings</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;PyTorch MNIST&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">64</span>, metavar=<span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input batch size for training (default: 64)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--test-batch-size&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1000</span>, metavar=<span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;input batch size for testing (default: 1000)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--epochs&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">14</span>, metavar=<span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;number of epochs to train (default: 14)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--lr&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">1.0</span>, metavar=<span class="string">&#x27;LR&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;learning rate (default: 1.0)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--gamma&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">float</span>, default=<span class="number">0.7</span>, metavar=<span class="string">&#x27;M&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;Learning rate step gamma (default: 0.7)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--no-cuda&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;disables CUDA training&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--dry-run&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;quickly check a single pass&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--seed&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">1</span>, metavar=<span class="string">&#x27;S&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;random seed (default: 1)&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--log-interval&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">10</span>, metavar=<span class="string">&#x27;N&#x27;</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;how many batches to wait before logging training status&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;--save-model&#x27;</span>, action=<span class="string">&#x27;store_true&#x27;</span>, default=<span class="literal">False</span>,</span><br><span class="line">                        <span class="built_in">help</span>=<span class="string">&#x27;For Saving the current Model&#x27;</span>)</span><br><span class="line">    args = parser.parse_args()</span><br><span class="line">    use_cuda = <span class="keyword">not</span> args.no_cuda <span class="keyword">and</span> torch.cuda.is_available()</span><br><span class="line"></span><br><span class="line">    torch.manual_seed(args.seed)</span><br><span class="line"></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> use_cuda <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">    train_kwargs = &#123;<span class="string">&#x27;batch_size&#x27;</span>: args.batch_size&#125;</span><br><span class="line">    test_kwargs = &#123;<span class="string">&#x27;batch_size&#x27;</span>: args.test_batch_size&#125;</span><br><span class="line">    <span class="keyword">if</span> use_cuda:</span><br><span class="line">        cuda_kwargs = &#123;<span class="string">&#x27;num_workers&#x27;</span>: <span class="number">1</span>,</span><br><span class="line">                       <span class="string">&#x27;pin_memory&#x27;</span>: <span class="literal">True</span>,</span><br><span class="line">                       <span class="string">&#x27;shuffle&#x27;</span>: <span class="literal">True</span>&#125;</span><br><span class="line">        train_kwargs.update(cuda_kwargs)</span><br><span class="line">        test_kwargs.update(cuda_kwargs)</span><br><span class="line"></span><br><span class="line">    ACCESS_KEY = <span class="string">&#x27;Accesskey-4669e1203a6fa8291d5d7744ba313f91&#x27;</span></span><br><span class="line">    train_loader, test_loader = create_loader(ACCESS_KEY)</span><br><span class="line"></span><br><span class="line">    model = Net().to(device)</span><br><span class="line">    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)</span><br><span class="line">    scheduler = StepLR(optimizer, step_size=<span class="number">1</span>, gamma=args.gamma)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, args.epochs + <span class="number">1</span>):</span><br><span class="line">        train(args, model, device, train_loader, optimizer, epoch)</span><br><span class="line">        test(model, device, test_loader)</span><br><span class="line">        scheduler.step()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> args.save_model:</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">&quot;outputs/mnist.pt&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p><strong>运行方式：</strong></p><p>打开终端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p outputs</span><br><span class="line">python 1.train.py --save-model</span><br></pre></td></tr></table></figure><p><strong>运行结果：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Train Epoch: 1 [0/60000 (0%)]Loss: 2.305400</span><br><span class="line">Train Epoch: 1 [640/60000 (1%)]Loss: 1.359776</span><br><span class="line">....</span><br></pre></td></tr></table></figure><p>训练完毕，在outputs文件下有<code>mnist.pt</code>模型文件。</p><h2 id="二、参数转换"><a href="#二、参数转换" class="headerlink" title="二、参数转换"></a>二、参数转换</h2><h3 id="Pytorch模型导出为ONNX"><a href="#Pytorch模型导出为ONNX" class="headerlink" title="Pytorch模型导出为ONNX"></a>Pytorch模型导出为ONNX</h3><blockquote><p>“各家都有一套语言，换到一个标准说话”</p></blockquote><p>开放神经网络交换（Open Neural Network Exchange）简称ONNX是微软和Facebook提出用来表示深度学习模型的<strong>开放</strong>格式。所谓开放就是ONNX定义了一组和环境，平台均无关的标准格式，来增强各种AI模型的可交互性。</p><p>换句话说，无论你使用何种训练框架训练模型（比如TensorFlow/Pytorch/OneFlow/Paddle），在训练完毕后你都可以将这些框架的模型统一转换为ONNX这种统一的格式进行存储。注意ONNX文件不仅仅存储了神经网络模型的权重，同时也存储了模型的结构信息以及网络中每一层的输入输出和一些其它的辅助信息。</p><p>ONNX开源在了[5]，笔者为大家准备了一些参考学习资料，可参考[5-10]进行学习。</p><p>Pytorch平台训练好模型后，使用下列脚本将模型转化为ONNX</p><p>首先安装用到的包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install onnx coremltools onnx-simplifier</span><br></pre></td></tr></table></figure><p><strong>脚本名称：</strong><code>2.pt2onnx.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> models.net <span class="keyword">import</span> Net</span><br><span class="line"><span class="keyword">import</span> torch.onnx</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span>():</span></span><br><span class="line">    <span class="keyword">import</span> argparse</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;PyTorch pt file to ONNX file&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-i&#x27;</span>, <span class="string">&#x27;--input&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    args = parse_args()</span><br><span class="line">    dummy_input = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    model = Net()</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Loading state dict to cpu&quot;</span>)</span><br><span class="line">    model.load_state_dict(torch.load(args.<span class="built_in">input</span>, map_location=torch.device(<span class="string">&#x27;cpu&#x27;</span>)))</span><br><span class="line">    name = os.path.join(os.path.dirname(args.<span class="built_in">input</span>), os.path.basename(args.<span class="built_in">input</span>).split(<span class="string">&#x27;.&#x27;</span>)[<span class="number">0</span>] + <span class="string">&quot;.onnx&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Onnx files at:&quot;</span>, name)</span><br><span class="line">    torch.onnx.export(model, dummy_input, name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p><strong>运行方式：</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 2.pt2onnx.py -i outputs/mnist.pt</span><br></pre></td></tr></table></figure><p><strong>运行结果：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Loading state dict to cpu</span><br><span class="line">Onnx files at: outputs/mnist.onnx</span><br></pre></td></tr></table></figure><p>运行完毕，在outputs文件可发现已将pt模型转为<code>mnist.onnx</code>模型文件。</p><h3 id="ONNX模型转化成KModel"><a href="#ONNX模型转化成KModel" class="headerlink" title="ONNX模型转化成KModel"></a>ONNX模型转化成KModel</h3><p>使用NNCASE将ONNX模型转为K210上能运行的KModel，由于NNCASE环境配置较为依赖环境，我们使用Docker完成环境配置，对于docker只需要安装并正确配置即可，不熟悉的可以参考我写的Docker教程[12]。</p><p><strong>代码文件：</strong><code>3.onnx2kmodel.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> onnxsim</span><br><span class="line"><span class="keyword">import</span> onnx</span><br><span class="line"><span class="keyword">import</span> nncase</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span>():</span></span><br><span class="line">    <span class="keyword">import</span> argparse</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&#x27;ONNX file to KModel&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-i&#x27;</span>, <span class="string">&#x27;--input&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">str</span>, required=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_model_input_output</span>(<span class="params">model_file</span>):</span></span><br><span class="line">    onnx_model = onnx.load(model_file)</span><br><span class="line">    input_all = [node.name <span class="keyword">for</span> node <span class="keyword">in</span> onnx_model.graph.<span class="built_in">input</span>]</span><br><span class="line">    input_initializer = [node.name <span class="keyword">for</span> node <span class="keyword">in</span> onnx_model.graph.initializer]</span><br><span class="line">    input_names = <span class="built_in">list</span>(<span class="built_in">set</span>(input_all) - <span class="built_in">set</span>(input_initializer))</span><br><span class="line">    input_tensors = [node <span class="keyword">for</span> node <span class="keyword">in</span> onnx_model.graph.<span class="built_in">input</span> <span class="keyword">if</span> node.name <span class="keyword">in</span> input_names]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># input</span></span><br><span class="line">    inputs = []</span><br><span class="line">    <span class="keyword">for</span> _, e <span class="keyword">in</span> <span class="built_in">enumerate</span>(input_tensors):</span><br><span class="line">        onnx_type = e.<span class="built_in">type</span>.tensor_type</span><br><span class="line">        input_dict = &#123;&#125;</span><br><span class="line">        input_dict[<span class="string">&#x27;name&#x27;</span>] = e.name</span><br><span class="line">        input_dict[<span class="string">&#x27;dtype&#x27;</span>] = onnx.mapping.TENSOR_TYPE_TO_NP_TYPE[onnx_type.elem_type]</span><br><span class="line">        input_dict[<span class="string">&#x27;shape&#x27;</span>] = [(i.dim_value <span class="keyword">if</span> i.dim_value != <span class="number">0</span> <span class="keyword">else</span> d) <span class="keyword">for</span> i, d <span class="keyword">in</span> <span class="built_in">zip</span>(</span><br><span class="line">            onnx_type.shape.dim, [<span class="number">1</span>, <span class="number">3</span>, <span class="number">224</span>, <span class="number">224</span>])]</span><br><span class="line">        inputs.append(input_dict)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> onnx_model, inputs</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onnx_simplify</span>(<span class="params">model_file</span>):</span></span><br><span class="line">    onnx_model, inputs = parse_model_input_output(model_file)</span><br><span class="line">    onnx_model = onnx.shape_inference.infer_shapes(onnx_model)</span><br><span class="line">    input_shapes = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span> <span class="keyword">in</span> inputs:</span><br><span class="line">        input_shapes[<span class="built_in">input</span>[<span class="string">&#x27;name&#x27;</span>]] = <span class="built_in">input</span>[<span class="string">&#x27;shape&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    onnx_model, check = onnxsim.simplify(onnx_model, input_shapes=input_shapes)</span><br><span class="line">    <span class="keyword">assert</span> check, <span class="string">&quot;Simplified ONNX model could not be validated&quot;</span></span><br><span class="line"></span><br><span class="line">    model_file = os.path.join(os.path.dirname(model_file), <span class="string">&#x27;simplified.onnx&#x27;</span>)</span><br><span class="line">    onnx.save_model(onnx_model, model_file)</span><br><span class="line">    <span class="keyword">return</span> model_file</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_model_file</span>(<span class="params">model_file</span>):</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(model_file, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        model_content = f.read()</span><br><span class="line">    <span class="keyword">return</span> model_content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    args = parse_args()</span><br><span class="line">    model_file = args.<span class="built_in">input</span></span><br><span class="line">    target = <span class="string">&#x27;k210&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># onnx simplify</span></span><br><span class="line">    model_file = onnx_simplify(model_file)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compile_options</span></span><br><span class="line">    compile_options = nncase.CompileOptions()</span><br><span class="line">    compile_options.target = target</span><br><span class="line">    compile_options.dump_ir = <span class="literal">True</span></span><br><span class="line">    compile_options.dump_asm = <span class="literal">True</span></span><br><span class="line">    compile_options.dump_dir = <span class="string">&#x27;tmp&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># compiler</span></span><br><span class="line">    compiler = nncase.Compiler(compile_options)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># import_options</span></span><br><span class="line">    import_options = nncase.ImportOptions()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># import</span></span><br><span class="line">    model_content = read_model_file(model_file)</span><br><span class="line">    compiler.import_onnx(model_content, import_options)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># compile</span></span><br><span class="line">    compiler.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># kmodel</span></span><br><span class="line">    kmodel = compiler.gencode_tobytes()</span><br><span class="line">    name = os.path.basename(model_file).split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">f&#x27;<span class="subst">&#123;name&#125;</span>.kmodel&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(kmodel)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure><p><strong>运行方式：</strong></p><p>为简化部署方式，在部署好NNCASE的Docker镜像中直接运行Python脚本。首先用Docker拉取NNCASE镜像，再进入到镜像中运行Python代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 拉取镜像</span></span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/kendryte/nncase:latest</span><br><span class="line"><span class="comment"># 进入到容器内部</span></span><br><span class="line">docker run -it --rm -v `<span class="built_in">pwd</span>`:/mnt -w /mnt registry.cn-hangzhou.aliyuncs.com/kendryte/nncase:latest /bin/bash -c <span class="string">&quot;/bin/bash&quot;</span></span><br><span class="line"><span class="comment"># 运行</span></span><br><span class="line">python3 3.onnx2kmodel.py -i outputs/mnist.onnx</span><br></pre></td></tr></table></figure><p><strong>运行结果：</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">1. Import graph...</span><br><span class="line">2. Optimize target independent...</span><br><span class="line">3. Optimize target dependent...</span><br><span class="line">5. Optimize target dependent after quantization...</span><br><span class="line">6. Optimize modules...</span><br><span class="line">7.1. Merge module regions...</span><br><span class="line">7.2. Optimize buffer fusion...</span><br><span class="line">7.3. Optimize target dependent after buffer fusion...</span><br><span class="line">8. Generate code...</span><br><span class="line">WARN: Cannot find a decompiler for section .rdata</span><br><span class="line">WARN: Cannot find a decompiler for section .text</span><br><span class="line"></span><br><span class="line">SUMMARY</span><br><span class="line">INPUTS</span><br><span class="line">0       input.1 f32[1,1,28,28]</span><br><span class="line">OUTPUTS</span><br><span class="line">0       18      f32[1,10]</span><br><span class="line"></span><br><span class="line">MEMORY USAGES</span><br><span class="line">.input     3.06 KB      (3136 B)</span><br><span class="line">.output   40.00 B       (40 B)</span><br><span class="line">.data    313.00 KB      (320512 B)</span><br><span class="line">MODEL      4.58 MB      (4802240 B)</span><br><span class="line">TOTAL      4.89 MB      (5125928 B)</span><br></pre></td></tr></table></figure><p>运行完毕，在outputs文件下有<code>mnist.kmodel</code>文件，这个文件。</p><p><strong>代码讲解</strong>：</p><p>（1）首先使用onnx-simplifier简化ONNX模型</p><blockquote><p>为什么要简化？这是因为在训练完深度学习的pytorch或者tensorflow模型后，有时候需要把模型转成 onnx，但是很多时候，很多节点比如cast节点，Identity 这些节点可能都不需要，我们需要进行简化[11]，这样会方便我们后续在嵌入式平台部署。onnx-simplifier的开源地址见[9]。</p></blockquote><p>主要代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">onnx_simplify</span>(<span class="params">model_file</span>):</span></span><br><span class="line">    onnx_model, inputs = parse_model_input_output(model_file)</span><br><span class="line">    onnx_model = onnx.shape_inference.infer_shapes(onnx_model)</span><br><span class="line">    input_shapes = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">input</span> <span class="keyword">in</span> inputs:</span><br><span class="line">        input_shapes[<span class="built_in">input</span>[<span class="string">&#x27;name&#x27;</span>]] = <span class="built_in">input</span>[<span class="string">&#x27;shape&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    onnx_model, check = onnxsim.simplify(onnx_model, input_shapes=input_shapes)</span><br><span class="line">    <span class="keyword">assert</span> check, <span class="string">&quot;Simplified ONNX model could not be validated&quot;</span></span><br><span class="line"></span><br><span class="line">    model_file = os.path.join(os.path.dirname(model_file), <span class="string">&#x27;outputs/simplified.onnx&#x27;</span>)</span><br><span class="line">    onnx.save_model(onnx_model, model_file)</span><br><span class="line">    <span class="keyword">return</span> model_file</span><br></pre></td></tr></table></figure><p>（2）使用NNCASE转换ONNX参数，核心代码为</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">model_content = read_model_file(model_file)</span><br><span class="line">compiler.import_onnx(model_content, import_options)</span><br><span class="line"></span><br><span class="line"><span class="comment"># compile</span></span><br><span class="line">compiler.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># kmodel</span></span><br><span class="line">kmodel = compiler.gencode_tobytes()</span><br></pre></td></tr></table></figure><p>这一步时，离部署到嵌入式不远了，那么我们继续来看K210的部分。</p><h2 id="三、K210开发环境"><a href="#三、K210开发环境" class="headerlink" title="三、K210开发环境"></a>三、K210开发环境</h2><p>开发这个K210的姿势总结如下有三种：（1）使用<strong>Micropython固件</strong>开发 （2）使用<strong>standalone SDK</strong> 进行开发 （3）使用<strong>FreeRTOS</strong>进行开发。</p><blockquote><p>K210是支持好几种编程环境的，从最基本的**<code>cmake命令行开发环境</code><strong>，到</strong><code>IDE开发环境</code><strong>，到</strong><code>Python脚本式</code>**开发环境都支持，这几种开发方式没有优劣之分，有的人喜欢用命令行+vim，有的人喜欢IDE图形界面，也有的人根本不关心编译环境觉得人生苦短只想写Python。</p><p>一般来说越基础的开发方式比如C语言+官方库会自由度越大，能充分发挥出芯片的各种外设功能，但是开发难度比较高，过程很繁琐；越顶层的开发方式比如写脚本，虽然十分地便捷，甚至连下载程序的过程都不需要了，但是程序功能的实现极度依赖于MicroPython的API更新，且很多高级系统功能无法使用[2]。</p></blockquote><p>为降低大家在开发中的不友好度，本文介绍第一种开发方法，以后有机会可以介绍使用C SDK直接进行开发。不管用什么系统都能进行K210的开发，我们需要完成下列内容的准备：</p><p>（0）将K210通过USB连入你的电脑</p><p>（1）CH340驱动已安装</p><p>（2）cmake</p><p>（3）kflash或kflash GUI，一个烧录程序用以将编译好的.bin文件烧录到硬件中。前者命令行，后者图形界面</p><p>（4）Micropython固件</p><p><strong>第一步</strong> 下载Micropython固件 到<a href="https://dl.sipeed.com/shareURL/MAIX/MaixPy/release/master">https://dl.sipeed.com/shareURL/MAIX/MaixPy/release/master</a> 下载一个bin文件，这里笔者使用的是<code>minimum_with_kmodel_v4_support</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://dl.sipeed.com/fileList/MAIX/MaixPy/release/master/maixpy_v0<span class="number">.6</span><span class="number">.2_72</span>_g22a8555b5/maixpy_v0<span class="number">.6</span><span class="number">.2_72</span>_g22a8555b5_minimum_with_kmodel_v4_support.<span class="built_in">bin</span></span><br></pre></td></tr></table></figure><p><strong>第二步</strong> 查看K210的串口号，以笔者使用的MacOS为例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls /dev/cu.usbserial-*</span><br><span class="line"><span class="comment"># /dev/cu.usbserial-14330</span></span><br></pre></td></tr></table></figure><p><strong>第三步</strong> 烧录</p><p>使用命令行进行烧录示例</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kflash  -p /dev/cu.usbserial-<span class="number">14330</span> -b <span class="number">115200</span> -t maixpy_v0<span class="number">.6</span><span class="number">.2_72</span>_g22a8555b5_minimum_with_kmodel_v4_support.<span class="built_in">bin</span></span><br></pre></td></tr></table></figure><p>笔者比较懒，不想每次指定串口号，所以直接用<code>/dev/cu.usbserial-*</code> 。如果你电脑只有一个以<code>/dev/cu.usbserial</code> 开头的串口，那就不用指定，直接用我这种方法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kflash  -p /dev/cu.usbserial-* -b <span class="number">115200</span> -t *.<span class="built_in">bin</span></span><br></pre></td></tr></table></figure><p>到这里，如果没有问题的话，说明你已经成功在K210上部署了。怎么使用其进行编程呢？笔者建议读完[16]，更多信息可以从参考Micropython的文档[14]和Github[15]。</p><h2 id="四、硬件平台部署"><a href="#四、硬件平台部署" class="headerlink" title="四、硬件平台部署"></a>四、硬件平台部署</h2><p>KModel制作好，接下来需要把KModel部署到硬件 。有两种方式，下面分别介绍，任选一种即可。</p><h3 id="方法一：将Model烧录到Flash中"><a href="#方法一：将Model烧录到Flash中" class="headerlink" title="方法一：将Model烧录到Flash中"></a>方法一：将Model烧录到Flash中</h3><p>打开Kflash GUI，配置如下烧录到0x300000地址</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/kflash.png" alt="image-20211205160459548" style="zoom: 33%;" /><h3 id="方法二：将KModel放在SD卡中"><a href="#方法二：将KModel放在SD卡中" class="headerlink" title="方法二：将KModel放在SD卡中"></a>方法二：将KModel放在SD卡中</h3><p>直接将KModel放在SD卡中即可，注意TF卡需要是MBR 分区 FAT32 格式[17]。如果不是这个格式，是加载不到SD卡的。在Mac中，可以打开磁盘管理工具–&gt;选择对应磁盘–&gt;抹掉–&gt;格式–&gt;MS-DOS(FAT)直接一步格式化。</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20211205160309155.png" alt="image-20211205160309155" style="zoom:50%;" /><h3 id="最终运行"><a href="#最终运行" class="headerlink" title="最终运行"></a>最终运行</h3><p>代码文件：<code>4.k210_main.py</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sensor, lcd, image</span><br><span class="line"><span class="keyword">import</span> KPU <span class="keyword">as</span> kpu</span><br><span class="line"></span><br><span class="line">lcd.init(invert=<span class="literal">True</span>)</span><br><span class="line">sensor.reset()</span><br><span class="line">sensor.set_pixformat(sensor.RGB565)</span><br><span class="line">sensor.set_framesize(sensor.QVGA)</span><br><span class="line">sensor.set_windowing((<span class="number">224</span>, <span class="number">224</span>))  <span class="comment"># set to 224x224 input</span></span><br><span class="line">sensor.set_hmirror(<span class="number">0</span>)  <span class="comment"># flip camera</span></span><br><span class="line">task = kpu.load(<span class="number">0x300000</span>)  <span class="comment"># load model from flash address 0x200000</span></span><br><span class="line">a = kpu.set_outputs(task, <span class="number">0</span>, <span class="number">10</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">sensor.run(<span class="number">1</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    img = sensor.snapshot()</span><br><span class="line">    lcd.display(img, oft=(<span class="number">0</span>, <span class="number">0</span>))  <span class="comment"># display large picture</span></span><br><span class="line">    img1 = img.to_grayscale(<span class="number">1</span>)  <span class="comment"># convert to gray</span></span><br><span class="line">    img2 = img1.resize(<span class="number">32</span>, <span class="number">32</span>)  <span class="comment"># resize to mnist input 32x32</span></span><br><span class="line">    a = img2.strech_char(<span class="number">1</span>)  <span class="comment"># preprocessing pictures, eliminate dark corner</span></span><br><span class="line">    lcd.display(img2, oft=(<span class="number">240</span>, <span class="number">32</span>))  <span class="comment"># display small 32x32 picture</span></span><br><span class="line">    a = img2.pix_to_ai();  <span class="comment"># generate data for ai</span></span><br><span class="line">    fmap = kpu.forward(task, img2)  <span class="comment"># run neural network model</span></span><br><span class="line">    plist = fmap[:]  <span class="comment"># get result (10 digit&#x27;s probability)</span></span><br><span class="line">    pmax = <span class="built_in">max</span>(plist)  <span class="comment"># get max probability</span></span><br><span class="line">    max_index = plist.index(pmax)  <span class="comment"># get the digit</span></span><br><span class="line">    lcd.draw_string(<span class="number">224</span>, <span class="number">0</span>, <span class="string">&quot;%d: %.3f&quot;</span> % (max_index, pmax), lcd.WHITE, lcd.BLACK)</span><br></pre></td></tr></table></figure><p><strong>运行方式：</strong></p><p>有多种方式，下面介绍两种，更多方式从参考<a href="https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html">https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html</a></p><p><strong>方式1：rshell</strong></p><p>正如使用 <code>linux</code> 终端一样， 使用 <a href="https://github.com/dhylands/rshell">rshell</a> 的 <code>cp</code> 命令即可简单地复制文件到开发板</p><p>按照 <code>rshell</code> 项目主页的说明安装好 <code>rshell</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python3-pip</span><br><span class="line">sudo pip3 install rshell</span><br><span class="line">rshell -p /dev/ttyUSB1 <span class="comment"># 这里根据实际情况选择串口</span></span><br></pre></td></tr></table></figure><p>Copy</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls /flash</span><br><span class="line">cp ./test.py /flash/ <span class="comment">#复制电脑当前目录的文件 test.py </span></span><br></pre></td></tr></table></figure><p><strong>方式2：SD 卡自动拷贝到 Flash 文件系统</strong></p><p>为了方便将 SD 卡的内容拷贝到 Flash 文件系统， 只需要将要拷贝到 Flash 文件系统的文件重命名为<code>cover.boot.py</code> 或者<code>cover.main.py</code>, 然后放到<code>SD</code>卡根目录， 开发板断电插入<code>SD</code>卡，然后开发板上电， 程序就会自动将这两个文件拷贝到<code>/flash/boot.py</code>或者<code>/flash/main.py</code>，这样就算后面取出了<code>SD</code>卡，程序已经在 <code>/flash/boot.py</code>或者<code>/flash/main.py</code>了</p><p>看看部署到K210的识别效果：</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/show.gif" alt="show" style="zoom:100%;" /><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><p>本文是笔者折腾嵌入式AI的一篇实践，涵盖以下内容：</p><ul><li>视觉模型的数据准备、网络设计、训练</li><li>ONNX基本知识与ONNX的简化</li><li>使用AI编译器NNCASE将ONNX转化为KModel</li><li>Micropython + KModel在K210上的部署</li></ul><p>本文方法由于在Micropython上进行模型加载，在系统资源调用以及软件适配上会有许多限制。做成产品时建议用C+K210 SDK开发。由于篇幅限制，下篇将探索使用C语言对模型进行部署，欢迎关注更新！由于个人能力有限，如有疑问以及勘误欢迎和笔者进行交流：Github/QiangZiBro！</p><p>本文使用到的代码都托管在这个仓库里： </p><blockquote><p><a href="https://github.com/QiangZiBro/pytorch-k210.git">https://github.com/QiangZiBro/pytorch-k210.git</a> </p></blockquote><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[ 1 ] : 模型部署的场景、挑战和技术方案 <a href="https://zhuanlan.zhihu.com/p/387575188">https://zhuanlan.zhihu.com/p/387575188</a> </p><p>[ 2 ] : 嵌入式AI从入门到放肆【K210篇】– 硬件与环境 <a href="https://zhuanlan.zhihu.com/p/81969854">https://zhuanlan.zhihu.com/p/81969854</a></p><p>[ 3 ] : nncase <a href="https://github.com/kendryte/nncase">https://github.com/kendryte/nncase</a></p><p>[ 4 ] : tensorbay mnist <a href="https://tensorbay-python-sdk.graviti.com/en/stable/integrations/pytorch.html">https://tensorbay-python-sdk.graviti.com/en/stable/integrations/pytorch.html</a></p><p>[ 5 ] : ONNX Github <a href="https://github.com/onnx/onnx">https://github.com/onnx/onnx</a></p><p>[ 6 ] : ONNX学习笔记 <a href="https://zhuanlan.zhihu.com/p/346511883">https://zhuanlan.zhihu.com/p/346511883</a></p><p>[ 7 ] : ONNX 教程 <a href="https://github.com/onnx/tutorials">https://github.com/onnx/tutorials</a></p><p>[ 8 ] : ONNX 预训练SOTA模型  <a href="https://github.com/onnx/models">https://github.com/onnx/models</a></p><p>[ 9 ] : ONNX简化器 <a href="https://github.com/daquexian/onnx-simplifier">https://github.com/daquexian/onnx-simplifier</a></p><p>[ 10  ] :  nncase Github  <a href="https://github.com/kendryte/nncase">https://github.com/kendryte/nncase</a></p><p>[ 11 ] : <a href="https://mp.weixin.qq.com/s/OTUSDSqGTgTJ6-KA-o0rQw">https://mp.weixin.qq.com/s/OTUSDSqGTgTJ6-KA-o0rQw</a></p><p>[ 12 ] : <a href="https://github.com/QiangZiBro/learn-docker-in-a-smart-way">https://github.com/QiangZiBro/learn-docker-in-a-smart-way</a></p><p>[ 13 ] : 训练好的深度学习模型原来这样部署的！ <a href="https://mp.weixin.qq.com/s/tqSmFcR-aQjDhaEyQBzeUA">https://mp.weixin.qq.com/s/tqSmFcR-aQjDhaEyQBzeUA</a></p><p>[ 14 ] : <a href="https://wiki.sipeed.com/soft/maixpy/zh/index.html">https://wiki.sipeed.com/soft/maixpy/zh/index.html</a></p><p>[ 15 ] : <a href="https://github.com/sipeed/MaixPy">https://github.com/sipeed/MaixPy</a></p><p>[ 16 ] : 编辑并执行文件 <a href="https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html">https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_edit_file.html</a></p><p>[ 17 ] : <a href="https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html#Micro-SD-%E5%8D%A1%E8%AF%BB%E5%8F%96%E4%B8%8D%E5%88%B0">https://wiki.sipeed.com/soft/maixpy/zh/others/maixpy_faq.html#Micro-SD-%E5%8D%A1%E8%AF%BB%E5%8F%96%E4%B8%8D%E5%88%B0</a></p><p>[ 18 ] : <a href="https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html">https://wiki.sipeed.com/soft/maixpy/zh/get_started/get_started_upload_script.html</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;font color=&quot;green&quot;&gt;作者申明：该文章仅在微信平台授权给公众号Datawhale（ID：Datawhale）首发原创，其他平台暂无授权。&lt;/font&gt;&lt;/p&gt;
&lt;p&gt;如何将深度学习算法部署到嵌入式设备？本文将带给你一个从Pytorch平台训练，到部署到嵌入式设备K210的完整方案。章节之间跨度大，知识点相对独立，欢迎点赞收藏慢慢看！跟着本文做完，你也可以做一个自己的嵌入式AI小产品！&lt;/p&gt;</summary>
    
    
    
    
    <category term="嵌入式" scheme="https://qiangzibro.com/tags/%E5%B5%8C%E5%85%A5%E5%BC%8F/"/>
    
    <category term="深度学习部署" scheme="https://qiangzibro.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%83%A8%E7%BD%B2/"/>
    
  </entry>
  
  <entry>
    <title>动手制作一个透明小电视</title>
    <link href="https://qiangzibro.com/2021/11/22/holocubic/"/>
    <id>https://qiangzibro.com/2021/11/22/holocubic/</id>
    <published>2021-11-22T14:02:44.000Z</published>
    <updated>2021-11-23T09:10:29.831Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h2&gt;</summary>
      
    
    
    
    
    <category term="ESP32" scheme="https://qiangzibro.com/tags/ESP32/"/>
    
  </entry>
  
  <entry>
    <title>看完鱿鱼游戏后，我用视觉算法做了个小游戏</title>
    <link href="https://qiangzibro.com/2021/10/20/suqid-game/"/>
    <id>https://qiangzibro.com/2021/10/20/suqid-game/</id>
    <published>2021-10-20T05:27:12.000Z</published>
    <updated>2021-10-26T11:46:13.737Z</updated>
    
    <content type="html"><![CDATA[<p>新坑待填中…</p><span id="more"></span><h2 id="引子">引子</h2><p>鱿鱼游戏是最近在Netflix上热播的一部惊悚类型韩剧，它的火热程度到底达到什么程度？在全球90多个国家，它在Netflix的收视率达到第一。它风靡欧洲各国，许多西方人因这部剧开始学习韩语。这部剧为什么这么引人注目呢？其大致设定如此（包含微量剧透，放心施用）</p><p>一个疯狂的组织召集了一群生活绝望的人，邀请他们参加几个游戏，只要全部通过便可以获得四百多亿韩元奖金。但殊不知这些游戏是以生命为赌注，输了游戏收到的是一个个枪子。由此，其剧情设定的惊悚程度可见一斑。</p><p>事情是这样的，笔者在看完第一集，也就是第一个游戏觉得很有意思。其游戏是一二三木头人，小女孩数完“一二三木头人”，所有人不许动，如果动的话收到的就是一枪。<br><img src="123game.gif" alt="motion_detected" style="zoom: 100%;" /></p><p>注意到这里，此剧给了一个检测镜头特写</p><img src="motion_detected.jpg" alt="motion_detected" style="zoom: 33%;" /><p>小女孩的眼睛（摄像头) 检测是否有人系统，检测到移动者的位置后，对这个位置进行射击。</p><p>笔者最担心的计算机视觉算法的应用出现了！看到这么阴间的游戏，我深思良久，决定用视觉算法亲自实现一个123木头人游戏！</p><h2 id="方法设计">方法设计</h2><p>这里面最关键的问题是精确地识别运动的目标，先看看有哪些方法：</p><p>笔者先决定用背景差法提取直接提取运动目标，这样做的一个问题是：我们需要反复调节差值图的轮廓面积（Contour Area），调就调吧，于是我用OpenCV写了一个参数标定程序</p><p>还是有许多小框框</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;新坑待填中…&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>数学建模协作方法论</title>
    <link href="https://qiangzibro.com/2021/10/11/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%8D%8F%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA/"/>
    <id>https://qiangzibro.com/2021/10/11/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E5%8D%8F%E4%BD%9C%E6%96%B9%E6%B3%95%E8%AE%BA/</id>
    <published>2021-10-11T11:38:55.000Z</published>
    <updated>2021-10-12T04:26:40.902Z</updated>
    
    <content type="html"><![CDATA[<p>数学建模比赛是本、硕学生参加频次较高一个比赛，其奖项也具有一定的含金量。笔者在研究生期间参加过两次华为杯数模，先后得到二等奖和一等奖。本文会结合笔者自身经验，并从一个开发者的角度，分享该以怎样的工作流来提高团队合作的效率。</p><span id="more"></span><blockquote><p>本文同步发表公众号：QiangZiBro和我的博客https://qiangzibro.com，欢迎关注！</p></blockquote><p>简而言之，笔者推荐的数模合作方式概述为以下四点</p><ul><li>每人各做1或2道题</li><li>使用Latex作为论文格式支持，使用VSCode作为论文编辑工具</li><li>使用Git做版本控制，Github作为同步源</li><li>在各自分支上进行论文写作，由队长最后合并到主分支</li></ul><p>下面，我们来抽枝剥茧地看细节。</p><p><strong>1. 每人各做1或2道题</strong></p><p>传统的编程+建模+写作三人分工模式将这三样工作割裂开来，造成的问题是编程等建模，写作等编程这样一个尴尬局面。</p><p>笔者建议每人都应该具有了解他人工作的能力，不要将几种能力独立开来。</p><p>比赛开始时，队友间相互讨论、协商，每人各选一道题，能力强者可以选两题进行求解。毕竟，多人同时求解的多线程操作，不太会造成最后一题没时间做的情况。</p><p><strong>2. 使用Latex+VSCode进行你的论文写作</strong></p><p>排版是论文最后得分高低的一个重要因素，但也是最令人头疼的问题。建议使用Latex进行论文写作，直接参考模板写作即可。</p><p>要使用Latex，需要下载安装支持Latex的Latex编译器。Latex编译器的下载和Latex语法网上有大量教学，这里不再赘述。在你的电脑下载安装Latex编译器后，能够将Latex文本转为PDF文本。</p><p>使用<strong>VSCode</strong>进行Latex文本编辑。在<strong>VSCode</strong>这个神奇的编辑器中，有个叫<strong>Latex Workshop</strong>的插件，能调用Latex编译器一键编译并显示PDF文件。建议参考南开大学程明明老师的<strong>学术论文写作</strong>[1]了解详细操作，也可参考[3]。</p><p>使用Latex还有一个好处是，便于做版本控制。不像Word，Latex文件本身是纯文本，能够轻松地做版本控制。</p><p>关于数学建模的Latex模板，网上有很多，以2020研究生数学建模为例[2]</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/latexstudio/GMCMthesis </span><br><span class="line"><span class="built_in">cd</span> GMCMthesis </span><br></pre></td></tr></table></figure><p>笔者在2020年数学建模用的就是这个模板，在Windows下可以直接使用，在Mac下的VSCode编译时，<strong>自动</strong>提醒我下载了两种字体后，才能使用。</p><p><strong>3. 使用Git做版本控制</strong></p><p>为什么要做版本控制？讲个恐怖故事：小明在比赛结束前一天将辛辛苦苦写的论文误删除了，并且是不可恢复的删除，于是小明顶着崩溃的心情在最后的时间又重写了一篇出来。</p><p>这个故事是真的，就发生在我身边。</p><p>由此可见版本控制+多地存储的重要性。使用Git对每一次小改动做提交，并及时push到你的Github或者Gitee仓库，就算你的电脑烧了也能从远程找回些东西出来。</p><p><strong>4. 多人协作分支策略</strong></p><p>使用Git多分支管理，共同协作一个私有的Github/Gitee仓库。主分支（master或者main分支）作为稳定的最终版本，每人在初始点的模板引出一个分支，并推到自己的分支上，由一人做最后的分支合并。</p><p>具体流程如下，比如我是队长，同时要写文章，用下列命令，从模板新引出一个分支出来</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b dev_captain</span><br></pre></td></tr></table></figure><p>队员小明也引出一个分支</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout -b dev_ming</span><br></pre></td></tr></table></figure><p>假设模板如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">## chapter 1</span><br><span class="line">## chapter 2</span><br><span class="line">## chapter 3</span><br><span class="line">## reference</span><br></pre></td></tr></table></figure><p>在分支<code>dev_captain</code>上，我对第1，3章节做了大量修改后，并push到自己的远程分支</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">## chapter 1</span><br><span class="line">大量修改 captain</span><br><span class="line">## chapter 2</span><br><span class="line">## chapter 3</span><br><span class="line">大量修改 captain</span><br><span class="line">## reference</span><br></pre></td></tr></table></figure><p>在分支<code>dev_ming</code>上，小明也对第2章节进行大量修改</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## chapter 1</span><br><span class="line">## chapter 2</span><br><span class="line">小明 大量内容</span><br><span class="line">## chapter 3</span><br><span class="line">## reference</span><br></pre></td></tr></table></figure><p>将这两份内容直接合并到主分支非常简单，因为我们只在自己的对应章节进行了更新，Git能够自动将其合并成一个整体。例如，分支管理者进行操作如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">git fetch -a <span class="comment"># 从远程更新</span></span><br><span class="line">git checkout master</span><br><span class="line">git merge dev_captain</span><br><span class="line">git merge dev_ming</span><br></pre></td></tr></table></figure><p>再次看我们点的论文，也就变成了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">## chapter 1</span><br><span class="line">大量修改 captain</span><br><span class="line">## chapter 2</span><br><span class="line">小明 大量内容</span><br><span class="line">## chapter 3</span><br><span class="line">大量修改 captain</span><br><span class="line">## reference</span><br></pre></td></tr></table></figure><p><strong>分支冲突</strong></p><p>遇到分支冲突不要怕，首先要明白为什么会有分支冲突：两个分支版本在同一块区域进行了不同的改动，Git不能确定到底要保留哪块内容，于是要求你改完后再次进行提交。还是上面的例子，我在<code>reference</code>章节下添加了两个参考</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">## reference</span><br><span class="line">- refer 1</span><br><span class="line">- refer 2</span><br></pre></td></tr></table></figure><p>小明在<code>reference</code>章节下也添加了两个参考</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">## reference</span><br><span class="line">- refer 1</span><br><span class="line">- refer 3</span><br></pre></td></tr></table></figure><p>将两个分支合并到主分支时，出现</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Auto-merging example.txt</span><br><span class="line">CONFLICT (content): Merge conflict in example.txt</span><br><span class="line">Automatic merge failed; fix conflicts and then commit the result.</span><br></pre></td></tr></table></figure><p>这意味着产生了冲突，打开这个文件</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">## reference</span><br><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="line">- refer 1 </span><br><span class="line">- refer 3</span><br><span class="line">=======</span><br><span class="line">- refer 1</span><br><span class="line">- refer 2</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev_captain</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以看到<code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code>和<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev1</code>中间包围的部分就是冲突内容，<code>=======</code>上下是各自分支的内容。我们将这个区域的内容改成我们想要的样子，比如说想要1、2、3，那就只需要删掉重复的<code>- refer 1</code></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</span><br><span class="line">- refer 1 </span><br><span class="line">- refer 3</span><br><span class="line">=======</span><br><span class="line">- refer 2</span><br><span class="line">&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev_captain</span><br></pre></td></tr></table></figure><p>再微调一下，并删掉<code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code>，<code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev_captain</code>和<code>=======</code>，如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">- refer 1 </span><br><span class="line">- refer 2</span><br><span class="line">- refer 3</span><br></pre></td></tr></table></figure><p>再次提交</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add .</span><br><span class="line">git commit -m <span class="string">&quot;解决了参考文献的冲突&quot;</span></span><br><span class="line">git push origin main</span><br></pre></td></tr></table></figure><p>至此，分支冲突解决。</p><blockquote><p><strong>课后作业：</strong>多人合作有时候会产生合并冲突，你会采取怎样约束，让冲突少产生、或者不产生？</p><p><strong>Hint：</strong></p><ul><li>本文提供的Latex模板仓库，没有忽略掉编译产生的中间文件，这些文件不应该被提交</li><li>Git能够自动识别合并不同区域</li></ul></blockquote><p>也许没有完美的方法，但一定有更适合你们的方法，希望本文能给即将参加数学建模的你们带来帮助，祝好运✨</p><h2 id="参考">参考</h2><p>[ 1 ] : https://mmcheng.net/writing/</p><p>[ 2 ] : https://github.com/latexstudio/GMCMthesis</p><p>[ 3 ] : https://zhuanlan.zhihu.com/p/38178015</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;数学建模比赛是本、硕学生参加频次较高一个比赛，其奖项也具有一定的含金量。笔者在研究生期间参加过两次华为杯数模，先后得到二等奖和一等奖。本文会结合笔者自身经验，并从一个开发者的角度，分享该以怎样的工作流来提高团队合作的效率。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Git" scheme="https://qiangzibro.com/tags/Git/"/>
    
  </entry>
  
  <entry>
    <title>使用Linux，从正确配置ssh开始</title>
    <link href="https://qiangzibro.com/2021/09/17/%E4%BD%BF%E7%94%A8Linux%EF%BC%8C%E4%BB%8E%E6%AD%A3%E7%A1%AE%E9%85%8D%E7%BD%AEssh%E5%BC%80%E5%A7%8B/"/>
    <id>https://qiangzibro.com/2021/09/17/%E4%BD%BF%E7%94%A8Linux%EF%BC%8C%E4%BB%8E%E6%AD%A3%E7%A1%AE%E9%85%8D%E7%BD%AEssh%E5%BC%80%E5%A7%8B/</id>
    <published>2021-09-17T14:27:13.000Z</published>
    <updated>2021-09-17T14:29:15.213Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>ssh相当于windows上的远程桌面连接，但没有桌面，只有文字终端。ssh是许多Linux使用者入门时必学的一个命令。借助ssh，开发人员可以很方便地连接远程或是局域网的其他电脑，直接在上面进行开发工作。</p><span id="more"></span><p>拿笔者自己平时工作流举例，每天到实验室首先打开mac上的item2终端，连接两个扩展屏，再ssh连入几台服务器，切换到tmux，大部分工作都可以在一个终端上完成。</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/WechatIMG102.jpeg" alt="" /><figcaption>WechatIMG102</figcaption></figure><p>可以说，使用好ssh，我们能更舒心地连接远程；使用好终端，开发人员能够更顺利地完成自己的开发工作。</p><p>本文介绍一些使用ssh的小技巧，非常容易操作，那么， let’s do it!</p><h1 id="基础">基础</h1><h2 id="ssh客户端与服务端">ssh客户端与服务端</h2><p>想要使用ssh，首先需要有个终端软件，其次本地系统要安装有ssh客户端，远程系统要有服务端。</p><p>比如从mac系统连接远程linux服务器，item2无疑是首选的终端软件，而ssh客户端在mac上是内置的；windows建议使用cmder软件，cmder是一款优秀的开源软件，可以让你在windows上有着类似linux的操作感觉。cmder直接集成了ssh客户端，下载方式见<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a><a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>。</p><p>对于处在远程的服务端，还需要远程的ssh服务器<strong>安装并打开。</strong>比如对一台新安装的ubuntu18.04系统，一般是只有ssh而没有ssh服务端，可进行下列安装操作</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install openssh-server -y</span><br><span class="line">sudo systemctl status ssh <span class="comment">#查看状态</span></span><br><span class="line"><span class="comment"># 如果你的防火墙开启了，使用下面语句</span></span><br><span class="line">sudo ufw allow ssh</span><br></pre></td></tr></table></figure><h2 id="连接方式">连接方式</h2><p>基本的ssh连接方法是</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh username@ip</span><br></pre></td></tr></table></figure><p><code>username</code>表示该机器的用户名，<code>ip</code>表示对应的ip地址。比如，笔者在<code>10.22.75.212</code>的用户名是<code>qiangzibro</code>，只需要在终端输入</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh qiangzibro@10.22.75.212</span><br></pre></td></tr></table></figure><p>接下来，终端会提示你一条信息，输入yes回车，会提示你输入密码，就像这样。</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20200820184652666.png" alt="" /><figcaption>image-20200820184652666</figcaption></figure><p>先别着急使用下去，稍加配置可以让我们使用得更加舒心、安全。</p><h1 id="基本配置">基本配置</h1><h2 id="给ip地址取别名">给ip地址取别名</h2><p>长长的ip地址不好记，给ip地址取个别名吧！在mac或者linux上，可以编辑<code>/etc/hosts</code>这个文件，由于是系统文件，需要使用管理员权限。编辑器可以自选，笔者使用的是<code>neovim</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo nvim /etc/hosts</span><br></pre></td></tr></table></figure><p>比如我想给<code>10.22.75.177</code>取名叫<code>lab1</code>，添加下面一行：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">10.22.75.177 lab1</span><br></pre></td></tr></table></figure><p>在以后的使用中，凡是需要用到ip地址，可以直接用别名代理，比如</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping lab1</span><br></pre></td></tr></table></figure><h2 id="给特定主机上的用户取别名">给特定主机上的用户取别名</h2><p>ip地址取完别名后，我们可以使用类似</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh qiangzibro@lab1</span><br></pre></td></tr></table></figure><p>的方式进行连接，实际上，这样的连接方式还可以进一步简化。</p><p>也就是说，给<code>qiangzibro@lab1</code>也取个别名</p><p>不建议自己造轮子，早年间笔者曾写过比如<code>alias sshqiang="ssh qiangzibro@lab1”</code>的别名，其实没有太大别要，因为进行下面配置可以让以后使用更方便：</p><p>类unix系统（mac或者linux）可以直接编辑<code>~/.ssh/config</code>这个文件，如果没有，自己创建一个。语法如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Host l1</span><br><span class="line">HostName lab1</span><br><span class="line">Port 22</span><br><span class="line">User qiangzibro</span><br></pre></td></tr></table></figure><p>配置很简单，四行分别表示别名、远程主机ip、远程主机ssh端口、远程主机用户名。然后我们可以用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh l1</span><br></pre></td></tr></table></figure><p>进行连接。</p><h2 id="免密码登录">免密码登录</h2><p>经常使用密码登录，一个问题是有安全风险，另外一个是麻烦，太懒了啊，每次输密码多麻烦！ssh还提供一种使用密匙验证的方式进行登录，相信大家在配置github免密登录时也遇到过。百度百科上对其解释如下：</p><blockquote><p>原理是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。</p></blockquote><p>也就是说，把本地公钥拷贝到远程服务器上，就不需要每次登录使用密码了。具体讲，是把本地<code>~/.ssh/id_rsa.pub</code>内的内容拷贝到远程<code>~/.ssh/authorized_keys</code>文件里。首先看看本地有没有公钥：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat ~/.ssh/id_rsa.pub</span><br></pre></td></tr></table></figure><p>没有，则生成一个</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa</span><br></pre></td></tr></table></figure><p>一路回车按下去，便生成在了<code>~/.ssh/id_rsa.pub</code></p><p>你可以使用复制粘贴最原始的方法，而这种操作也有命令简化了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id l1 <span class="comment"># 将本地公钥拷贝到远程名为l1用户下，也就是/home/qiangzibro/.ssh/authorized_keys里</span></span><br></pre></td></tr></table></figure><h1 id="更多用法">更多用法</h1><p>前几个配置做完，相信你一定可以更加舒适地使用ssh了。但除了常用的远程连接，ssh还有许多使用的技巧。</p><h2 id="使用scp传文件">使用scp传文件</h2><p>基于ssh协议——把名为<code>local_path</code>的文件， 从本地传到远程家目录下</p><blockquote><p>scp 是 secure copy 的缩写, scp 是 linux 系统下基于 ssh 登陆进行安全的远程文件拷贝命令。</p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp [-r] local_path l1:~</span><br></pre></td></tr></table></figure><p>两点注意：如果<code>local_path</code>是文件夹，则带一个<code>-r</code>参数，再一个是注意中间的冒号。</p><p>同理，远程到本地：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scp [-r] l1:remote_path local_path</span><br></pre></td></tr></table></figure><h2 id="通过ssh运行远程脚本">通过ssh运行远程脚本</h2><p>运行远程机器的一个命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh l1 <span class="string">&quot;ls&quot;</span></span><br></pre></td></tr></table></figure><p>也许你会问：<strong>直接ssh连接到远程机器，运行程序不就好了，为什么通过ssh命令运行呢？</strong></p><p>其实，单个命令确实没有什么必要，但对于复杂、批量的操作，写在脚本里，可以大大提高我们的效率。比如笔者自己维护的一个dotfiles，其功能就是能够使自己的笔记本，和几个linux服务器同步一份配置，有着相同的使用感觉。整个项目是用git和github管理的。如果一个地方做改动，想同步到其他地方，需要一个机器先push，其他机器再pull等多个操作。其实这些操作都可以交给脚本完成。分享一段笔者写的自动更新脚本：</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20200820195507087.png" alt="" /><figcaption>image-20200820195507087</figcaption></figure><blockquote><p>关于dotfiles，就不分享自己的项目了，建议大家创建一份属于自己的dotfiles。毕竟各种配置，只有适合自己的才是最舒服的嘛！github也有许多dotfiles的分享，读者可以去参考。</p></blockquote><h2 id="ssh做代理">ssh做代理</h2><p>ssh 命令除了登陆外还有三种代理功能：</p><ul><li>正向代理（-L）：相当于 iptable 的 port forwarding</li><li>反向代理（-R）：相当于 frp 或者 ngrok</li><li>socks5 代理（-D）：相当于 ss/ssr</li></ul><p>这里不展开赘述，可以参考<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p><h1 id="总结">总结</h1><p>本文总结了常用的linux ssh操作，虽然大部分操作都很简单，但可以提升我们使用的体验。作为开发人员，“舒舒服服”地使用操作系统，可是常规操作哦。</p><p>你好，我是强子哥，一个Linux爱好者，也是三维深度学习方向的在读研究生，欢迎关注，共同学习。</p><h1 id="参考">参考</h1><section class="footnotes" role="doc-endnotes"><hr /><ol><li id="fn1" role="doc-endnote"><p>https://github.com/cmderdev/cmder/ "cmder的github"<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn2" role="doc-endnote"><p>https://cmder.net/ "cmder官网"<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li><li id="fn3" role="doc-endnote"><p>https://zhuanlan.zhihu.com/p/57630633 "韦易笑 SSH 命令的三种代理功能（-L/-R/-D）"<a href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li></ol></section>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;前言&lt;/h1&gt;
&lt;p&gt;ssh相当于windows上的远程桌面连接，但没有桌面，只有文字终端。ssh是许多Linux使用者入门时必学的一个命令。借助ssh，开发人员可以很方便地连接远程或是局域网的其他电脑，直接在上面进行开发工作。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="https://qiangzibro.com/tags/Linux/"/>
    
    <category term="Tutorial" scheme="https://qiangzibro.com/tags/Tutorial/"/>
    
  </entry>
  
  <entry>
    <title>动手实践全景图像语义分割</title>
    <link href="https://qiangzibro.com/2021/09/17/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%99%AF%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/"/>
    <id>https://qiangzibro.com/2021/09/17/%E5%8A%A8%E6%89%8B%E5%AE%9E%E8%B7%B5%E5%85%A8%E6%99%AF%E5%9B%BE%E5%83%8F%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2/</id>
    <published>2021-09-16T16:47:18.000Z</published>
    <updated>2021-09-17T14:07:02.108Z</updated>
    
    <content type="html"><![CDATA[<h2 id="导读">导读</h2><p>相信许多读者体验过b站上的全景视频，如果还没有，快来体验一下吧[1]！只需鼠标点击并移动，便可360度无死角的浏览全景视频。全景图像，又称360°全景图，其数据分布在球面空间上。如下图所示，如果将全景图像展开则会造成畸变，因此，直接将传统二维平面图像处理方法应用到球面数据上，其效果则会大大降低。要解决分布在球面空间上的数据，需要特定的方法，比如球面卷积网络。本文手把手带你实践一个有趣的应用——全景图像语义分割，并对多种传统CNN方法和球面CNN方法进行对比。</p><span id="more"></span><figure><img src="imgs/动手实践全景图像语义分割/640.png" alt="" /><figcaption>图片</figcaption></figure><p>如下图所示，全景图分割实例为像素级别分类，每种实例对应一个标签。完成本教程后，你将能够做一个如下图所示的全景图小应用。</p><p><img src="imgs/动手实践全景图像语义分割/image-20210816192833332.png" alt="image-20210816192833332" style="zoom:50%;" /></p><p>本教程以及相关代码托管在https://github.com/QiangZiBro/spherical_image_segmentation_tutorial，欢迎讨论、提Issue</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/QiangZiBro/spherical_image_segmentation_tutorial</span><br><span class="line"><span class="built_in">cd</span> spherical_image_segmentation_tutorial</span><br></pre></td></tr></table></figure><h2 id="环境构建">环境构建</h2><p>基于深度学习的编程环境往往有各种复杂的环境依赖，而各种安装报错总是消磨我们的时间，其实这个过程可以大大缩短。我们所需要的也就是通过一个命令安装所有的依赖并打开环境</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make up <span class="comment">#等价于 docker-compose up -d</span></span><br></pre></td></tr></table></figure><p>再通过一个命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make <span class="keyword">in</span></span><br></pre></td></tr></table></figure><p>来进入我们需要的环境，然后运行程序。为实现构建这一过程，基于<code>docker</code> –<code>docker-compose</code> – <code>make</code>来搭建我们的环境，其原理如下图所示：</p><p><img src="imgs/动手实践全景图像语义分割/image-20210815194243532.png" alt="环境构建原理图" style="zoom: 33%;" /></p><p><code>docker</code> –<code>docker-compose</code> – <code>make</code>三个工具对应三个配置文件，都在项目根目录进行了声明：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Dockerfile</span><br><span class="line">docker-compose.yml</span><br><span class="line">Makefile</span><br></pre></td></tr></table></figure><p>其中</p><ul><li><code>Dockerfile</code> 定义了实验所需要的所有环境，依据此文件可以编译成docker镜像，其中包含我们需要的库</li><li><code>docker-compose.yml</code>定义了镜像的启动方式，在本文中，我们定义两个服务，一个作为终端来运行命令，一个作为<code>jupyter lab</code>供调试</li><li><code>Makefile</code>定义了启动环境的方式</li></ul><p>本文实验环境</p><ul><li>Ubuntu20.04</li><li>CUDA11.0</li><li>Pytorch1.7</li></ul><h3 id="docker安装">Docker安装</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1.安装docker</span></span><br><span class="line">sudo apt install -y docker docker.io</span><br><span class="line"><span class="comment"># 2.安装英伟达docker</span></span><br><span class="line">distribution=$(. /etc/os-release;<span class="built_in">echo</span> $ID<span class="variable">$VERSION_ID</span>) \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - \</span><br><span class="line">&amp;&amp; curl -s -L https://nvidia.github.io/nvidia-docker/<span class="variable">$distribution</span>/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install -y nvidia-docker2</span><br><span class="line"><span class="comment"># 3.安装docker-compose(apt常常不能安装最新版本的docker-compose)</span></span><br><span class="line">pip install docker-compose</span><br><span class="line"><span class="comment"># 4.解决linux下docker的权限问题，将用户放在docker组里</span></span><br><span class="line">GROUPNAME=docker</span><br><span class="line">getent group <span class="variable">$GROUPNAME</span> 2&gt;&amp;1 &gt;/dev/null || groupadd <span class="variable">$GROUPNAME</span></span><br><span class="line">sudo usermod -aG docker $(whoami)</span><br><span class="line"><span class="comment"># 5.重启</span></span><br><span class="line">sudo systemctl daemon-reload</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h3 id="使用docker镜像">使用Docker镜像</h3><p>Docker镜像构建好之后，可以直接运行docker命令启动镜像，但是这样不是最方便的。使用<code>docker-compose</code>搭配<code>Makefile</code>，具体操作如下：首先写好<code>docker-compose.yml</code>启动文件，可参考本项目对应的<a href="https://github.com/QiangZiBro/spherical_image_segmentation_tutorial/blob/main/docker-compose.yml">docker-compose.yml</a>，接着，在Makefile里写常见docker相关命令，我们将应用分为启动（up）、关闭（down）、进入容器环境（in）三个需求，Makefile如下：</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">up:</span></span><br><span class="line">docker-compose up -d</span><br><span class="line"></span><br><span class="line"><span class="section">down:</span></span><br><span class="line">docker-compose down</span><br><span class="line"></span><br><span class="line"><span class="section">in:</span></span><br><span class="line">docker-compose exec spherical-env bash</span><br></pre></td></tr></table></figure><p>本项目镜像已上传dockerhub，可以直接使用下列命令下载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker pull qiangzibro/spherical_image_segmentation</span><br><span class="line"><span class="comment"># 或者使用下面命令自己编译</span></span><br><span class="line">make build</span><br></pre></td></tr></table></figure><p>接着，一键完成编译、启动</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make up <span class="comment">#等价于 docker-compose up -d</span></span><br></pre></td></tr></table></figure><p>再通过下列命令便可以进入终端</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make <span class="keyword">in</span></span><br></pre></td></tr></table></figure><p>使用<code>docker-compose logs</code>可以看到notebook对应的网址</p><h2 id="数据获取">数据获取</h2><p>使用<strong>2D-3D-S 数据集</strong>进行本实验，该数据集提供了来自 2D、2.5D 和 3D 域的各种相互注册的数据，以及实例级语义和几何注释。 它收集在来自 3 座不同建筑的 6 个大型室内区域。 它包含超过 70,000 张 RGB 图像，以及相应的深度、表面法线、语义注释、全局 XYZ 图像（均以常规和 360° 等距柱状图图像的形式）以及相机信息。 它还包括注册的原始和语义注释 3D 网格和点云。</p><p>使用国内数据集网站：https://gas.graviti.cn/，这个网站汇总了AI开发者常见的公开数据集，更方便的是，我们能通过命令上传、下载数据集。对于发布在网站上的数据集，fork后还可以通过命令行进行下载。</p><ol type="a"><li><p>打开本文对应数据集链接 https://gas.graviti.cn/dataset/qiangzibro/spherical_segmentation</p></li><li><p>右上角注册登录</p></li><li><p>fork数据集</p></li></ol><figure><img src="imgs/动手实践全景图像语义分割/image-20210915170201901.png" alt="" /><figcaption>image-20210915170201901</figcaption></figure><figure><img src="imgs/动手实践全景图像语义分割/image-20210915170228705.png" alt="" /><figcaption>image-20210915170228705</figcaption></figure><ol start="4" type="a"><li>点击网页上方开发者工具，获取使用SDK所需的AccessKey，获取到 AccessKey 后，将其存在项目根目录的<code>gas_key.py</code>里：</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">KEY = <span class="string">&quot;&lt;Your-Key&gt;&quot;</span></span><br></pre></td></tr></table></figure><p>然后即可以通过AccessKey可以上传数据、读取数据、使用数据，灵活对接模型开发和训练，与数据pipeline快速集成。</p><ol start="5" type="a"><li>AccessKey写入后就可以写代码读取数据了，读完了一行下载代码就可以进行下载。将下载后的数据放在<code>data</code>文件夹下。</li></ol><h2 id="方法">方法</h2><p>使用多种二维CNN方法和球面卷积方法UGSCNN。其中，二维CNN有三种：</p><ul><li>UNet</li><li>ResNet</li><li>FCN</li></ul><p>UGSCNN[3]参考自论文《Spherical CNNs on Unstructured Grids》，下面着重看一下UGSCNN的方法。MeshConv对卷积算子进行定义：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MeshConv</span>(<span class="params">_MeshConv</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, in_channels, out_channels, mesh_file, stride=<span class="number">1</span>, bias=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MeshConv, self).__init__(in_channels, out_channels, mesh_file, stride, bias)</span><br><span class="line">        pkl = self.pkl</span><br><span class="line">        <span class="keyword">if</span> stride == <span class="number">2</span>:</span><br><span class="line">            self.nv_prev = pkl[<span class="string">&#x27;nv_prev&#x27;</span>]</span><br><span class="line">            L = sparse2tensor(pkl[<span class="string">&#x27;L&#x27;</span>].tocsr()[:self.nv_prev].tocoo()) <span class="comment"># laplacian matrix V-&gt;V</span></span><br><span class="line">            F2V = sparse2tensor(pkl[<span class="string">&#x27;F2V&#x27;</span>].tocsr()[:self.nv_prev].tocoo())  <span class="comment"># F-&gt;V, #V x #F</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="comment"># stride == 1</span></span><br><span class="line">            self.nv_prev = pkl[<span class="string">&#x27;V&#x27;</span>].shape[<span class="number">0</span>]</span><br><span class="line">            L = sparse2tensor(pkl[<span class="string">&#x27;L&#x27;</span>].tocoo())</span><br><span class="line">            F2V = sparse2tensor(pkl[<span class="string">&#x27;F2V&#x27;</span>].tocoo())</span><br><span class="line">        self.register_buffer(<span class="string">&quot;L&quot;</span>, L)</span><br><span class="line">        self.register_buffer(<span class="string">&quot;F2V&quot;</span>, F2V)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, <span class="built_in">input</span></span>):</span></span><br><span class="line">        <span class="comment"># compute gradient</span></span><br><span class="line">        grad_face = spmatmul(<span class="built_in">input</span>, self.G)</span><br><span class="line">        grad_face = grad_face.view(*(<span class="built_in">input</span>.size()[:<span class="number">2</span>]), <span class="number">3</span>, -<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>) <span class="comment"># gradient, 3 component per face</span></span><br><span class="line">        laplacian = spmatmul(<span class="built_in">input</span>, self.L)</span><br><span class="line">        identity = <span class="built_in">input</span>[..., :self.nv_prev]</span><br><span class="line">        grad_face_ew = torch.<span class="built_in">sum</span>(torch.mul(grad_face, self.EW), keepdim=<span class="literal">False</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        grad_face_ns = torch.<span class="built_in">sum</span>(torch.mul(grad_face, self.NS), keepdim=<span class="literal">False</span>, dim=-<span class="number">1</span>)</span><br><span class="line">        grad_vert_ew = spmatmul(grad_face_ew, self.F2V)</span><br><span class="line">        grad_vert_ns = spmatmul(grad_face_ns, self.F2V)</span><br><span class="line"></span><br><span class="line">        feat = [identity, laplacian, grad_vert_ew, grad_vert_ns]</span><br><span class="line"></span><br><span class="line">        out = torch.stack(feat, dim=-<span class="number">1</span>)</span><br><span class="line">        out = torch.<span class="built_in">sum</span>(torch.<span class="built_in">sum</span>(torch.mul(out.unsqueeze(<span class="number">1</span>), self.coeffs.unsqueeze(<span class="number">2</span>)), dim=<span class="number">2</span>), dim=-<span class="number">1</span>)</span><br><span class="line">        out += self.bias.unsqueeze(-<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure><p>基于MeshConv算子构建了一个Unet形式的分割网络：</p><p><img src="imgs/动手实践全景图像语义分割/image-20210727184927162.png" alt="image-20210727184927162" style="zoom:50%;" /></p><h2 id="训练">训练</h2><p>环境构建好后只需简单的几个命令便可以运行起来</p><figure><img src="imgs/动手实践全景图像语义分割/env-9114978.gif" alt="" /><figcaption>env-9114978</figcaption></figure><p>在使用<code>make in</code>成功进入到容器终端</p><ul><li>基于CNN对网格进行分割</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> cnns</span><br><span class="line"><span class="comment"># 基于</span></span><br><span class="line">./run.sh UNet</span><br><span class="line"><span class="comment"># 基于FCN</span></span><br><span class="line">./run.sh FCN8s</span><br><span class="line"><span class="comment"># 基于ResNetDUCHDC</span></span><br><span class="line">./run.sh ResNetDUCHDC</span><br></pre></td></tr></table></figure><p>脚本<code>run.sh</code>解释</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Model choice</span></span><br><span class="line"><span class="comment"># ResNetDUCHDC,FCN8s,UNet</span></span><br><span class="line"><span class="comment"># Run example</span></span><br><span class="line"><span class="comment"># 1) ./run.sh</span></span><br><span class="line"><span class="comment"># 2) ./run.sh FCN8s</span></span><br><span class="line"><span class="comment"># 3) ./run.sh ResNetDUCHDC</span></span><br><span class="line">model=<span class="string">&quot;<span class="variable">$&#123;1:-UNet&#125;</span>&quot;</span></span><br><span class="line">MESHFILES=../data/mesh_files</span><br><span class="line">DATADIR=../data/2d3ds_pano_small/</span><br><span class="line"><span class="comment"># create log directory</span></span><br><span class="line">mkdir -p logs</span><br><span class="line"></span><br><span class="line">python train.py \</span><br><span class="line">--batch-size 16 \ <span class="comment"># 训练批量大小</span></span><br><span class="line">--test-batch-size 16 \ <span class="comment">#测试批量大小</span></span><br><span class="line">--epochs 200 \ <span class="comment"># 训练epoch数量</span></span><br><span class="line">--data_folder <span class="variable">$DATADIR</span> \</span><br><span class="line">--mesh_folder <span class="variable">$MESHFILES</span> \ <span class="comment"># 正二十面体网格文件位置</span></span><br><span class="line">--fold 3 \ <span class="comment"># K-fold交叉验证，k=3。将原始数据分成K组(K-Fold)，将每个子集数据分别做一次验证集，其余的K-1组子集数据作为训练集，这样会得到K个模型。这K个模型分别在验证集中评估结果，最后的误差MSE(Mean Squared Error)加和平均就得到交叉验证误差。交叉验证有效利用了有限的数据，并且评估结果能够尽可能接近模型在测试集上的表现，可以做为模型优化的指标使用。</span></span><br><span class="line">--log_dir logs/log_<span class="variable">$&#123;model&#125;</span>_f16_cv3_rgbd \ <span class="comment"># 日志目录</span></span><br><span class="line">--decay \ <span class="comment"># 学习率衰减</span></span><br><span class="line">--train_stats_freq 5 \</span><br><span class="line">--model <span class="variable">$&#123;model&#125;</span> \ <span class="comment">#模型选择</span></span><br><span class="line">--in_ch rgbd \ <span class="comment"># 输入数据通道</span></span><br><span class="line">--lr 1e-3 \ <span class="comment"># 学习路</span></span><br><span class="line">--feat 16 <span class="comment">#特征层的数量</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>基于UGSCNN对球面数据进行分割</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> ugscnn</span><br><span class="line">./run.sh</span><br></pre></td></tr></table></figure><p>训练200个epoch后，可得如下结果：</p><figure><img src="imgs/动手实践全景图像语义分割/image-20210727204519252.png" alt="" /><figcaption>image-20210727204519252</figcaption></figure><h2 id="测试">测试</h2><p>使用提供的测试脚本<code>test.sh</code>即可进行测试</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于UNet</span></span><br><span class="line">./test.sh UNet</span><br><span class="line"><span class="comment"># 基于FCN</span></span><br><span class="line">./test.sh FCN8s</span><br><span class="line"><span class="comment"># 基于ResNetDUCHDC</span></span><br><span class="line">./test.sh ResNetDUCHDC</span><br></pre></td></tr></table></figure><p>测试结果保存在当前目录下，命名格式为<code>模型名</code>+<code>.npz</code>，将其打开进行结果分析：</p><p>全景图实例</p><p><img src="imgs/动手实践全景图像语义分割/image-20210816180457180.png" alt="image-20210816180457180" style="zoom:33%;" /></p><p>结果</p><figure><img src="imgs/动手实践全景图像语义分割/image-20210816190643319.png" alt="" /><figcaption>image-20210816190643319</figcaption></figure><p>更多结果欢迎打开<a href="https://github.com/QiangZiBro/spherical_image_segmentation_tutorial/blob/main/spherical_image_segmentation.ipynb">spherical_image_segmentation.ipynb</a> 来动手体验吧！</p><h2 id="总结">总结</h2><p>本文介绍了docker作为环境构建的知识，介绍几种基于传统CNN方法和一种基于球面CNN的方法，并将上述方法在全景数据集上完成了分割任务。</p><h2 id="参考资料">参考资料</h2><p>[ 1 ] : https://www.bilibili.com/video/BV1NT4y1w7cy?from=search&amp;seid=10079355191633664125</p><p>[ 2 ] : https://mp.weixin.qq.com/s/RZqa9aNgK--7pnkJHV1cAw</p><p>[ 3 ] : https://gas.graviti.cn/</p><p>[ 4 ] :https://github.com/maxjiang93/ugscnn/</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;导读&quot;&gt;导读&lt;/h2&gt;
&lt;p&gt;相信许多读者体验过b站上的全景视频，如果还没有，快来体验一下吧[1]！只需鼠标点击并移动，便可360度无死角的浏览全景视频。全景图像，又称360°全景图，其数据分布在球面空间上。如下图所示，如果将全景图像展开则会造成畸变，因此，直接将传统二维平面图像处理方法应用到球面数据上，其效果则会大大降低。要解决分布在球面空间上的数据，需要特定的方法，比如球面卷积网络。本文手把手带你实践一个有趣的应用——全景图像语义分割，并对多种传统CNN方法和球面CNN方法进行对比。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Tutorial" scheme="https://qiangzibro.com/tags/Tutorial/"/>
    
    <category term="Docker" scheme="https://qiangzibro.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>动手实现胶囊网络</title>
    <link href="https://qiangzibro.com/2021/09/17/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C/"/>
    <id>https://qiangzibro.com/2021/09/17/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0%E8%83%B6%E5%9B%8A%E7%BD%91%E7%BB%9C/</id>
    <published>2021-09-16T16:45:58.000Z</published>
    <updated>2021-09-17T14:16:13.106Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言">前言</h1><p>2017年，Hinton团队提出胶囊网络，首次将标量型网络扩展到矢量，并运用动态路由方式来进行胶囊之间的传递计算。提出的矢量神经元被认为具有保留物体姿态的能力，为神经网络带来了等变性(equivariance)。本着learning by doing的态度，笔者尝试对这一篇论文进行复现。本文不会对其原论文原理和思想有太多解释。在保证工程性和完整性的同时，尽可能记录自己在实现过程中的总结和反思。Anyway，实现过程也许会有一些bug，欢迎交流和提交issue~</p><span id="more"></span><blockquote><p><strong>Author</strong>: QiangZiBro.<br /><strong>Github</strong>: https://github/QiangZiBro.</p><p><strong>本文notebook地址</strong>：https://github.com/QiangZiBro/capsule_networks_play_ground/blob/main/capsule_networks/notebooks/caps_v2017.ipynb.</p></blockquote><h1 id="基础模块实现">基础模块实现</h1><h2 id="引入必备的库">引入必备的库</h2><p>本文依赖第三方框架pytorch，实验使用1.2，基本来说各个版本都可以用。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.utils <span class="keyword">import</span> save_image</span><br></pre></td></tr></table></figure><h2 id="超参数定义">超参数定义</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Hyper-parameters</span></span><br><span class="line">num_epochs = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">learning_rate = <span class="number">1e-3</span></span><br></pre></td></tr></table></figure><h2 id="数据加载">数据加载</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># MNIST dataset</span></span><br><span class="line">root=<span class="string">&quot;/home/qiangzibro/2TB1/&quot;</span></span><br><span class="line">train_dataset = torchvision.datasets.MNIST(root=root,</span><br><span class="line">                                           train=<span class="literal">True</span>, </span><br><span class="line">                                           transform=transforms.ToTensor(),</span><br><span class="line">                                           download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_dataset = torchvision.datasets.MNIST(root=root,</span><br><span class="line">                                          train=<span class="literal">False</span>, </span><br><span class="line">                                          transform=transforms.ToTensor())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Data loader</span></span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,</span><br><span class="line">                                           batch_size=batch_size, </span><br><span class="line">                                           shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class="line">                                          batch_size=batch_size, </span><br><span class="line">                                          shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p>对MNIST图片可视化</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show_img</span>(<span class="params">data_tuple</span>):</span></span><br><span class="line">    img, label = data_tuple</span><br><span class="line">    img = img.squeeze()</span><br><span class="line">    plt.imshow(img)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;label is <span class="subst">&#123;label&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">show_img(test_dataset[<span class="number">1</span>])</span><br></pre></td></tr></table></figure><figure><img src="imgs/动手实现胶囊网络/53267F57-8828-45D7-8BE2-55D99D628B9A-20210917004648407.png" alt="" /><figcaption>img</figcaption></figure><h2 id="胶囊网络的压缩函数与动态路由算法">胶囊网络的压缩函数与动态路由算法</h2><p>胶囊网络由三层组成：卷积层，初级胶囊层，卷积胶囊层，其中卷积胶囊层使用了动态路由算法。我们来一一实现这些功能。 首先实现两个helper函数，压缩函数与动态路由算法</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">squash</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: (B, 10, 16)</span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        squashed x (B, 10, 16)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    L = torch.norm(x, dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>) <span class="comment">#(B, 10, 1)</span></span><br><span class="line">    L_square = L**<span class="number">2</span> <span class="comment">#(B, 10, 1)</span></span><br><span class="line">    c = (L_square)/(<span class="number">1</span>+L_square)/L <span class="comment">#(B, 10, 1)</span></span><br><span class="line">    </span><br><span class="line">    s = c*x <span class="comment">#(B, 10, 16)</span></span><br><span class="line">    s[s==np.nan] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> s</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">1</span>,<span class="number">10</span>,<span class="number">16</span>)</span><br><span class="line">squash(x).shape</span><br></pre></td></tr></table></figure><p>输出</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.Size([1, 10, 16])</span><br></pre></td></tr></table></figure><p>动态路由算法相当于一个聚类过程，将底层的若干个向量以迭代的路由方法，选取若干具有代表性的胶囊。</p><ul><li>输入 (B, 10, 32x6x6, 16)</li><li>输出 (B, 10, 16)</li></ul><p>要注意的细节</p><ul><li>b的维度是多少？ 注意b是有batchsize的</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dynamic_routing</span>(<span class="params">x, iterations=<span class="number">3</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: u_hat,  (B, 10, 32x6x6, 16, 1)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        v: next layer output (B, 10, 16)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    N = <span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span> <span class="comment"># previous layer</span></span><br><span class="line">    N1 = <span class="number">10</span> <span class="comment"># next layer</span></span><br><span class="line">    B = x.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    b = torch.zeros(B,N1,N,<span class="number">1</span>, <span class="number">1</span>).to(x.device)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(iterations):        </span><br><span class="line">        <span class="comment"># probability of each vector to be distributed is 1</span></span><br><span class="line">        <span class="comment"># (B,10,32*6*6,1, 1)</span></span><br><span class="line">        c = F.softmax(b, dim=<span class="number">1</span>)  </span><br><span class="line"> </span><br><span class="line">        <span class="comment"># (B,10,16)</span></span><br><span class="line">        s = torch.<span class="built_in">sum</span>(x.matmul(c), dim=<span class="number">2</span>).squeeze(-<span class="number">1</span>)</span><br><span class="line">     </span><br><span class="line">        <span class="comment"># (B,10,16)</span></span><br><span class="line">        v = squash(s)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># (B,10,32*6*6,1,1)</span></span><br><span class="line">        b = b + v[:,:,<span class="literal">None</span>,<span class="literal">None</span>,:].matmul(x)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> v</span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">1</span>,<span class="number">10</span>,<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>,<span class="number">16</span>, <span class="number">1</span>)</span><br><span class="line">dynamic_routing(x).shape</span><br></pre></td></tr></table></figure><h2 id="初级胶囊层">初级胶囊层</h2><p>在实现初级胶囊层时，我们要了解一些细节，比如</p><ul><li>怎样表示一个胶囊？ 每个像素点上一个1x8的向量</li><li>怎样计算出初级胶囊？使用32组卷积核，每组输出8个通道（256组卷积核，通道拆分32份也没有问题）</li><li>怎样在程序里存这些胶囊？我的做法是将所有的胶囊放在一列，换句话说，放在一个<code>(B, 32*6*6, 8)</code>的矩阵里面</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">PrimaryCapsuleLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.primary_capsule_layer = \</span><br><span class="line">            nn.ModuleList([nn.Conv2d(<span class="number">256</span>,<span class="number">8</span>,<span class="number">9</span>, stride=<span class="number">2</span>) <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">32</span>)])</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Produce primary capsules</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: features with (B, 256, 20, 20)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            vectors (B, 32*6*6, 8)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        capsules = [conv(x) <span class="keyword">for</span> conv <span class="keyword">in</span> self.primary_capsule_layer]  <span class="comment"># [[B, 8, 6, 6] * 32] </span></span><br><span class="line">        capsules_reshaped = [c.reshape(-<span class="number">1</span>,<span class="number">8</span>,<span class="number">6</span>*<span class="number">6</span>) <span class="keyword">for</span> c <span class="keyword">in</span> capsules]  <span class="comment"># [[B, 8, 36] * 32] </span></span><br><span class="line">        s = torch.cat(capsules_reshaped, dim=-<span class="number">1</span>).permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)  <span class="comment"># (B, 32*6*6, 8)</span></span><br><span class="line">        <span class="keyword">return</span> squash(s)</span><br><span class="line"></span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试单元</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_for_primary_capsule_layer</span>():</span></span><br><span class="line">    <span class="built_in">input</span> = torch.rand(<span class="number">1</span>,<span class="number">256</span>,<span class="number">20</span>,<span class="number">20</span>)</span><br><span class="line">    layer = PrimaryCapsuleLayer()</span><br><span class="line">    <span class="keyword">assert</span> layer(<span class="built_in">input</span>).shape == (<span class="number">1</span>,<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>, <span class="number">8</span>)</span><br><span class="line">test_for_primary_capsule_layer()</span><br></pre></td></tr></table></figure><h2 id="卷积胶囊层">卷积胶囊层</h2><blockquote><p>在实现卷积胶囊层时，我们要了解一些细节有</p><ul><li><p>高维矩阵相乘怎么进行计算？ 比如对(B, 32x6x6, 8)大小的向量矩阵，通过权重矩阵，得到输出(B,10, 32x6x6,16)的矩阵，通过下面高维矩阵相乘方式推出𝑜=𝑊𝑥o=Wx</p><ul><li>W <code>(1, 10, 32x6x6, 16, 8)</code></li><li>x <code>(B, 1,  32x6x6, 8,  1)</code></li><li>o <code>(B, 10, 32x6x6, 16, 1)</code></li></ul><p>上面两个矩阵相乘看起来有点复杂，怎么思考呢？多维矩阵的相乘可以看作最后两个维度作矩阵乘法，两个维度我们肯定很清楚，维度(a,b)和(b,c)两个矩阵相乘就是(a,c)。其他维度要么进行广播机制，要么不变。所以，从上面的维度，可以知道，前两个维度实行广播机制，第三个不变，最后两个维度的乘法也就是(16,8)和(8,1)的向量相乘，完成了变换。因此，就有了下面的例子</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">B = <span class="number">1</span></span><br><span class="line">x = torch.rand(B,<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>,<span class="number">8</span>)</span><br><span class="line">x = x[:,<span class="literal">None</span>,...,<span class="literal">None</span>]</span><br><span class="line">    </span><br><span class="line">w = torch.rand(<span class="number">1</span>,<span class="number">10</span>,<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>,<span class="number">16</span>,<span class="number">8</span>)</span><br><span class="line">w.matmul(x).shape</span><br><span class="line"><span class="comment"># torch.Size([1, 10, 1152, 16, 1])</span></span><br></pre></td></tr></table></figure></li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CapsLayer</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,nclasses=<span class="number">10</span>, out_channels_dim=<span class="number">16</span></span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.W = nn.Parameter(<span class="number">1e-3</span> * torch.randn(<span class="number">1</span>,nclasses,<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>,out_channels_dim,<span class="number">8</span>))</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Predict and routing</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: Input vectors, (B, 32*6*6, 8)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            class capsules, (B, 10, 16)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = x[:,<span class="literal">None</span>,...,<span class="literal">None</span>]</span><br><span class="line">        u_hat = self.W.matmul(x)  <span class="comment"># (B, 10, 32x6x6, 16, 1)</span></span><br><span class="line">        <span class="keyword">assert</span> u_hat.shape[<span class="number">1</span>:] == (<span class="number">10</span>, <span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>, <span class="number">16</span>, <span class="number">1</span>)</span><br><span class="line">        class_capsules = dynamic_routing(u_hat)</span><br><span class="line">        <span class="keyword">return</span> class_capsules</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_for_caps_layer</span>():</span></span><br><span class="line">    <span class="built_in">input</span> = torch.rand(<span class="number">1</span>,<span class="number">32</span>*<span class="number">6</span>*<span class="number">6</span>,<span class="number">8</span>)</span><br><span class="line">    layer = CapsLayer()</span><br><span class="line">    <span class="keyword">assert</span> layer(<span class="built_in">input</span>).shape == (<span class="number">1</span>,<span class="number">10</span>,<span class="number">16</span>)</span><br><span class="line">test_for_caps_layer()</span><br></pre></td></tr></table></figure><h2 id="胶囊网络">胶囊网络</h2><p>实现了前面必须的几层，相信胶囊网络也是非常好搭了。我们定义的胶囊网络最后输出为10个分类向量</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CapsNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv_layer = nn.Conv2d(<span class="number">1</span>,<span class="number">256</span>,<span class="number">9</span>)</span><br><span class="line">        self.primary_layer = PrimaryCapsuleLayer()</span><br><span class="line">        self.caps_layer = CapsLayer(nclasses=<span class="number">10</span>, out_channels_dim=<span class="number">16</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x : Input img, (B, 1, 28, 28)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            the class capsules, each capsule is a 16 dimension vector</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        x = self.conv_layer(x)  <span class="comment"># (B, 256, 20, 20)</span></span><br><span class="line">        x = self.primary_layer(x)  <span class="comment"># (B, 32*6*6, 8)</span></span><br><span class="line">        x = self.caps_layer(x)  <span class="comment"># (B, 10, 16)</span></span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_for_caps_net</span>():</span></span><br><span class="line">    <span class="built_in">input</span> = torch.rand(<span class="number">1</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">    model = CapsNet()</span><br><span class="line">    <span class="keyword">assert</span> model(<span class="built_in">input</span>).shape == (<span class="number">1</span>,<span class="number">10</span>,<span class="number">16</span>)</span><br><span class="line">    </span><br><span class="line">test_for_caps_net()</span><br></pre></td></tr></table></figure><h1 id="胶囊网络的分类实验">胶囊网络的分类实验</h1><h2 id="margin-loss">margin loss</h2><p>现在我们来到第一个实验，训练一个分类网络。首先了解原文提到的损失</p><p><span class="math display">\[L_{k}=T_{k} \max \left(0, m^{+}-\left\|\mathbf{v}_{k}\right\|\right)^{2}+\lambda\left(1-T_{k}\right) \max \left(0,\left\|\mathbf{v}_{k}\right\|-m^{-}\right)^{2}\]</span></p><p>这其中<span class="math inline">\(\left\|\mathbf{v}_{k}\right\|\)</span>就是胶囊网络最后输出来的分类胶囊，k表示第k个。这个式子可以理解为一个分段函数</p><p><span class="math display">\[\begin{equation}L_{k}=\left\{\begin{aligned}\max \left(0, m^{+}-\left\|\mathbf{v}_{k}\right\|\right)^{2}&amp; &amp; {第k个胶囊正确分类} \\\lambda \max \left(0,\left\|\mathbf{v}_{k}\right\|-m^{-}\right)^{2} &amp; &amp; {第k个胶囊错误分类}\end{aligned}\right.\end{equation}\]</span> 其中<span class="math inline">\(m^{+}=0.9,m^{-}=0.1, \lambda=0.5\)</span>。也就是说，分类胶囊概率（即模长）为0.9以上且分类正确的，以及概率为0.1且错误的，我们都认为是”好“的，因此训练时我们采样梯度下降到方式往这个方向靠拢。</p><blockquote><p><strong>一些细节</strong></p><ul><li>使用onehot向量T和预测胶囊模长相乘来选取正确预测的值，(1-T)和预测胶囊模长相乘来选取错误预测的值</li></ul></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">margin_loss</span>(<span class="params">y, y_hat</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        y: ground truth labels (B)</span></span><br><span class="line"><span class="string">        y_hat: class capsules with (B, 10, 16)</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Return</span></span><br><span class="line"><span class="string">        the margin loss</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    _<span class="keyword">lambda</span> = <span class="number">0.5</span></span><br><span class="line">    m_plus = <span class="number">0.9</span></span><br><span class="line">    m_minus = <span class="number">0.1</span></span><br><span class="line">    nclasses = <span class="number">10</span></span><br><span class="line">    </span><br><span class="line">    y_norm = y_hat.norm(dim=-<span class="number">1</span>) <span class="comment"># (B,10)</span></span><br><span class="line">    T = F.one_hot(y, nclasses) <span class="comment"># use it as index for right class (B,10)</span></span><br><span class="line">    T = T.<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    right = torch.<span class="built_in">max</span>(torch.zeros_like(y_norm), m_plus-y_norm*T)</span><br><span class="line">    right = right**<span class="number">2</span></span><br><span class="line">    wrong = torch.<span class="built_in">max</span>(torch.zeros_like(y_norm), y_norm*(<span class="number">1</span>-T)-m_minus)</span><br><span class="line">    wrong = _<span class="keyword">lambda</span>*wrong**<span class="number">2</span></span><br><span class="line">    <span class="keyword">return</span> torch.<span class="built_in">sum</span>(right+wrong)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_margin_loss</span>():</span></span><br><span class="line">    y = torch.randint(<span class="number">0</span>,<span class="number">10</span>,(<span class="number">20</span>,))</span><br><span class="line">    y_hat = torch.rand(<span class="number">20</span>,<span class="number">10</span>,<span class="number">16</span>)</span><br><span class="line">    <span class="built_in">print</span>(margin_loss(y,y_hat).item())</span><br></pre></td></tr></table></figure><h2 id="训练函数">训练函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">net, epochs, dataloader,reconstruction=<span class="literal">False</span>, report=<span class="number">30</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; </span></span><br><span class="line"><span class="string">    global variable:</span></span><br><span class="line"><span class="string">        - train_loader</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    net.train()</span><br><span class="line"></span><br><span class="line">    optimizer = torch.optim.Adam(net.parameters())</span><br><span class="line"></span><br><span class="line">    train_history = []</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">        t0 = time.time()</span><br><span class="line">        </span><br><span class="line">        epoch_loss = torch.tensor(<span class="number">0.</span>)</span><br><span class="line">        <span class="keyword">for</span> batch, (X_batch, y_batch) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            X_batch, y_batch = X_batch.to(device), y_batch.to(device)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> reconstruction:</span><br><span class="line">                y_hat_param = net(X_batch, y_batch)</span><br><span class="line">                loss = total_loss(X_batch, y_batch, y_hat_param)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                y_hat = net(X_batch)</span><br><span class="line">                loss = margin_loss(y_batch, y_hat)</span><br><span class="line">            epoch_loss += loss</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">        train_history.append(epoch_loss.item())</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> loss is <span class="subst">&#123;epoch_loss&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> train_history</span><br></pre></td></tr></table></figure><h2 id="实验过程">实验过程</h2><p>训练</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Start training</span></span><br><span class="line">torch.autograd.set_detect_anomaly(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">encoder = CapsNet().to(device)</span><br><span class="line">train(encoder, <span class="number">5</span>, train_loader, margin_loss, report=<span class="number">460</span>)，</span><br></pre></td></tr></table></figure><p>测试</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Test the model</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">model, test_loader</span>):</span></span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        total = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            outputs = model(images)</span><br><span class="line">            outputs = outputs.norm(dim=-<span class="number">1</span>)</span><br><span class="line">            _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">            total += labels.size(<span class="number">0</span>)</span><br><span class="line">            correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">    <span class="keyword">return</span> correct / total</span><br><span class="line"></span><br><span class="line">acc = evaluate(encoder, test_loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test Accuracy of the model on the 10000 test images: &#123;:.2f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * acc))</span><br><span class="line"><span class="comment"># Test Accuracy of the model on the 10000 test images: 98.62%</span></span><br></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>有点惊喜，训练了五个epoch，效果达到98.62%，但是每轮训练比较相对参考资料[1]花的时间更多，并且精度没有他们高，这应该与一些参数和计算细节有关，有时间研究下。</p><h1 id="重建实验">重建实验</h1><h2 id="解码器实现">解码器实现</h2><p>除了做简单的分类外，原作者对预测正确的向量进行解码，解码到图片空间。这个过程现有的实现都是用MLP来实现的。也就是说，对一个预测正确的向量(1x16)，使用<code>(16 --&gt; 28*28)</code>的解码网络即可，只是中间网络层数可能需要多一些。原文用了三个全连接层，[1] [2]给隐层size设定都是512，1024。</p><blockquote><p>这里编程的细节有</p><ul><li>运用zip来迭代两个序列</li><li>根据list来选元素: <code>class_capsules[torch.arange(B), y]</code>，参考https://discuss.pytorch.org/t/selecting-element-on-dimension-from-list-of-indexes/36319/3</li><li>在训练的时候，因为前面encoder已经训练过了，我们可以冻结掉前面编码网络参数，只训练解码网络，可以进行下列操作</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">set_parameter_requires_grad</span>(<span class="params">model, feature_extracting</span>):</span></span><br><span class="line">    <span class="keyword">if</span> feature_extracting:</span><br><span class="line">        <span class="keyword">for</span> param <span class="keyword">in</span> model.parameters():</span><br><span class="line">            param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_parameter_requires_grad(encoder, <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 对优化器</span></span><br><span class="line">optimizer = optim.Adam(</span><br><span class="line">        <span class="built_in">filter</span>(<span class="keyword">lambda</span> p: p.requires_grad, net.parameters()),</span><br><span class="line">        lr=<span class="number">0.1</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MLPDecoder</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Decode the input predicted vectors tor origin images</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Usage:</span></span><br><span class="line"><span class="string">        decoder = MLPDecoder([512, 1024], 16, (28,28))</span></span><br><span class="line"><span class="string">        reconstructed_x = decoder(selected_capsules)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, hidden, in_channels, out_shape</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.out_shape = out_shape</span><br><span class="line">        h,w = out_shape</span><br><span class="line">        out_channels = w*h</span><br><span class="line">        self.mlp = nn.Sequential(*[</span><br><span class="line">            nn.Linear(_<span class="keyword">in</span>, _out)</span><br><span class="line">            <span class="keyword">for</span> _<span class="keyword">in</span>,_out <span class="keyword">in</span> <span class="built_in">zip</span>([in_channels]+hidden, hidden+[out_channels])</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B,16)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            reconstructed images with (B,1,28,28)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B = x.shape[<span class="number">0</span>]</span><br><span class="line">        x = self.mlp(x)</span><br><span class="line">        x = x.reshape(B, <span class="number">1</span>, *self.out_shape)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test_decoder</span>():</span></span><br><span class="line">    decoder = MLPDecoder([<span class="number">512</span>, <span class="number">1024</span>], <span class="number">16</span>, (<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">    x = torch.rand(<span class="number">5</span>,<span class="number">16</span>)</span><br><span class="line">    <span class="keyword">assert</span> decoder(x).shape == (<span class="number">5</span>,<span class="number">1</span>,<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line">test_decoder()</span><br></pre></td></tr></table></figure><h2 id="自编码网络实现">自编码网络实现</h2><p>对于自编码器的设计，我们将编解码设得灵活一点，通过构造函数传入</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CapsAE</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, encoder, decoder</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.encoder = encoder</span><br><span class="line">        self.decoder = decoder</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x, y</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            x: (B, C, H, W) (B,1,28,28)</span></span><br><span class="line"><span class="string">            y: (B)</span></span><br><span class="line"><span class="string">            </span></span><br><span class="line"><span class="string">        Return:</span></span><br><span class="line"><span class="string">            reconstructed images with (B,1,28,28)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        B = x.shape[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        class_capsules = self.encoder(x)  <span class="comment"># (B, 10, 16)</span></span><br><span class="line">        selected_capsules = class_capsules[torch.arange(B), y] <span class="comment">#  (B, 16)</span></span><br><span class="line">        <span class="keyword">assert</span> selected_capsules.shape ==  (B, <span class="number">16</span>)</span><br><span class="line">        </span><br><span class="line">        reconstructed_x = self.decoder(selected_capsules)</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> class_capsules,reconstructed_x</span><br></pre></td></tr></table></figure><h2 id="损失">损失</h2><p>加上重建损失的总损失 <span class="math display">\[L_{total} = L_{margin} + 0.0005 \times L_{reconstruction}\]</span> 其中 <span class="math display">\[L_{reconstruction} = ||x - \hat{x} ||^2\]</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">total_loss</span>(<span class="params">x, y, y_hat_params, c=<span class="number">0.0005</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; marigin loss + 0.00005reconstruction loss</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        x: (B,C,H,W)</span></span><br><span class="line"><span class="string">        y: (B,)</span></span><br><span class="line"><span class="string">        y_hat_params: a tuple of (class_capsules, reconstructed_x)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    class_capsules, reconstructed_x = y_hat_params</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> margin_loss(y, class_capsules)+c*F.mse_loss(x,reconstructed_x)</span><br></pre></td></tr></table></figure><h2 id="实验过程-1">实验过程</h2><p>重新训练自编码器</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">encoder = CapsNet()</span><br><span class="line">decoder = MLPDecoder([<span class="number">512</span>, <span class="number">1024</span>], <span class="number">16</span>, (<span class="number">28</span>,<span class="number">28</span>))</span><br><span class="line">autoencoder = CapsAE(</span><br><span class="line">    encoder = encoder,</span><br><span class="line">    decoder = decoder</span><br><span class="line">).to(device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_loss = train(autoencoder, <span class="number">5</span>, train_loader, reconstruction=<span class="literal">True</span>, report=<span class="number">460</span>)</span><br></pre></td></tr></table></figure><p>对自编码器，我们从两个方面来评估：</p><ul><li>编码器的分类能力</li><li>解码器解码效果</li></ul><p>编码器的分类能力</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">acc = evaluate(encoder, test_loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test accuracy of the model on the 10000 test images of encoder in AE: &#123;:.2f&#125;%&#x27;</span>.<span class="built_in">format</span>(<span class="number">100</span> * acc))</span><br><span class="line">Test Accuracy of the model on the <span class="number">10000</span> test images of encoder <span class="keyword">in</span> AE: <span class="number">98.80</span>%</span><br></pre></td></tr></table></figure><p>解码效果</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_ae</span>(<span class="params">model, test_loader, once=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; get all reconstruction results</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model: autoencoder</span></span><br><span class="line"><span class="string">        test_loader</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">        origin images and reconstructed images (N,1,28,28)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()  <span class="comment"># eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        X_ = [] <span class="comment"># reconstructed images</span></span><br><span class="line">        X = [] <span class="comment"># origin images</span></span><br><span class="line">        <span class="keyword">for</span> images, labels <span class="keyword">in</span> test_loader:</span><br><span class="line">            images = images.to(device)</span><br><span class="line">            labels = labels.to(device)</span><br><span class="line">            _, x_ = model(images, labels)</span><br><span class="line">            X_.append(x_)</span><br><span class="line">            X.append(images)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> once:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">return</span> torch.cat(X, dim=<span class="number">0</span>),torch.cat(X_, dim=<span class="number">0</span>)</span><br></pre></td></tr></table></figure><p>计算重建</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">X,X_ =  evaluate_ae(autoencoder, test_loader, once=<span class="literal">True</span>)</span><br><span class="line">X,X_ = X.cpu(),X_.cpu()</span><br></pre></td></tr></table></figure><p>可视化展示</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">fg, axs = plt.subplots(nrows=<span class="number">2</span>, ncols=<span class="number">10</span>, gridspec_kw=&#123;<span class="string">&#x27;hspace&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;wspace&#x27;</span>: <span class="number">0.1</span>&#125;, figsize=(<span class="number">13</span>,<span class="number">5</span>))</span><br><span class="line">fg.suptitle(<span class="string">&#x27;Groundtruths - Reconstructions&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    axs[<span class="number">0</span>, i].imshow(X[i].squeeze(), cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    axs[<span class="number">1</span>, i].imshow(X_[i].squeeze(), cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    axs[<span class="number">0</span>, i].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    axs[<span class="number">1</span>, i].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><figure><img src="imgs/动手实现胶囊网络/6C85007E-CDD1-4564-884A-150A0C6ADCE9-20210917004648552.png" alt="" /><figcaption>img</figcaption></figure><h2 id="总结-1">总结</h2><ul><li>重建效果 不是特别好，和[1]相比有些糊，但是基本轮廓是重建出来了</li></ul><h1 id="探究胶囊每一位的作用">探究胶囊每一位的作用</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate_class_capsule</span>(<span class="params">model, x, y, delta=<span class="number">1</span>, dim=<span class="number">0</span>, l=<span class="number">5</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Simply adding class capsules digit from -7 to 7, to </span></span><br><span class="line"><span class="string">    see what happens about reconstruction.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        model: autoencoder</span></span><br><span class="line"><span class="string">        x: input image (B,1,28,28)</span></span><br><span class="line"><span class="string">        y</span></span><br><span class="line"><span class="string">        dim: which dim you want to research</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">    Return </span></span><br><span class="line"><span class="string">        [origin image,reconstructed_xs] [(B,1,28,28), ... ,(B,1,28,28)]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    B = x.shape[<span class="number">0</span>]</span><br><span class="line">    encoder, decoder = model.encoder, model.decoder</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():        </span><br><span class="line">        <span class="comment"># Auto encoder, but adding class capsules digit from -7 to 7 </span></span><br><span class="line">        class_capsules = encoder(x)  <span class="comment"># (B, 10, 16)</span></span><br><span class="line">        selected_capsules = class_capsules[torch.arange(B), y] <span class="comment">#  (B, 16)</span></span><br><span class="line">        <span class="keyword">assert</span> selected_capsules.shape ==  (B, <span class="number">16</span>)</span><br><span class="line">        </span><br><span class="line">        index = F.one_hot(torch.ones(<span class="number">1</span>, dtype=torch.long)*dim, num_classes=<span class="number">16</span>)</span><br><span class="line">        index = index.<span class="built_in">float</span>().to(device)</span><br><span class="line">        </span><br><span class="line">        shifted_capsules = [selected_capsules+i*delta*index <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(-l,l+<span class="number">1</span>)]</span><br><span class="line">        reconstructed_xs = [decoder(i) <span class="keyword">for</span> i <span class="keyword">in</span> shifted_capsules]</span><br><span class="line">        </span><br><span class="line">    reconstructed_xs.insert(<span class="number">0</span>, x)</span><br><span class="line">    <span class="keyword">return</span> reconstructed_xs</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">research_for_class_capsule_for</span>(<span class="params">i=<span class="number">0</span>,  delta=<span class="number">0.5</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Test class capsule dim usage for i th test image</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> X,y <span class="keyword">in</span> test_loader:</span><br><span class="line">        X,y = X[i][<span class="literal">None</span>,...].to(device),y[i][<span class="literal">None</span>,...].to(device)</span><br><span class="line">        <span class="keyword">for</span> dim <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">            result.append(</span><br><span class="line">                evaluate_class_capsule(autoencoder, X, y, delta=delta, dim=dim)</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">        </span><br><span class="line">    fg, axs = plt.subplots(nrows=<span class="number">16</span>, ncols=<span class="built_in">len</span>(result[<span class="number">0</span>]), gridspec_kw=&#123;<span class="string">&#x27;hspace&#x27;</span>: <span class="number">0</span>, <span class="string">&#x27;wspace&#x27;</span>: <span class="number">0.1</span>&#125;, figsize=(<span class="number">13</span>,<span class="number">13</span>))</span><br><span class="line">    fg.suptitle(<span class="string">f&#x27;research for each dim in capsule, delta=<span class="subst">&#123;delta&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">16</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(result[<span class="number">0</span>])):</span><br><span class="line">            axs[i, j].imshow(result[i][j].squeeze().cpu(), cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">            axs[i, j].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h2 id="部分效果">部分效果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    research_for_class_capsule_for(i, <span class="number">0.05</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    research_for_class_capsule_for(i, <span class="number">0.1</span>)</span><br></pre></td></tr></table></figure><p>！</p><figure><img src="imgs/动手实现胶囊网络/image-20201109183833560-20210917004648615.png" alt="" /><figcaption>image-20201109183833560</figcaption></figure><figure><img src="imgs/动手实现胶囊网络/image-20201109183855380-20210917004648616.png" alt="" /><figcaption>image-20201109183855380</figcaption></figure><figure><img src="imgs/动手实现胶囊网络/image-20201109185258096-20210917004648553.png" alt="" /><figcaption>image-20201109185258096</figcaption></figure><h2 id="总结-2">总结</h2><p>使用控制变量的方式观察重建出来的效果，并没有像原论文那样胶囊里每一位都明确控制一个属性，反而没太明显的变化。也许实现中仍有一些问题，欢迎有研究的朋友指正。</p><h1 id="展望和总结">展望和总结</h1><h2 id="总结-3">总结</h2><p>写了两天，写完这篇对胶囊网络的细节更加了然于心，而对胶囊是否work更加持批判的态度。</p><p>2017年胶囊网络的提出之后引出了一个新的研究方向，随即胶囊网络被用在多个领域当中，其中2017版的后续工作最多。将标量网络扩展到矢量网络在直觉上来说是一个很有潜力的方式，但实际实验上效果上并不是很好。Hinton也在最近AAAI会议的演讲称：”之前胶囊网络都是错的，忘记它们吧“，这也让矢量型网络的研究变得争议不断——矢量神经元到底能发挥多少作用，比标量神经网络优越多少，这是一个待考察的问题。</p><p>在初步的三个小实验仍有问题：</p><ul><li>在分类上，训练了五个epoch，效果达到98.62%，但是每轮训练时间相对参考资料[1]慢6倍，并且精度没有他们高，这应该与一些参数和计算细节有关，有时间研究下。</li><li>在重建上，MLP解码器效果不太好，可能是损失的占比有关？</li><li>在第三个实验，使用控制变量的方式观察重建出来的效果，并没有像原论文那样的效果——胶囊里每一位都明确控制一个属性。反而没太明显的变化。也许实现中仍有一些问题，欢迎有研究的朋友指正。</li></ul><h2 id="展望">展望</h2><p>而在具体设计中，到底怎样定义一个矢量神经元，怎样推理矢量神经元之间的关系成为了难题。后续将继续考察矢量神经元在其中的作用，分别复现2018，2019年的堆栈式胶囊编码网络（立个flag），并将算法实现的工程型进一步加强（写个小library）。</p><h1 id="参考资料">参考资料</h1><p>[1] https://github.com/gchochla/capsules-utils [2] https://github.com/gram-ai/capsule-networks</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;前言&lt;/h1&gt;
&lt;p&gt;2017年，Hinton团队提出胶囊网络，首次将标量型网络扩展到矢量，并运用动态路由方式来进行胶囊之间的传递计算。提出的矢量神经元被认为具有保留物体姿态的能力，为神经网络带来了等变性(equivariance)。本着learning by doing的态度，笔者尝试对这一篇论文进行复现。本文不会对其原论文原理和思想有太多解释。在保证工程性和完整性的同时，尽可能记录自己在实现过程中的总结和反思。Anyway，实现过程也许会有一些bug，欢迎交流和提交issue~&lt;/p&gt;</summary>
    
    
    
    
    <category term="Tutorial" scheme="https://qiangzibro.com/tags/Tutorial/"/>
    
    <category term="Capsule Network" scheme="https://qiangzibro.com/tags/Capsule-Network/"/>
    
  </entry>
  
  <entry>
    <title>动手实现《stacked capsule autoencoders》</title>
    <link href="https://qiangzibro.com/2021/09/15/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0%E3%80%8Astacked-capsule-autoencoders%E3%80%8B(%E4%B8%8A%EF%BC%89/"/>
    <id>https://qiangzibro.com/2021/09/15/%E5%8A%A8%E6%89%8B%E5%AE%9E%E7%8E%B0%E3%80%8Astacked-capsule-autoencoders%E3%80%8B(%E4%B8%8A%EF%BC%89/</id>
    <published>2021-09-15T08:59:29.000Z</published>
    <updated>2021-09-16T16:39:37.399Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>本次动手实现论文《<a href="https://arxiv.org/abs/1906.06818">stacked capsule autoencoders</a>》的pytorch版本。这篇论文的原作者开源了TensorFlow版本[1]，其细节和工程性都挺不错，是个参考的好范本（做研究建议直接参考原项目）。关于pytorch的实现，github也开源了相关例子[2,3,4]，但这些都只实现了原文第二个实验。本文是对其原文第一个实验的复现笔记，后续也计划复现第二个实验。</p><span id="more"></span><blockquote><p>全部复现代码会开源在https://github.com/QiangZiBro/stacked_capsule_autoencoders.pytorch，欢迎提issue。</p></blockquote><h3 id="复现目标">复现目标</h3><p>第一个实验</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />Set Transformer （直接使用原论文代码）</li><li><input type="checkbox" disabled="" checked="" />CCAE模型</li><li><input type="checkbox" disabled="" checked="" />高斯混合模型的编程实现</li><li><input type="checkbox" disabled="" checked="" />Concellation数据集生成</li><li><input type="checkbox" disabled="" checked="" />CCAE训练</li><li><input type="checkbox" disabled="" checked="" />可视化CCAE</li></ul><h3 id="前期准备">前期准备</h3><p>环境</p><ul><li>系统：ubuntu 18.04.04</li><li>显卡：GP100</li><li>环境管理：miniconda3</li><li>相关第三方库：pytorch1.7</li></ul><p>为了保证工程性以及少点重复工作，我们基于一个深度学习模板项目来进行本次实现。当然，为了可解释性，也会使用notebook进行相关可视化。同时会写一些必备的test case，来帮助我更加了解一些细节。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/QiangZiBro/pytorch-template</span><br><span class="line"><span class="built_in">cd</span> pytorch-template</span><br><span class="line">python new_project.py ../stacked_capsule_autoencoders.pytorch</span><br><span class="line"><span class="built_in">cd</span> ../stacked_capsule_autoencoders.pytorch</span><br><span class="line">wget https://raw.githubusercontent.com/github/gitignore/master/Python.gitignore -O .gitignore</span><br></pre></td></tr></table></figure><h2 id="模型细节">模型细节</h2><h3 id="概览">概览</h3><p>CCAE编码器为Set Transformer，解码器为mlp的自编码器，其输入是2维平面上的点集。</p><p>我们接下来总结CCAE模型的细节</p><h3 id="set-transformer">Set Transformer</h3><hr /><p>Set Transformer的编码器可以是连续的SAB或者连续的ISAB。使用ISAB的优点是其使用了诱导点<span class="math inline">\(I \in \mathbb{R}^{m \times d}\)</span>，使得计算参数比SAB更少。 <span class="math display">\[Z=\operatorname{Encoder}(X)=\operatorname{SAB}(\operatorname{SAB}(X))  \in \mathbb{R}^{n \times d}\]</span></p><p><span class="math display">\[Z=\operatorname{Encoder}(X)=\operatorname{ISAB}_{m}\left(\operatorname{ISAB}_{m}(X)\right) \in \mathbb{R}^{n \times d}\]</span></p><p>解码器 <span class="math display">\[O=\operatorname{Decoder}(Z ; \lambda)=\operatorname{rFF}\left(\operatorname{SAB}\left(\operatorname{PMA}_{k}(Z)\right)\right) \in \mathbb{R}^{k \times d}\]</span></p><hr /><p>细节部分</p><ul><li><span class="math inline">\(\operatorname{rFF}(x)\)</span> 全连接 ，具体的讲，输入<span class="math inline">\(n \times d\)</span>维，输出也是<span class="math inline">\(n \times d\)</span>维。</li><li>注意力机制：<span class="math inline">\(\operatorname{Att}(Q, K, V ; \omega)=\omega\left(Q K^{\top}\right) V \in \mathbb{R}^{n \times d_v}\)</span>，其中，<span class="math inline">\(\omega\)</span>是激活函数。</li><li>多头注意力机制</li></ul><p><span class="math display">\[\operatorname{Multihead} (Q, K, V ; \lambda, \omega) = \operatorname{concat(Z_1,…,Z_h)}W^O \in \mathbb{R}^{n \times d},\\ Z_{j}=\operatorname{Att}\left(Q W_{j}^{Q}, K W_{j}^{K}, V W_{j}^{V} ; \omega_{j}\right)​\]</span></p><ul><li><p>多头注意力模块（Multihead Attention Block） 输出维度和X维度相同 <span class="math display">\[\operatorname{MAB}(X, Y)=\operatorname{LayerNorm}(H+\operatorname{rFF}(H))\]</span> 其中<span class="math inline">\(H=\text { LayerNorm }(X+\operatorname{Multihead}(X, Y, Y ; \omega))\)</span></p></li><li><p>集合注意力模块（Set Attention Block ），计算复杂度<span class="math inline">\(\mathcal{O}\left(n^{2}\right)\)</span></p></li></ul><p><span class="math display">\[\operatorname{SAB}(X) = \operatorname{MAB}(X,X)\]</span></p><ul><li>诱导集合注意力模块（Induced Set Attention Block ）</li></ul><p><span class="math display">\[\operatorname{ISAB}_m(X)=\operatorname{MAB}(X, H) \in \mathbb{R}^{n \times d}​\]</span></p><p>​ 其中<span class="math inline">\(H=\operatorname{MAB}(I,X) \in \mathbb{R}^{m \times d}\)</span>，<span class="math inline">\(I \in \mathbb{R}^{m \times d}\)</span>为可学习参数。</p><ul><li>多头注意力机制的池化（Pooling by Multihead Attention）。池化是一种常见的聚合（aggregation）操作。上面提到，池化可以是最大或是平均。这里提出的池化是应用一个MAB在一个可学习的矩阵<span class="math inline">\(S \in \mathbb{R}^{k \times d}\)</span>上。在一些聚类任务上，<span class="math inline">\(k\)</span>设为我们需要的类别数。使用基于注意力的池化的直觉是，每个实例对target的重要性都不一样</li></ul><p><span class="math display">\[\operatorname{PMA}_{k}(Z)=\operatorname{MAB}(S, \operatorname{rFF}(Z))\]</span></p><p><span class="math display">\[H=\operatorname{SAB}\left(\operatorname{PMA}_{k}(Z)\right)\]</span></p><p>其中池化操作<span class="math inline">\(\operatorname{PMA}_{k}(Z)=\operatorname{MAB}(S, \operatorname{rFF}(Z)) \in \mathbb{R}^{k \times d}\)</span>，<span class="math inline">\(k\)</span>表示输出集合中实例的个数，<span class="math inline">\(k &lt; n\)</span>。</p><h3 id="ccae">CCAE</h3><p>对M个2维输入点组成的集合<span class="math inline">\(\mathbf{x_{1:M}}\)</span>，首先使用Set Transformer将这个集合编码为<span class="math inline">\(K\)</span>个<span class="math inline">\((2\times 2+n_c+1)\)</span>的object向量，这三个数分别表示OV矩阵大小、特殊向量（即特征）、存在概率。特殊向量的尺度是个超参，原文<span class="math inline">\(n_c=16\)</span>。 <span class="math display">\[\mathrm{OV}_{1: K}, \mathbf{c}_{1: K}, a_{1: K}=\mathrm{h}^{\mathrm{caps}}\left(\mathbf{x}_{1: M}\right) = \operatorname{SetTransformer}\left(\mathbf{x}_{1: M}\right)\]</span> 对每个object向量，取其特殊向量，通过mlp解码出<span class="math inline">\(N\)</span>个part。其中，每个part长度为<span class="math inline">\((2+1+1)\)</span>，分别为OP矩阵、存在概率、和标准差；每个object应用一个单独的mlp，mlp结构为<span class="math inline">\(n_c，128,(2+1+1)\times N\)</span>。 <span class="math display">\[\mathrm{OP}_{k, 1: N}, a_{k, 1: N}, \lambda_{k, 1: N}=\mathrm{h}_{\mathrm{k}}^{\mathrm{part}}\left(\mathbf{c}_{k}\right) = \operatorname{mlp_k}\left(\mathbf{c}_{k}\right)\]</span> 在原文例子中，<span class="math inline">\(M=3, N=4\)</span>。</p><p>每个解码出的part都可以表示一个高斯分量。CCAE处理的数据是2维平面点，因此表示的高斯分量的均值是2维，协方差矩阵大小是<span class="math inline">\(2 \times 2\)</span>的矩阵。具体的讲，由第<span class="math inline">\(i\)</span>个object产生的第<span class="math inline">\(j\)</span>个part表示的高斯分量均值为 <span class="math display">\[\mu_{k,n} = OV_k OP_{k,n}\]</span> 其中<span class="math inline">\(OV_k\)</span>是<span class="math inline">\(2 \times 2\)</span>的矩阵，<span class="math inline">\(OP_{k,n}\)</span>是长度为2的向量。而part只有一个标量的标准差<span class="math inline">\(\lambda_{k,n}\)</span>，即，原文将一个高斯分量假设为各向同性，通过标准差<span class="math inline">\(\lambda_{k,n}\)</span>计算到高斯模型的协方差矩阵： <span class="math display">\[\Sigma_{k,n} = \begin{bmatrix}\frac{1}{\lambda_{k,n}} &amp; 0\\0 &amp; \frac{1}{\lambda_{k,n}}\end{bmatrix}\]</span> 对于这个高斯分量的存在概率，表示为 <span class="math display">\[\pi_{k,n} = \frac{a_{k} a_{k, n}}{\sum_{i} a_{i} \sum_{j} a_{i, j}}\]</span> 因此，给定每个高斯模型的三个参数：均值，协方差，概率。可以得到给定数据分布在整个高斯混合模型上的估计为： <span class="math display">\[p\left(\mathbf{x}_{1: M}\right)=\prod_{m=1}^{M} \sum_{k=1}^{K} \sum_{n=1}^{N} \frac{a_{k} a_{k, n}}{\sum_{i} a_{i} \sum_{j} a_{i, j}} p\left(\mathbf{x}_{m} \mid k, n\right)\]</span> 其中，点<span class="math inline">\(\mathbf{x}_{m}\)</span>在第<span class="math inline">\(i\)</span>个object产生的第<span class="math inline">\(j\)</span>个part表示的高斯计算得到的似然值为 <span class="math display">\[p(\mathbf{x}_{m}|k,n) =  p(\mathbf{x}_{m}|\mu_{k,n} ,\Sigma_{k,n}) = \frac{1}{(2 \pi)^{D/2} |\Sigma_{k,n}|^{1/2}}\operatorname{exp}\left(\frac{1}{2} \left(\mathbf{x}_{m}-\mu_{k,n} \right)^T \Sigma_{k,n}^{-1} \left(\mathbf{x}_{m}-\mu_{k,n} \right) \right)\]</span> 最大化<span class="math inline">\(p\left(\mathbf{x}_{1: M}\right)\)</span>，求得<span class="math inline">\(\mu_{k,n},\lambda_{k,n},\pi_{k,n}\)</span>，在理论上即可得到表示这个数据分布的模型。原文使用反向传播优化参数，目标是最大化<span class="math inline">\(\operatorname{log }p\left(\mathbf{x}_{1: M}\right)\)</span>，等价于最小化<span class="math inline">\(-\operatorname{log }p\left(\mathbf{x}_{1: M}\right)\)</span>。</p><h4 id="数据集">数据集</h4><p>数据（3个集群，两个正方形，一个三角形）是在线创建的，每一次创建后被随机平移、放缩、旋转到180度，最后所有点被标准化到-1到1之间。</p><h4 id="决策">决策</h4><p>依据object $ a_{k}$和其概率最高的part <span class="math inline">\(a_{k,n}\)</span>，对每个点<span class="math inline">\(x_m\)</span>，其类别决策为<span class="math inline">\(k^{\star}=\arg \max _{k} a_{k} a_{k, n} p\left(\mathbf{x}_{m} \mid k, n\right)\)</span>。</p><h4 id="一些实现细节">一些实现细节</h4><ul><li><p><strong>多维矩阵</strong> 首先要明白将所有的part、object放在一个矩阵里，每个维度的含义。笔者设定：part为<code>(B, n_objects, n_votes, (dim_input+1+1))</code>，object为<code>(B, n_objects, dim_input**2+dim_speical_features+1)</code>。搞定这些，之后可以进行矩阵拆分，对应到原论文对应的变量里。</p></li><li><p><strong>BatchMLP</strong> 在计算object到part的解码时用到。每个object capsule需要一个单独的MLP来解码到对应的part capsule，也就是说，输入的object维度为<code>[B, n_objects, n_special_features]</code>，被多个MLP计算得到结果应该是<code>(B, n_objects, n_votes*(dim_input+1+1))</code>。pytorch里面只有单个的MLP，我们类似原作者也实现了个BatchMLP来完成这个功能。</p></li><li><p><strong>对概率的处理</strong> 对预测的<span class="math inline">\(a_k\)</span>和<span class="math inline">\(a_{k,n}\)</span>使用softmax等函数进行处理，对预测的标准差加上一个<span class="math inline">\(\epsilon=10^{-6}\)</span>防止分母为0.</p></li></ul><h2 id="代码部分">代码部分</h2><h4 id="set-transformer-1">Set Transformer</h4><p>关于Set Transformer的实现如下，笔者做了相关注释，具体每个模块实现这里不贴。简而言之，这个编码器将<code>(B, N, dim_input)</code>的输入转化为<code>(B, num_outputs, dim_output)</code>的输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> base <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> model.modules.setmodules <span class="keyword">import</span> ISAB,SAB,PMA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SetTransformer</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim_input, num_outputs, dim_output,</span></span></span><br><span class="line"><span class="params"><span class="function">            num_inds=<span class="number">32</span>, dim_hidden=<span class="number">128</span>, num_heads=<span class="number">4</span>, ln=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Set Transformer, An autoencoder model dealing with set data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input set X with N elements, each `dim_input` dimensions, output</span></span><br><span class="line"><span class="string">        `num_outputs` elements, each `dim_output` dimensions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        In short, choose:</span></span><br><span class="line"><span class="string">        N --&gt; num_outputs</span></span><br><span class="line"><span class="string">        dim_input --&gt; dim_output</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Hyper-parameters:</span></span><br><span class="line"><span class="string">            num_inds</span></span><br><span class="line"><span class="string">            dim_hidden</span></span><br><span class="line"><span class="string">            num_heads</span></span><br><span class="line"><span class="string">            ln</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dim_input: Number of dimensions of one elem in input set X</span></span><br><span class="line"><span class="string">            num_outputs: Number of output elements</span></span><br><span class="line"><span class="string">            dim_output: Number of dimensions of one elem in output set</span></span><br><span class="line"><span class="string">            num_inds: inducing points number</span></span><br><span class="line"><span class="string">            dim_hidden: output dimension of one elem of middle layer</span></span><br><span class="line"><span class="string">            num_heads: heads number of multi-heads attention in MAB</span></span><br><span class="line"><span class="string">            ln: whether to use layer norm in MAB</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(SetTransformer, self).__init__()</span><br><span class="line">        self.enc = nn.Sequential(</span><br><span class="line">                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),</span><br><span class="line">                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))</span><br><span class="line">        self.dec = nn.Sequential(</span><br><span class="line">                PMA(dim_hidden, num_heads, num_outputs, ln=ln),</span><br><span class="line">                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),</span><br><span class="line">                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),</span><br><span class="line">                nn.Linear(dim_hidden, dim_output))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            X: (B, N, dim_input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            output set with shape (B, num_outputs, dim_output)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.dec(self.enc(X))</span><br></pre></td></tr></table></figure><h4 id="ccae-1">CCAE</h4><p>编码器核心部分如下，可以看到可以类似17版那样用矢量表示胶囊，不过这里每个胶囊用三种不同意义的变量表示，因此后续处理也不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">objects = self.set_transformer(x)  <span class="comment"># (B, n_objects, dim_input**2+dim_speical_features+1)</span></span><br><span class="line">splits = [self.dim_input**<span class="number">2</span>,self.dim_input**<span class="number">2</span>+self.dim_speical_features]</span><br><span class="line">ov_matrix,special_features,presence=objects[:,:,:splits[<span class="number">0</span>]],objects[:,:,splits[<span class="number">0</span>]:splits[<span class="number">1</span>]],objects[:,:,splits[<span class="number">1</span>]:]</span><br><span class="line"></span><br><span class="line">ov_matrix = ov_matrix.reshape(B, self.n_objects, self.dim_input, self.dim_input)</span><br><span class="line">presence = F.softmax(presence, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>解码器，注意到这里使用了一个BatchMLP，即使用多个MLP对每个object的<strong>特殊向量</strong>进行解码，每个object都可以解码出若干个part。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">x = self.bmlp(x) <span class="comment"># (B, n_objects, n_votes*(dim_input+1+1))</span></span><br><span class="line">x_chunk = x.chunk(self.n_votes, dim=-<span class="number">1</span>)</span><br><span class="line">x_object_part = torch.stack(x_chunk, dim=<span class="number">2</span>) <span class="comment"># (B, n_objects, n_votes, (dim_input+1+1))</span></span><br><span class="line"></span><br><span class="line">splits = [self.dim_input, self.dim_input+<span class="number">1</span>]</span><br><span class="line">op_matrix = x_object_part[:,:,:,:splits[<span class="number">0</span>]]</span><br><span class="line">standard_deviation = x_object_part[:,:,:,splits[<span class="number">0</span>]:splits[<span class="number">1</span>]]</span><br><span class="line">presence = x_object_part[:,:,:,splits[<span class="number">1</span>]:]</span><br><span class="line">presence = F.softmax(presence, dim=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用无监督的决策方式，参考上文原理部分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (B, 1, n_objects, 1)</span></span><br><span class="line">object_presence = res_dict.object_presence[:, <span class="literal">None</span>, ...]</span><br><span class="line"><span class="comment"># (B, 1, n_objects, n_votes)</span></span><br><span class="line">part_presence = res_dict.part_presence[:, <span class="literal">None</span>, ...].squeeze(-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># (B, M, n_objects, n_votes)</span></span><br><span class="line">likelihood = res_dict.likelihood</span><br><span class="line">a_k_n_times_p = (part_presence * likelihood).<span class="built_in">max</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">expr = object_presence * a_k_n_times_p</span><br><span class="line">winners = expr.<span class="built_in">max</span>(dim=-<span class="number">2</span>)[<span class="number">1</span>].squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="数据集-1">数据集</h4><p>这里直接复用了原本数据生成代码，搭建了一个Dataloader</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CCAE_Dataloader</span>(<span class="params">BaseDataLoader</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="comment"># for dataloader</span></span></span></span><br><span class="line"><span class="params"><span class="function">            batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">            shuffle=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            validation_split=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            num_workers=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="comment"># for dataset</span></span></span></span><br><span class="line"><span class="params"><span class="function">            shuffle_corners=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            gaussian_noise=<span class="number">0.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_translation=<span class="number">1.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            rotation_percent=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            which_patterns=<span class="string">&#x27;basic&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            drop_prob=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_scale=<span class="number">3.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            min_scale=<span class="number">.1</span></span></span></span><br><span class="line"><span class="params"><span class="function">        </span>):</span></span><br><span class="line">        self.dataset = CCAE_Dataset(</span><br><span class="line">            shuffle_corners,</span><br><span class="line">            gaussian_noise,</span><br><span class="line">            max_translation,</span><br><span class="line">            rotation_percent,</span><br><span class="line">            which_patterns,</span><br><span class="line">            drop_prob,</span><br><span class="line">            max_scale,</span><br><span class="line">            min_scale</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">super</span>().__init__(self.dataset, batch_size, shuffle, validation_split, num_workers)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CCAE_Dataset</span>(<span class="params">data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">            shuffle_corners=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            gaussian_noise=<span class="number">0.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_translation=<span class="number">1.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            rotation_percent=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            which_patterns=<span class="string">&#x27;basic&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            drop_prob=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_scale=<span class="number">3.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            min_scale=<span class="number">.1</span></span></span></span><br><span class="line"><span class="params"><span class="function">        </span>):</span></span><br><span class="line">        self.shuffle_corners = shuffle_corners</span><br><span class="line">        self.scale = max_scale</span><br><span class="line">        self.gaussian_noise = gaussian_noise</span><br><span class="line">        self.max_translation = max_translation</span><br><span class="line">        self.rotation_percent = rotation_percent</span><br><span class="line">        self.which_patterns = which_patterns</span><br><span class="line">        self.drop_prob = drop_prob</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">10000</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, item</span>):</span></span><br><span class="line">        data = create_numpy(</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            self.shuffle_corners,</span><br><span class="line">            self.gaussian_noise,</span><br><span class="line">            self.max_translation,</span><br><span class="line">            self.rotation_percent,</span><br><span class="line">            self.scale,</span><br><span class="line">            self.which_patterns,</span><br><span class="line">            self.drop_prob)</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><h4 id="损失">损失</h4><p>损失函数的计算方式如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ccae_loss</span>(<span class="params">res_dict, target, epsilon = <span class="number">1e-6</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        res_dict:</span></span><br><span class="line"><span class="string">        target: input set with (B, k, dim_input)</span></span><br><span class="line"><span class="string">        epsilon: avoiding nan for reciprocal of standard deviation</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        log likelihood for input dataset(here &quot;target&quot;) , (B,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># retrieve the variable (Sorry for possible complication)</span></span><br><span class="line">    op_matrix = res_dict.op_matrix <span class="comment"># (B, n_objects, n_votes, dim_input)</span></span><br><span class="line">    ov_matrix = res_dict.ov_matrix <span class="comment"># (B, n_objects, dim_input, dim_input)</span></span><br><span class="line">    standard_deviation = res_dict.standard_deviation <span class="comment"># (B, n_objects, n_votes, 1)</span></span><br><span class="line">    object_presence = res_dict.object_presence <span class="comment"># (B, n_objects, 1)</span></span><br><span class="line">    part_presence = res_dict.part_presence  <span class="comment"># (B, n_objects, n_votes, 1)</span></span><br><span class="line">    dim_input = res_dict.dim_input</span><br><span class="line">    B, n_objects, n_votes, _ = standard_deviation.shape</span><br><span class="line">    op_matrix = op_matrix[:,:,:,:,<span class="literal">None</span>] <span class="comment"># (B, n_objects, n_votes, dim_input,1)</span></span><br><span class="line">    ov_matrix = ov_matrix[:,:,<span class="literal">None</span>,:,:] <span class="comment"># (B, n_objects, 1, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 防止分母为0</span></span><br><span class="line">    standard_deviation = epsilon + standard_deviation[<span class="literal">Ellipsis</span>, <span class="literal">None</span>]</span><br><span class="line">    <span class="comment"># 计算mu</span></span><br><span class="line">    mu = ov_matrix @ op_matrix <span class="comment"># (B, n_objects, n_votes, dim_input,1)</span></span><br><span class="line">    <span class="comment"># 计算协方差</span></span><br><span class="line">    identity = torch.eye(dim_input).repeat(B, n_objects, n_votes, <span class="number">1</span>, <span class="number">1</span>).to(standard_deviation.device)</span><br><span class="line">    sigma = identity * (<span class="number">1</span>/standard_deviation) <span class="comment"># (B, n_objects, n_votes, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算数据集（即target）在混合模型上的似然估计</span></span><br><span class="line">    <span class="comment"># (B, k, n_objects, n_votes)</span></span><br><span class="line">    gaussian_likelihood = gmm(mu, sigma).likelihood(target, object_presence=object_presence, part_presence=part_presence)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算似然估计的对数，作为损失目标</span></span><br><span class="line">    log_likelihood = torch.log(gaussian_likelihood.<span class="built_in">sum</span>((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))).mean()</span><br><span class="line">    gaussian_likelihood = gaussian_likelihood.mean()</span><br><span class="line">    res_dict.likelihood = -gaussian_likelihood</span><br><span class="line">    res_dict.log_likelihood = -log_likelihood</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res_dict</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>笔者又实现了一个高斯混合模型类来计算似然值，下面是计算损失的核心代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mu = ov_matrix @ op_matrix  <span class="comment"># (B, n_objects, n_votes, dim_input,1)</span></span><br><span class="line">identity = (</span><br><span class="line">  torch.eye(dim_input)</span><br><span class="line">  .repeat(B, n_objects, n_votes, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">  .to(standard_deviation.device)</span><br><span class="line">)</span><br><span class="line">sigma = identity * (</span><br><span class="line">  <span class="number">1</span> / standard_deviation</span><br><span class="line">)  <span class="comment"># (B, n_objects, n_votes, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (B, k, n_objects, n_votes)</span></span><br><span class="line">likelihood = gmm(mu, sigma).likelihood(</span><br><span class="line">  target, object_presence=object_presence, part_presence=part_presence</span><br><span class="line">)</span><br><span class="line">log_likelihood = torch.log(likelihood.<span class="built_in">sum</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))).mean()</span><br></pre></td></tr></table></figure><blockquote><p>后续思考，这个损失函数有点写复杂了，直接在model里算好就不需要这么多代码了。</p></blockquote><p>高斯混合模型的核心实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GuassianMixture</span>(<span class="params"><span class="built_in">object</span></span>):</span>    <span class="string">&quot;&quot;&quot;    GMM for part capsules    &quot;&quot;&quot;</span>    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, mu, sigma</span>):</span>        <span class="string">&quot;&quot;&quot;        Args:            mu: (B, n_objects, n_votes, dim_input, 1)            sigma: (B, n_objects, n_votes, dim_input, dim_input)        After initialized:            mu:   (B, 1, n_objects, n_votes, dim_input, 1)            sigma:(B, 1, n_objects, n_votes, dim_input,dim_input)            multiplier:(B, 1, n_objects, n_votes, 1, 1)        &quot;&quot;&quot;</span>        <span class="comment">#  Converse shape to        #  (Batch_size, num_of_points, num_of_objects, number_of_votes, ...)        mu = mu[:, None, ...]  # (B, 1, n_objects, n_votes, dim_input, 1)        sigma = sigma[:, None, ...]  # (B, 1, n_objects, n_votes, dim_input,dim_input)        self.sigma = sigma        self.mu = mu        self.sigma_inv = sigma.inverse()        D = self.sigma.shape[-1]        sigma_det = torch.det(sigma)  # (B, 1, n_objects, n_votes)        self.multiplier = (            1 / ((2 * math.pi) ** (D / 2) * sigma_det.sqrt())[..., None, None]        )    def likelihood(self, x, object_presence=None, part_presence=None):        diff = x - self.mu        exp_result = torch.exp(-0.5 * diff.transpose(-1, -2) @ self.sigma_inv @ diff)        denominator = object_presence.sum(dim=2, keepdim=True) * part_presence.sum(          dim=3, keepdim=True        )        exp_result = (object_presence * part_presence / denominator) * exp_result        gaussian_likelihood = self.multiplier * exp_result        return gaussian_likelihood.squeeze(-1).squeeze(-1)    def plot(self, choose):        raise NotImplemented</span></span><br></pre></td></tr></table></figure><h2 id="目前的效果">目前的效果</h2><ul><li>正确分类</li></ul><p>原数据</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20201204231106857.png" alt="" /><figcaption>image-20201204231106857</figcaption></figure><p>无监督分类结果</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20201204231147582.png" alt="" /><figcaption>image-20201204231147582</figcaption></figure><ul><li>错误分类</li></ul><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20201204231236948.png" alt="" /><figcaption>image-20201204231236948</figcaption></figure><h2 id="总结">总结</h2><p>本文使用pytorch实现了原论文第一个toy experiment，做了一个简单的展示，损失使用的是 <span class="math display">\[p\left(\mathbf{x}_{1: M}\right)=\prod_{m=1}^{M} \sum_{k=1}^{K} \sum_{n=1}^{N} \frac{a_{k} a_{k, n}}{\sum_{i} a_{i} \sum_{j} a_{i, j}} p\left(\mathbf{x}_{m} \mid k, n\right)\]</span> 未使用原文提出的sparsity loss。</p><p>工程方面</p><ul><li>参数传递的过程中，形状为1的维度应该压缩掉</li></ul><p>实验方面</p><ul><li>写了个重大BUG：BatchMLP忘记使用激活，梯度变为nan，还是对激活函数的理解程度不深，写MLP竟然忘记带了</li><li>还需要对无监督效果进行评估，</li></ul><p>TODO</p><ul><li><p>实现无监督评估方法</p></li><li><p>尝试用这个模型做指导性学习</p></li></ul><h2 id="参考资料">参考资料</h2><p>[1] https://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders</p><p>[2] https://github.com/phanideepgampa/stacked-capsule-networks</p><p>[3] https://github.com/MuhammadMomin93/Stacked-Capsule-Autoencoders-PyTorch</p><p>[4] https://github.com/Axquaris/StackedCapsuleAutoencoders</p><p>[5] Fitting a generative model using standard divergences between measures http://www.math.ens.fr/~feydy/Teaching/DataScience/fitting_a_generative_model.html</p><h2 id="前言-1">前言</h2><p>本次动手实现论文《<a href="https://arxiv.org/abs/1906.06818">stacked capsule autoencoders</a>》的pytorch版本。这篇论文的原作者开源了TensorFlow版本[1]，其细节和工程性都挺不错，是个参考的好范本（做研究建议直接参考原项目）。关于pytorch的实现，github也开源了相关例子[2,3,4]，但这些都只实现了原文第二个实验。本文是对其原文第一个实验的复现笔记，后续也计划复现第二个实验。</p><blockquote><p>全部复现代码会开源在https://github.com/QiangZiBro/stacked_capsule_autoencoders.pytorch，欢迎提issue。</p></blockquote><h3 id="复现目标-1">复现目标</h3><p>第一个实验</p><ul class="task-list"><li><input type="checkbox" disabled="" checked="" />Set Transformer （直接使用原论文代码）</li><li><input type="checkbox" disabled="" checked="" />CCAE模型</li><li><input type="checkbox" disabled="" checked="" />高斯混合模型的编程实现</li><li><input type="checkbox" disabled="" checked="" />Concellation数据集生成</li><li><input type="checkbox" disabled="" checked="" />CCAE训练</li><li><input type="checkbox" disabled="" checked="" />可视化CCAE</li></ul><h3 id="前期准备-1">前期准备</h3><p>环境</p><ul><li>系统：ubuntu 18.04.04</li><li>显卡：GP100</li><li>环境管理：miniconda3</li><li>相关第三方库：pytorch1.7</li></ul><p>为了保证工程性以及少点重复工作，我们基于一个深度学习模板项目来进行本次实现。当然，为了可解释性，也会使用notebook进行相关可视化。同时会写一些必备的test case，来帮助我更加了解一些细节。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/QiangZiBro/pytorch-template</span><br><span class="line"><span class="built_in">cd</span> pytorch-template</span><br><span class="line">python new_project.py ../stacked_capsule_autoencoders.pytorch</span><br><span class="line"><span class="built_in">cd</span> ../stacked_capsule_autoencoders.pytorch</span><br><span class="line">wget https://raw.githubusercontent.com/github/gitignore/master/Python.gitignore -O .gitignore</span><br></pre></td></tr></table></figure><h2 id="模型细节-1">模型细节</h2><h3 id="概览-1">概览</h3><p>CCAE编码器为Set Transformer，解码器为mlp的自编码器，其输入是2维平面上的点集。</p><p>我们接下来总结CCAE模型的细节</p><h3 id="set-transformer-2">Set Transformer</h3><hr /><p>Set Transformer的编码器可以是连续的SAB或者连续的ISAB。使用ISAB的优点是其使用了诱导点<span class="math inline">\(I \in \mathbb{R}^{m \times d}\)</span>，使得计算参数比SAB更少。 <span class="math display">\[Z=\operatorname{Encoder}(X)=\operatorname{SAB}(\operatorname{SAB}(X))  \in \mathbb{R}^{n \times d}\]</span></p><p><span class="math display">\[Z=\operatorname{Encoder}(X)=\operatorname{ISAB}_{m}\left(\operatorname{ISAB}_{m}(X)\right) \in \mathbb{R}^{n \times d}\]</span></p><p>解码器 <span class="math display">\[O=\operatorname{Decoder}(Z ; \lambda)=\operatorname{rFF}\left(\operatorname{SAB}\left(\operatorname{PMA}_{k}(Z)\right)\right) \in \mathbb{R}^{k \times d}\]</span></p><hr /><p>细节部分</p><ul><li><span class="math inline">\(\operatorname{rFF}(x)\)</span> 全连接 ，具体的讲，输入<span class="math inline">\(n \times d\)</span>维，输出也是<span class="math inline">\(n \times d\)</span>维。</li><li>注意力机制：<span class="math inline">\(\operatorname{Att}(Q, K, V ; \omega)=\omega\left(Q K^{\top}\right) V \in \mathbb{R}^{n \times d_v}\)</span>，其中，<span class="math inline">\(\omega\)</span>是激活函数。</li><li>多头注意力机制</li></ul><p><span class="math display">\[\operatorname{Multihead} (Q, K, V ; \lambda, \omega) = \operatorname{concat(Z_1,…,Z_h)}W^O \in \mathbb{R}^{n \times d},\\ Z_{j}=\operatorname{Att}\left(Q W_{j}^{Q}, K W_{j}^{K}, V W_{j}^{V} ; \omega_{j}\right)\]</span></p><ul><li><p>多头注意力模块（Multihead Attention Block） 输出维度和X维度相同 <span class="math display">\[\operatorname{MAB}(X, Y)=\operatorname{LayerNorm}(H+\operatorname{rFF}(H))\]</span> 其中<span class="math inline">\(H=\text { LayerNorm }(X+\operatorname{Multihead}(X, Y, Y ; \omega))\)</span></p></li><li><p>集合注意力模块（Set Attention Block ），计算复杂度<span class="math inline">\(\mathcal{O}\left(n^{2}\right)\)</span></p></li></ul><p><span class="math display">\[\operatorname{SAB}(X) = \operatorname{MAB}(X,X)\]</span></p><ul><li>诱导集合注意力模块（Induced Set Attention Block ）</li></ul><p><span class="math display">\[\operatorname{ISAB}_m(X)=\operatorname{MAB}(X, H) \in \mathbb{R}^{n \times d}​\]</span></p><p>​ 其中<span class="math inline">\(H=\operatorname{MAB}(I,X) \in \mathbb{R}^{m \times d}\)</span>，<span class="math inline">\(I \in \mathbb{R}^{m \times d}\)</span>为可学习参数。</p><ul><li>多头注意力机制的池化（Pooling by Multihead Attention）。池化是一种常见的聚合（aggregation）操作。上面提到，池化可以是最大或是平均。这里提出的池化是应用一个MAB在一个可学习的矩阵<span class="math inline">\(S \in \mathbb{R}^{k \times d}\)</span>上。在一些聚类任务上，<span class="math inline">\(k\)</span>设为我们需要的类别数。使用基于注意力的池化的直觉是，每个实例对target的重要性都不一样</li></ul><p><span class="math display">\[\operatorname{PMA}_{k}(Z)=\operatorname{MAB}(S, \operatorname{rFF}(Z))\]</span></p><p><span class="math display">\[H=\operatorname{SAB}\left(\operatorname{PMA}_{k}(Z)\right)\]</span></p><p>其中池化操作<span class="math inline">\(\operatorname{PMA}_{k}(Z)=\operatorname{MAB}(S, \operatorname{rFF}(Z)) \in \mathbb{R}^{k \times d}\)</span>，<span class="math inline">\(k\)</span>表示输出集合中实例的个数，<span class="math inline">\(k &lt; n\)</span>。</p><h3 id="ccae-2">CCAE</h3><p>对M个2维输入点组成的集合<span class="math inline">\(\mathbf{x_{1:M}}\)</span>，首先使用Set Transformer将这个集合编码为<span class="math inline">\(K\)</span>个<span class="math inline">\((2\times 2+n_c+1)\)</span>的object向量，这三个数分别表示OV矩阵大小、特殊向量（即特征）、存在概率。特殊向量的尺度是个超参，原文<span class="math inline">\(n_c=16\)</span>。 <span class="math display">\[\mathrm{OV}_{1: K}, \mathbf{c}_{1: K}, a_{1: K}=\mathrm{h}^{\mathrm{caps}}\left(\mathbf{x}_{1: M}\right) = \operatorname{SetTransformer}\left(\mathbf{x}_{1: M}\right)\]</span> 对每个object向量，取其特殊向量，通过mlp解码出<span class="math inline">\(N\)</span>个part。其中，每个part长度为<span class="math inline">\((2+1+1)\)</span>，分别为OP矩阵、存在概率、和标准差；每个object应用一个单独的mlp，mlp结构为<span class="math inline">\(n_c，128,(2+1+1)\times N\)</span>。 <span class="math display">\[\mathrm{OP}_{k, 1: N}, a_{k, 1: N}, \lambda_{k, 1: N}=\mathrm{h}_{\mathrm{k}}^{\mathrm{part}}\left(\mathbf{c}_{k}\right) = \operatorname{mlp_k}\left(\mathbf{c}_{k}\right)\]</span> 在原文例子中，<span class="math inline">\(M=3, N=4\)</span>。</p><p>每个解码出的part都可以表示一个高斯分量。CCAE处理的数据是2维平面点，因此表示的高斯分量的均值是2维，协方差矩阵大小是<span class="math inline">\(2 \times 2\)</span>的矩阵。具体的讲，由第<span class="math inline">\(i\)</span>个object产生的第<span class="math inline">\(j\)</span>个part表示的高斯分量均值为 <span class="math display">\[\mu_{k,n} = OV_k OP_{k,n}\]</span> 其中<span class="math inline">\(OV_k\)</span>是<span class="math inline">\(2 \times 2\)</span>的矩阵，<span class="math inline">\(OP_{k,n}\)</span>是长度为2的向量。而part只有一个标量的标准差<span class="math inline">\(\lambda_{k,n}\)</span>，即，原文将一个高斯分量假设为各向同性，通过标准差<span class="math inline">\(\lambda_{k,n}\)</span>计算到高斯模型的协方差矩阵： <span class="math display">\[\Sigma_{k,n} = \begin{bmatrix}\frac{1}{\lambda_{k,n}} &amp; 0\\0 &amp; \frac{1}{\lambda_{k,n}}\end{bmatrix}\]</span> 对于这个高斯分量的存在概率，表示为 <span class="math display">\[\pi_{k,n} = \frac{a_{k} a_{k, n}}{\sum_{i} a_{i} \sum_{j} a_{i, j}}\]</span> 因此，给定每个高斯模型的三个参数：均值，协方差，概率。可以得到给定数据分布在整个高斯混合模型上的估计为： <span class="math display">\[p\left(\mathbf{x}_{1: M}\right)=\prod_{m=1}^{M} \sum_{k=1}^{K} \sum_{n=1}^{N} \frac{a_{k} a_{k, n}}{\sum_{i} a_{i} \sum_{j} a_{i, j}} p\left(\mathbf{x}_{m} \mid k, n\right)\]</span> 其中，点<span class="math inline">\(\mathbf{x}_{m}\)</span>在第<span class="math inline">\(i\)</span>个object产生的第<span class="math inline">\(j\)</span>个part表示的高斯计算得到的似然值为 <span class="math display">\[p(\mathbf{x}_{m}|k,n) =  p(\mathbf{x}_{m}|\mu_{k,n} ,\Sigma_{k,n}) = \frac{1}{(2 \pi)^{D/2} |\Sigma_{k,n}|^{1/2}}\operatorname{exp}\left(\frac{1}{2} \left(\mathbf{x}_{m}-\mu_{k,n} \right)^T \Sigma_{k,n}^{-1} \left(\mathbf{x}_{m}-\mu_{k,n} \right) \right)\]</span> 最大化<span class="math inline">\(p\left(\mathbf{x}_{1: M}\right)\)</span>，求得<span class="math inline">\(\mu_{k,n},\lambda_{k,n},\pi_{k,n}\)</span>，在理论上即可得到表示这个数据分布的模型。原文使用反向传播优化参数，目标是最大化<span class="math inline">\(\operatorname{log }p\left(\mathbf{x}_{1: M}\right)\)</span>，等价于最小化<span class="math inline">\(-\operatorname{log }p\left(\mathbf{x}_{1: M}\right)\)</span>。</p><h4 id="数据集-2">数据集</h4><p>数据（3个集群，两个正方形，一个三角形）是在线创建的，每一次创建后被随机平移、放缩、旋转到180度，最后所有点被标准化到-1到1之间。</p><h4 id="决策-1">决策</h4><p>依据object $ a_{k}$和其概率最高的part <span class="math inline">\(a_{k,n}\)</span>，对每个点<span class="math inline">\(x_m\)</span>，其类别决策为<span class="math inline">\(k^{\star}=\arg \max _{k} a_{k} a_{k, n} p\left(\mathbf{x}_{m} \mid k, n\right)\)</span>。</p><h4 id="一些实现细节-1">一些实现细节</h4><ul><li><p><strong>多维矩阵</strong> 首先要明白将所有的part、object放在一个矩阵里，每个维度的含义。笔者设定：part为<code>(B, n_objects, n_votes, (dim_input+1+1))</code>，object为<code>(B, n_objects, dim_input**2+dim_speical_features+1)</code>。搞定这些，之后可以进行矩阵拆分，对应到原论文对应的变量里。</p></li><li><p><strong>BatchMLP</strong> 在计算object到part的解码时用到。每个object capsule需要一个单独的MLP来解码到对应的part capsule，也就是说，输入的object维度为<code>[B, n_objects, n_special_features]</code>，被多个MLP计算得到结果应该是<code>(B, n_objects, n_votes*(dim_input+1+1))</code>。pytorch里面只有单个的MLP，我们类似原作者也实现了个BatchMLP来完成这个功能。</p></li><li><p><strong>对概率的处理</strong> 对预测的<span class="math inline">\(a_k\)</span>和<span class="math inline">\(a_{k,n}\)</span>使用softmax等函数进行处理，对预测的标准差加上一个<span class="math inline">\(\epsilon=10^{-6}\)</span>防止分母为0.</p></li></ul><h2 id="代码部分-1">代码部分</h2><h4 id="set-transformer-3">Set Transformer</h4><p>关于Set Transformer的实现如下，笔者做了相关注释，具体每个模块实现这里不贴。简而言之，这个编码器将<code>(B, N, dim_input)</code>的输入转化为<code>(B, num_outputs, dim_output)</code>的输出。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> base <span class="keyword">import</span> BaseModel</span><br><span class="line"><span class="keyword">from</span> model.modules.setmodules <span class="keyword">import</span> ISAB,SAB,PMA</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SetTransformer</span>(<span class="params">BaseModel</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, dim_input, num_outputs, dim_output,</span></span></span><br><span class="line"><span class="params"><span class="function">            num_inds=<span class="number">32</span>, dim_hidden=<span class="number">128</span>, num_heads=<span class="number">4</span>, ln=<span class="literal">True</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Set Transformer, An autoencoder model dealing with set data</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Input set X with N elements, each `dim_input` dimensions, output</span></span><br><span class="line"><span class="string">        `num_outputs` elements, each `dim_output` dimensions.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        In short, choose:</span></span><br><span class="line"><span class="string">        N --&gt; num_outputs</span></span><br><span class="line"><span class="string">        dim_input --&gt; dim_output</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Hyper-parameters:</span></span><br><span class="line"><span class="string">            num_inds</span></span><br><span class="line"><span class="string">            dim_hidden</span></span><br><span class="line"><span class="string">            num_heads</span></span><br><span class="line"><span class="string">            ln</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            dim_input: Number of dimensions of one elem in input set X</span></span><br><span class="line"><span class="string">            num_outputs: Number of output elements</span></span><br><span class="line"><span class="string">            dim_output: Number of dimensions of one elem in output set</span></span><br><span class="line"><span class="string">            num_inds: inducing points number</span></span><br><span class="line"><span class="string">            dim_hidden: output dimension of one elem of middle layer</span></span><br><span class="line"><span class="string">            num_heads: heads number of multi-heads attention in MAB</span></span><br><span class="line"><span class="string">            ln: whether to use layer norm in MAB</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="built_in">super</span>(SetTransformer, self).__init__()</span><br><span class="line">        self.enc = nn.Sequential(</span><br><span class="line">                ISAB(dim_input, dim_hidden, num_heads, num_inds, ln=ln),</span><br><span class="line">                ISAB(dim_hidden, dim_hidden, num_heads, num_inds, ln=ln))</span><br><span class="line">        self.dec = nn.Sequential(</span><br><span class="line">                PMA(dim_hidden, num_heads, num_outputs, ln=ln),</span><br><span class="line">                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),</span><br><span class="line">                SAB(dim_hidden, dim_hidden, num_heads, ln=ln),</span><br><span class="line">                nn.Linear(dim_hidden, dim_output))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            X: (B, N, dim_input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            output set with shape (B, num_outputs, dim_output)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> self.dec(self.enc(X))</span><br></pre></td></tr></table></figure><h4 id="ccae-3">CCAE</h4><p>编码器核心部分如下，可以看到可以类似17版那样用矢量表示胶囊，不过这里每个胶囊用三种不同意义的变量表示，因此后续处理也不同。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">objects = self.set_transformer(x)  <span class="comment"># (B, n_objects, dim_input**2+dim_speical_features+1)</span></span><br><span class="line">splits = [self.dim_input**<span class="number">2</span>,self.dim_input**<span class="number">2</span>+self.dim_speical_features]</span><br><span class="line">ov_matrix,special_features,presence=objects[:,:,:splits[<span class="number">0</span>]],objects[:,:,splits[<span class="number">0</span>]:splits[<span class="number">1</span>]],objects[:,:,splits[<span class="number">1</span>]:]</span><br><span class="line"></span><br><span class="line">ov_matrix = ov_matrix.reshape(B, self.n_objects, self.dim_input, self.dim_input)</span><br><span class="line">presence = F.softmax(presence, dim=<span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>解码器，注意到这里使用了一个BatchMLP，即使用多个MLP对每个object的<strong>特殊向量</strong>进行解码，每个object都可以解码出若干个part。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">x = self.bmlp(x) <span class="comment"># (B, n_objects, n_votes*(dim_input+1+1))</span></span><br><span class="line">x_chunk = x.chunk(self.n_votes, dim=-<span class="number">1</span>)</span><br><span class="line">x_object_part = torch.stack(x_chunk, dim=<span class="number">2</span>) <span class="comment"># (B, n_objects, n_votes, (dim_input+1+1))</span></span><br><span class="line"></span><br><span class="line">splits = [self.dim_input, self.dim_input+<span class="number">1</span>]</span><br><span class="line">op_matrix = x_object_part[:,:,:,:splits[<span class="number">0</span>]]</span><br><span class="line">standard_deviation = x_object_part[:,:,:,splits[<span class="number">0</span>]:splits[<span class="number">1</span>]]</span><br><span class="line">presence = x_object_part[:,:,:,splits[<span class="number">1</span>]:]</span><br><span class="line">presence = F.softmax(presence, dim=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>使用无监督的决策方式，参考上文原理部分</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># (B, 1, n_objects, 1)</span></span><br><span class="line">object_presence = res_dict.object_presence[:, <span class="literal">None</span>, ...]</span><br><span class="line"><span class="comment"># (B, 1, n_objects, n_votes)</span></span><br><span class="line">part_presence = res_dict.part_presence[:, <span class="literal">None</span>, ...].squeeze(-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># (B, M, n_objects, n_votes)</span></span><br><span class="line">likelihood = res_dict.likelihood</span><br><span class="line">a_k_n_times_p = (part_presence * likelihood).<span class="built_in">max</span>(dim=-<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>]</span><br><span class="line">expr = object_presence * a_k_n_times_p</span><br><span class="line">winners = expr.<span class="built_in">max</span>(dim=-<span class="number">2</span>)[<span class="number">1</span>].squeeze(-<span class="number">1</span>)</span><br></pre></td></tr></table></figure><h4 id="数据集-3">数据集</h4><p>这里直接复用了原本数据生成代码，搭建了一个Dataloader</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CCAE_Dataloader</span>(<span class="params">BaseDataLoader</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="comment"># for dataloader</span></span></span></span><br><span class="line"><span class="params"><span class="function">            batch_size,</span></span></span><br><span class="line"><span class="params"><span class="function">            shuffle=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            validation_split=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            num_workers=<span class="number">1</span>,</span></span></span><br><span class="line"><span class="params"><span class="function"></span></span></span><br><span class="line"><span class="params"><span class="function">            <span class="comment"># for dataset</span></span></span></span><br><span class="line"><span class="params"><span class="function">            shuffle_corners=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            gaussian_noise=<span class="number">0.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_translation=<span class="number">1.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            rotation_percent=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            which_patterns=<span class="string">&#x27;basic&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            drop_prob=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_scale=<span class="number">3.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            min_scale=<span class="number">.1</span></span></span></span><br><span class="line"><span class="params"><span class="function">        </span>):</span></span><br><span class="line">        self.dataset = CCAE_Dataset(</span><br><span class="line">            shuffle_corners,</span><br><span class="line">            gaussian_noise,</span><br><span class="line">            max_translation,</span><br><span class="line">            rotation_percent,</span><br><span class="line">            which_patterns,</span><br><span class="line">            drop_prob,</span><br><span class="line">            max_scale,</span><br><span class="line">            min_scale</span><br><span class="line">        )</span><br><span class="line">        <span class="built_in">super</span>().__init__(self.dataset, batch_size, shuffle, validation_split, num_workers)</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CCAE_Dataset</span>(<span class="params">data.Dataset</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,</span></span></span><br><span class="line"><span class="params"><span class="function">            shuffle_corners=<span class="literal">True</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            gaussian_noise=<span class="number">0.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_translation=<span class="number">1.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            rotation_percent=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            which_patterns=<span class="string">&#x27;basic&#x27;</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            drop_prob=<span class="number">0.0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            max_scale=<span class="number">3.</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">            min_scale=<span class="number">.1</span></span></span></span><br><span class="line"><span class="params"><span class="function">        </span>):</span></span><br><span class="line">        self.shuffle_corners = shuffle_corners</span><br><span class="line">        self.scale = max_scale</span><br><span class="line">        self.gaussian_noise = gaussian_noise</span><br><span class="line">        self.max_translation = max_translation</span><br><span class="line">        self.rotation_percent = rotation_percent</span><br><span class="line">        self.which_patterns = which_patterns</span><br><span class="line">        self.drop_prob = drop_prob</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">10000</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, item</span>):</span></span><br><span class="line">        data = create_numpy(</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            self.shuffle_corners,</span><br><span class="line">            self.gaussian_noise,</span><br><span class="line">            self.max_translation,</span><br><span class="line">            self.rotation_percent,</span><br><span class="line">            self.scale,</span><br><span class="line">            self.which_patterns,</span><br><span class="line">            self.drop_prob)</span><br><span class="line">        <span class="keyword">return</span> data</span><br></pre></td></tr></table></figure><h4 id="损失-1">损失</h4><p>损失函数的计算方式如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ccae_loss</span>(<span class="params">res_dict, target, epsilon = <span class="number">1e-6</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        res_dict:</span></span><br><span class="line"><span class="string">        target: input set with (B, k, dim_input)</span></span><br><span class="line"><span class="string">        epsilon: avoiding nan for reciprocal of standard deviation</span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">        log likelihood for input dataset(here &quot;target&quot;) , (B,)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># retrieve the variable (Sorry for possible complication)</span></span><br><span class="line">    op_matrix = res_dict.op_matrix <span class="comment"># (B, n_objects, n_votes, dim_input)</span></span><br><span class="line">    ov_matrix = res_dict.ov_matrix <span class="comment"># (B, n_objects, dim_input, dim_input)</span></span><br><span class="line">    standard_deviation = res_dict.standard_deviation <span class="comment"># (B, n_objects, n_votes, 1)</span></span><br><span class="line">    object_presence = res_dict.object_presence <span class="comment"># (B, n_objects, 1)</span></span><br><span class="line">    part_presence = res_dict.part_presence  <span class="comment"># (B, n_objects, n_votes, 1)</span></span><br><span class="line">    dim_input = res_dict.dim_input</span><br><span class="line">    B, n_objects, n_votes, _ = standard_deviation.shape</span><br><span class="line">    op_matrix = op_matrix[:,:,:,:,<span class="literal">None</span>] <span class="comment"># (B, n_objects, n_votes, dim_input,1)</span></span><br><span class="line">    ov_matrix = ov_matrix[:,:,<span class="literal">None</span>,:,:] <span class="comment"># (B, n_objects, 1, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 防止分母为0</span></span><br><span class="line">    standard_deviation = epsilon + standard_deviation[<span class="literal">Ellipsis</span>, <span class="literal">None</span>]</span><br><span class="line">    <span class="comment"># 计算mu</span></span><br><span class="line">    mu = ov_matrix @ op_matrix <span class="comment"># (B, n_objects, n_votes, dim_input,1)</span></span><br><span class="line">    <span class="comment"># 计算协方差</span></span><br><span class="line">    identity = torch.eye(dim_input).repeat(B, n_objects, n_votes, <span class="number">1</span>, <span class="number">1</span>).to(standard_deviation.device)</span><br><span class="line">    sigma = identity * (<span class="number">1</span>/standard_deviation) <span class="comment"># (B, n_objects, n_votes, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算数据集（即target）在混合模型上的似然估计</span></span><br><span class="line">    <span class="comment"># (B, k, n_objects, n_votes)</span></span><br><span class="line">    gaussian_likelihood = gmm(mu, sigma).likelihood(target, object_presence=object_presence, part_presence=part_presence)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算似然估计的对数，作为损失目标</span></span><br><span class="line">    log_likelihood = torch.log(gaussian_likelihood.<span class="built_in">sum</span>((<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>))).mean()</span><br><span class="line">    gaussian_likelihood = gaussian_likelihood.mean()</span><br><span class="line">    res_dict.likelihood = -gaussian_likelihood</span><br><span class="line">    res_dict.log_likelihood = -log_likelihood</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res_dict</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>笔者又实现了一个高斯混合模型类来计算似然值，下面是计算损失的核心代码。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mu = ov_matrix @ op_matrix  <span class="comment"># (B, n_objects, n_votes, dim_input,1)</span></span><br><span class="line">identity = (</span><br><span class="line">  torch.eye(dim_input)</span><br><span class="line">  .repeat(B, n_objects, n_votes, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">  .to(standard_deviation.device)</span><br><span class="line">)</span><br><span class="line">sigma = identity * (</span><br><span class="line">  <span class="number">1</span> / standard_deviation</span><br><span class="line">)  <span class="comment"># (B, n_objects, n_votes, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># (B, k, n_objects, n_votes)</span></span><br><span class="line">likelihood = gmm(mu, sigma).likelihood(</span><br><span class="line">  target, object_presence=object_presence, part_presence=part_presence</span><br><span class="line">)</span><br><span class="line">log_likelihood = torch.log(likelihood.<span class="built_in">sum</span>((<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>))).mean()</span><br></pre></td></tr></table></figure><blockquote><p>后续思考，这个损失函数有点写复杂了，直接在model里算好就不需要这么多代码了。</p></blockquote><p>高斯混合模型的核心实现</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GuassianMixture</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    GMM for part capsules</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, mu, sigma</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            mu: (B, n_objects, n_votes, dim_input, 1)</span></span><br><span class="line"><span class="string">            sigma: (B, n_objects, n_votes, dim_input, dim_input)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        After initialized:</span></span><br><span class="line"><span class="string">            mu:   (B, 1, n_objects, n_votes, dim_input, 1)</span></span><br><span class="line"><span class="string">            sigma:(B, 1, n_objects, n_votes, dim_input,dim_input)</span></span><br><span class="line"><span class="string">            multiplier:(B, 1, n_objects, n_votes, 1, 1)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment">#  Converse shape to</span></span><br><span class="line">        <span class="comment">#  (Batch_size, num_of_points, num_of_objects, number_of_votes, ...)</span></span><br><span class="line"></span><br><span class="line">        mu = mu[:, <span class="literal">None</span>, ...]  <span class="comment"># (B, 1, n_objects, n_votes, dim_input, 1)</span></span><br><span class="line">        sigma = sigma[:, <span class="literal">None</span>, ...]  <span class="comment"># (B, 1, n_objects, n_votes, dim_input,dim_input)</span></span><br><span class="line"></span><br><span class="line">        self.sigma = sigma</span><br><span class="line">        self.mu = mu</span><br><span class="line">        self.sigma_inv = sigma.inverse()</span><br><span class="line">        D = self.sigma.shape[-<span class="number">1</span>]</span><br><span class="line">        sigma_det = torch.det(sigma)  <span class="comment"># (B, 1, n_objects, n_votes)</span></span><br><span class="line">        self.multiplier = (</span><br><span class="line">            <span class="number">1</span> / ((<span class="number">2</span> * math.pi) ** (D / <span class="number">2</span>) * sigma_det.sqrt())[..., <span class="literal">None</span>, <span class="literal">None</span>]</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">likelihood</span>(<span class="params">self, x, object_presence=<span class="literal">None</span>, part_presence=<span class="literal">None</span></span>):</span></span><br><span class="line">        diff = x - self.mu</span><br><span class="line">        exp_result = torch.exp(-<span class="number">0.5</span> * diff.transpose(-<span class="number">1</span>, -<span class="number">2</span>) @ self.sigma_inv @ diff)</span><br><span class="line"></span><br><span class="line">        denominator = object_presence.<span class="built_in">sum</span>(dim=<span class="number">2</span>, keepdim=<span class="literal">True</span>) * part_presence.<span class="built_in">sum</span>(</span><br><span class="line">          dim=<span class="number">3</span>, keepdim=<span class="literal">True</span></span><br><span class="line">        )</span><br><span class="line">        exp_result = (object_presence * part_presence / denominator) * exp_result</span><br><span class="line">        gaussian_likelihood = self.multiplier * exp_result</span><br><span class="line">        <span class="keyword">return</span> gaussian_likelihood.squeeze(-<span class="number">1</span>).squeeze(-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">plot</span>(<span class="params">self, choose</span>):</span></span><br><span class="line">        <span class="keyword">raise</span> <span class="literal">NotImplemented</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="目前的效果-1">目前的效果</h2><ul><li>正确分类</li></ul><p>原数据</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20201204231106857.png" alt="" /><figcaption>image-20201204231106857</figcaption></figure><p>无监督分类结果</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20201204231147582.png" alt="" /><figcaption>image-20201204231147582</figcaption></figure><ul><li>错误分类</li></ul><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20201204231236948.png" alt="" /><figcaption>image-20201204231236948</figcaption></figure><h2 id="总结-1">总结</h2><p>本文使用pytorch实现了原论文第一个toy experiment，做了一个简单的展示，损失使用的是 <span class="math display">\[p\left(\mathbf{x}_{1: M}\right)=\prod_{m=1}^{M} \sum_{k=1}^{K} \sum_{n=1}^{N} \frac{a_{k} a_{k, n}}{\sum_{i} a_{i} \sum_{j} a_{i, j}} p\left(\mathbf{x}_{m} \mid k, n\right)\]</span> 未使用原文提出的sparsity loss。</p><p>工程方面</p><ul><li>参数传递的过程中，形状为1的维度应该压缩掉</li></ul><p>实验方面</p><ul><li>写了个重大BUG：BatchMLP忘记使用激活，梯度变为nan，还是对激活函数的理解程度不深，写MLP竟然忘记带了</li><li>还需要对无监督效果进行评估，</li></ul><p>TODO</p><ul><li><p>实现无监督评估方法</p></li><li><p>尝试用这个模型做指导性学习</p></li></ul><h2 id="参考资料-1">参考资料</h2><p>[1] https://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders</p><p>[2] https://github.com/phanideepgampa/stacked-capsule-networks</p><p>[3] https://github.com/MuhammadMomin93/Stacked-Capsule-Autoencoders-PyTorch</p><p>[4] https://github.com/Axquaris/StackedCapsuleAutoencoders</p><p>[5] Fitting a generative model using standard divergences between measures http://www.math.ens.fr/~feydy/Teaching/DataScience/fitting_a_generative_model.html</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;本次动手实现论文《&lt;a href=&quot;https://arxiv.org/abs/1906.06818&quot;&gt;stacked capsule autoencoders&lt;/a&gt;》的pytorch版本。这篇论文的原作者开源了TensorFlow版本[1]，其细节和工程性都挺不错，是个参考的好范本（做研究建议直接参考原项目）。关于pytorch的实现，github也开源了相关例子[2,3,4]，但这些都只实现了原文第二个实验。本文是对其原文第一个实验的复现笔记，后续也计划复现第二个实验。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Tutorial" scheme="https://qiangzibro.com/tags/Tutorial/"/>
    
    <category term="Capsule Network" scheme="https://qiangzibro.com/tags/Capsule-Network/"/>
    
  </entry>
  
  <entry>
    <title>Hexo部署博客到多个远程主机</title>
    <link href="https://qiangzibro.com/2021/08/10/Hexo%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2%E5%88%B0%E8%BF%9C%E7%A8%8B/"/>
    <id>https://qiangzibro.com/2021/08/10/Hexo%E9%83%A8%E7%BD%B2%E5%8D%9A%E5%AE%A2%E5%88%B0%E8%BF%9C%E7%A8%8B/</id>
    <published>2021-08-10T03:12:23.000Z</published>
    <updated>2021-08-10T04:58:37.765Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>博客写完了，也许你希望将生成的静态页面放在github仓库里，亦或是自己购买的公网主机上。之前一直觉得需要使用类似webhook的方式进行更新，其实根本没有必要，直接在按hexo的要求配置即可。</p><span id="more"></span><h2 id="配置">配置</h2><p><code>rsync</code>是一个远程文件同步工具，支持增量式同步。下载其插件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install hexo-deployer-rsync --save</span><br></pre></td></tr></table></figure><p>在本地博客配置文件里编辑</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line">  <span class="attr">type:</span> <span class="string">rsync</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">&lt;host&gt;</span></span><br><span class="line">  <span class="attr">user:</span> <span class="string">&lt;user&gt;</span></span><br><span class="line">  <span class="attr">root:</span> <span class="string">&lt;root&gt;</span></span><br><span class="line">  <span class="attr">port:</span> [<span class="string">port</span>]</span><br><span class="line">  <span class="attr">delete:</span> [<span class="literal">true</span><span class="string">|false</span>]</span><br><span class="line">  <span class="attr">verbose:</span> [<span class="literal">true</span><span class="string">|false</span>]</span><br><span class="line">  <span class="attr">ignore_errors:</span> [<span class="literal">true</span><span class="string">|false</span>]</span><br></pre></td></tr></table></figure><p>可以添加多主机部署，每一个主机的<code>type</code>前面加一个<code>-</code></p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">deploy:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">git</span></span><br><span class="line">  <span class="attr">repo:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">type:</span> <span class="string">heroku</span></span><br><span class="line">  <span class="attr">repo:</span></span><br></pre></td></tr></table></figure><h2 id="实践">实践</h2><p>上述配置完毕后，使用<code>hexo g -d</code>便可以一键生成、部署到远程了。</p><h2 id="参考">参考</h2><p>[ 1 ] : <a href="https://hexo.io/docs/one-command-deployment#Rsync">https://hexo.io/docs/one-command-deployment#Rsync</a></p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;博客写完了，也许你希望将生成的静态页面放在github仓库里，亦或是自己购买的公网主机上。之前一直觉得需要使用类似webhook的方式进行更新，其实根本没有必要，直接在按hexo的要求配置即可。&lt;/p&gt;</summary>
    
    
    
    
  </entry>
  
  <entry>
    <title>分布式训练探秘——horovod</title>
    <link href="https://qiangzibro.com/2021/08/09/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8E%A2%E7%A7%98%E2%80%94%E2%80%94horovod-1/"/>
    <id>https://qiangzibro.com/2021/08/09/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E6%8E%A2%E7%A7%98%E2%80%94%E2%80%94horovod-1/</id>
    <published>2021-08-09T09:40:45.000Z</published>
    <updated>2021-09-17T14:33:11.405Z</updated>
    
    <content type="html"><![CDATA[<h2 id="前言">前言</h2><p>Horovod是Uber公司研发的分布式训练框架，今天，我们学习如何利用horovod在多台机器的多张显卡，完成分布式训练。本文介绍该框架从安装到应用的相关细节。本文以及我写的安装脚本也同步在我的github上[1]。</p><span id="more"></span><h2 id="环境">环境</h2><ul><li>Ubuntu 20.04 机器两台，ip分别是<code>192.168.3.3</code>，<code>192.168.3.4</code></li><li>Nvidia 3080Ti 每台各两张</li><li>CUDA 11.1</li><li>Miniconda3 每台机器相同的位置，相同的环境</li></ul><h2 id="安装horovod步骤">安装Horovod步骤</h2><blockquote><p>参考 https://github.com/horovod/horovod/blob/master/docs/gpus.rst</p></blockquote><h3 id="cmake">cmake</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y cmake</span><br></pre></td></tr></table></figure><h3 id="安装nccl2">安装NCCL2</h3><p>参考 https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html，一共有4步，仔细阅读下图</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20210716165354396.png" alt="" /><figcaption>image-20210716165354396</figcaption></figure><p>第1步，根据自己的环境，操作：加一个ubuntu key</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-key add /var/nccl-local-repo-ubuntu2004-2.10.3-cuda11.0/7fa2af80.pub</span><br></pre></td></tr></table></figure><p>第2步，<code>nccl-repo-&lt;version&gt;.deb</code>需要到官网 https://developer.nvidia.com/nccl下载。（注意要注册账号，NVIDIA官网很慢，梯子开全局才打开）</p><p>​ <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20210716155002045.png" alt="image-20210716155002045" /></p><p>分别选择下列项<img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20210716155142838.png" alt="5" /></p><p>下载，安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dpkg -i nccl-local-repo-ubuntu2004-2.10.3-cuda11.0_1.0-1_amd64.deb</span><br></pre></td></tr></table></figure><blockquote><p>Note：笔者在CUDA11.1的机器上安装依赖CUDA11.0的NCCL，后续horovod安装并运行成功了。</p></blockquote><p>第3、4步</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br><span class="line">sudo apt install libnccl2 libnccl-dev</span><br></pre></td></tr></table></figure><h3 id="安装mpi">安装MPI</h3><blockquote><p>到底需不需要MPI？ <a href="https://horovod.readthedocs.io/en/stable/mpi.html">这里</a>给出了答案:CPU上MPI更好， GPU上GLOO和MPI差不多。如果你不用MPI，运行时加上一个<code>--gloo</code>参数即可。</p></blockquote><p>MPI安装不是很容易，自身也具有许多issue，根据文档提示得知</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Note: Open MPI 3.1.3 has an issue that may cause hangs. The recommended fix is to downgrade to Open MPI 3.1.2 or upgrade to Open MPI 4.0.0.</span><br></pre></td></tr></table></figure><p>于是我们安装MPI 4.0.0，谷歌到它的软件包网址：https://www.open-mpi.org/software/ompi/v4.0/</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20210716171356679.png" alt="" /><figcaption>image-20210716171356679</figcaption></figure><p>点击下载或者用下列方式</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://download.open-mpi.org/release/open-mpi/v4.0/openmpi-4.0.0.tar.gz</span><br></pre></td></tr></table></figure><p>注意到<a href="https://github.com/horovod/horovod/blob/89121661a2eaa36e4fab8566bd4f84e2361f3469/docs/troubleshooting.rst#force-terminate-at-data-unpack-would-read-past-end-of-buffer">这个issue</a>，清除hwloc</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt list | grep hwloc | grep installed | awk -F<span class="string">&#x27;,&#x27;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs -I&#123;&#125; apt purge -y &#123;&#125;</span><br></pre></td></tr></table></figure><p>安装（注意安装的时候需要管理员权限）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf openmpi-4.0.0.tar.gz</span><br><span class="line"><span class="built_in">cd</span> openmpi-4.0.0</span><br><span class="line">./configure --prefix=/usr/<span class="built_in">local</span></span><br><span class="line">make all install</span><br></pre></td></tr></table></figure><p>:beers::beers: 搞定 ！</p><h3 id="pip安装horovod">pip安装horovod</h3><p>我们使用miniconda3进行环境管理，在两台机器上均进行环境安装：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">conda create -n horovod python=3.8 -y</span><br><span class="line">conda activate horovod</span><br><span class="line">conda install pytorch==1.8.0 torchvision==0.9.0 torchaudio==0.8.0 cudatoolkit=11.1 -c pytorch -c conda-forge</span><br><span class="line">pip install filelock <span class="comment"># 运行例子需要</span></span><br></pre></td></tr></table></figure><p>因为我们需要GPU版本，使用下面命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HOROVOD_GPU_OPERATIONS=NCCL pip install horovod</span><br></pre></td></tr></table></figure><p>编译花了好一会儿时间，最终安装</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20210716160517662.png" alt="" /><figcaption>image-20210716160517662</figcaption></figure><p>:beers::beers: 搞定 ！</p><h2 id="分布式训练以mnist为例">分布式训练——以MNIST为例</h2><h3 id="代码数据准备">代码、数据准备</h3><p>我们直接跑一跑Uber官方提供的<a href="https://github.com/horovod/horovod/tree/master/examples">例子</a>，再去研究相关细节</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/horovod/horovod --depth 1</span><br><span class="line"><span class="built_in">cd</span> horovod/examples/pytorch</span><br></pre></td></tr></table></figure><p>这里我们关注<code>pytorch_mnist.py</code> 这个脚本。</p><blockquote><p>这个脚本对MNIST数据集的下载有些问题，第一次运行脚本下载好之后，报了一个<code>urllib.error.HTTPError: HTTP Error 503: Service Unavailable</code>的错误，解决方法是142行的download参数设为False即可。</p></blockquote><h3 id="单机多卡运行">单机多卡运行</h3><p>在单台机器、双显卡的<strong>本机</strong>下运行:rocket::rocket:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">horovodrun -np 2 -H localhost:2 python pytorch_mnist.py</span><br></pre></td></tr></table></figure><p>成功运行，结果日志如下:beers::beers:</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20210716162636235.png" alt="" /><figcaption>image-20210716162636235</figcaption></figure><h3 id="多机多卡运行">多机多卡运行</h3><p>仍然以mnist为例，再次注意，所有机器：</p><ul><li>都安装了Horovod</li><li>anaconda安装位置、环境一样</li></ul><p>直接在其中一个ip上运行，比如<code>192.168.3.3</code>上：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">horovodrun --gloo --start-timeout 600 -np 4 -H 192.168.3.3:2,192.168.3.4:2 python pytorch_mnist.py</span><br></pre></td></tr></table></figure><h3 id="更多运行方式">更多运行方式</h3><p>除此以外，还有更多运行horovod的方法，比如</p><ul><li>Docker</li><li>K8s</li><li>Spark</li></ul><p>具体参考官方<a href="https://horovod.readthedocs.io/en/stable/summary_include.html#running-horovod">文档</a></p><h2 id="总结">总结</h2><p>本文在两台各有2张3080的机器上，实操了基于pytorch的分布式训练。在安装horovod上，如果使用GPU的话，MPI不是必须项。后续可能的博客有：</p><ul><li>horovod的框架使用，探索如何将horovod用于自己的工作上</li><li>分布式训练常见概念扫盲，了解horovod如何进行工作的</li></ul><p>这是一个自容的horovod版Hello world教程，enjoy！欢迎提出issue:beers:</p><h2 id="问题">问题</h2><ul><li><p>安装Horovod需要步骤繁多，特别是不同机器环境不同的情况，比如我发现实验室大多CUDA驱动版本为11.1，但是Horovod的依赖，NCCL，其对应的CUDA只有11.0，11.4，10.2几个选择。自己的测试，CUDA11.1，安装了依赖CUDA11.0的NCCL，Horovod安装<strong>成功</strong>。</p></li><li><p><code>ORTE_ERROR_LOG: Data unpack would read past end of buffer in file grpcomm_direct.c at line 355</code></p><p>报如下错误</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[GPU-2-3080-M5:11115] [[27185,0],1] ORTE_ERROR_LOG: Data unpack would read past end of buffer in file grpcomm_direct.c at line 355--------------------------------------------------------------------------An internal error has occurred in ORTE:[[27185,0],1] FORCE-TERMINATE AT Data unpack would read past end of buffer:-26 - error grpcomm_direct.c(359)This is something that should be reported to the developers.--------------------------------------------------------------------------</span><br></pre></td></tr></table></figure><p>解决方案：选择如下两种方式之一</p><p>（1）增加<code>—gloo</code>参数，<a href="https://github.com/horovod/horovod/issues/2156#issuecomment-668090235">参考</a></p><p>（2）hwloc版本有问题，清除（purge）掉<code>hwloc*</code>，并重新安装mpi， <a href="https://github.com/horovod/horovod/blob/master/docs/troubleshooting.rst#force-terminate-at-data-unpack-would-read-past-end-of-buffer">参考</a>。</p><p>使用如下命令可以清除已安装的hwloc库。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt list | grep hwloc | grep installed | awk -F<span class="string">&#x27;,&#x27;</span> <span class="string">&#x27;&#123;print $1&#125;&#x27;</span> | xargs -I&#123;&#125; apt purge -y &#123;&#125;</span><br></pre></td></tr></table></figure></li><li><p>到底需不需要MPI？ <a href="https://horovod.readthedocs.io/en/stable/mpi.html">这里</a>给出了答案:CPU上MPI更好， GPU上GLOO和MPI差不多</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MPI can be used as an alternative to Gloo for coordinating work between processes in Horovod. When using NCCL, performance will be similar between the two, but if you are doing CPU training, there are noticeable performance benefits to using MPI.</span><br></pre></td></tr></table></figure></li></ul><h2 id="参考">参考</h2><p>[1] https://github.com/QiangZiBro/horovod_tutorial</p><p>[2] horovod的官方教学，值得参考 https://github.com/horovod/tutorials</p>]]></content>
    
    
    <summary type="html">&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;
&lt;p&gt;Horovod是Uber公司研发的分布式训练框架，今天，我们学习如何利用horovod在多台机器的多张显卡，完成分布式训练。本文介绍该框架从安装到应用的相关细节。本文以及我写的安装脚本也同步在我的github上[1]。&lt;/p&gt;</summary>
    
    
    
    
    <category term="Pytorch" scheme="https://qiangzibro.com/tags/Pytorch/"/>
    
  </entry>
  
  <entry>
    <title>宿主机上运行Docker容器gui</title>
    <link href="https://qiangzibro.com/2021/08/09/%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%B8%8A%E8%BF%90%E8%A1%8CDocker%E5%AE%B9%E5%99%A8gui/"/>
    <id>https://qiangzibro.com/2021/08/09/%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%B8%8A%E8%BF%90%E8%A1%8CDocker%E5%AE%B9%E5%99%A8gui/</id>
    <published>2021-08-09T09:30:00.000Z</published>
    <updated>2021-09-16T16:53:49.660Z</updated>
    
    <content type="html"><![CDATA[<h1>宿主机上运行Docker容器gui</h1><h2 id="导言">导言</h2><p>问：我想在容器里运行一个带<code>cv2.show()</code>/<code>plt.show()</code>/各种图形显示的程序，该怎么做？</p><span id="more"></span><p>答：看本文即可。本文提供在Mac/Linux的docker容器里显示图形界面的方法（Windows用户默泪…抱歉笔者手边没有windows系统）</p><p>容器里没有显示屏，无法供我们运行opencv或者plt的显示，但可以通过中间程序搭起桥梁。本文相关Dockerfile，python显示文件可在https://github.com/QiangZiBro/docker-tutorial/tree/main/run_gui_from_container找到。</p><h2 id="Mac上运行的docker容器显示图像">Mac上运行的docker容器显示图像</h2><h3 id="解决方案">解决方案</h3><p>socat+xquartz，docker容器内部<code>$DISPLAY</code>设为主机ip</p><h3 id="准备工作">准备工作</h3><p>第0步，homebrew安装</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/bin/bash -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)</span>&quot;</span></span><br></pre></td></tr></table></figure><p>第1步，socat 安装，用 <strong>socat</strong> 来解决容器和 Mac 主机 GUI 的通信问题：</p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/1046925-20190824165625707-1560779550.png" alt="img" style="zoom: 25%;" /><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install socat</span><br></pre></td></tr></table></figure><p>第2步，xquartz 安装，处理 X windows system</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install xquartz</span><br></pre></td></tr></table></figure><p>安装好了之后需要<strong>注销并重新进入 Mac 主机</strong>。</p><p>第3步，xquartz 配置</p><p>重启之后我们发现有了环境变量 <code>$DISPLAY</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo $DISPLAY</span><br><span class="line">/private/tmp/com.apple.launchd.nzm51qjuIW/org.macosforge.xquartz:0</span><br></pre></td></tr></table></figure><p><strong>点击应用图标</strong>或者<strong>命令行输入</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">open -a Xquartz</span><br></pre></td></tr></table></figure><p>程序坞可以看到有一个 Xquartz 应用：</p><p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/1046925-20190824173752510-977533929.png" alt="img"></p><p>在这个应用下进行偏好设置，勾选允许从网络客户端连接：</p><p><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/1046925-20190824174022289-1832774345.png" alt="img"></p><p><strong>配置之后，此时暂时 Command+Q 退出 Xquartz 应用。</strong></p><p>第4步，Socat 配置，我们在有了 DISPLAY 环境变量之后，才会对 Socat 进行配置，输入：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">socat TCP-LISTEN:6000,reuseaddr,fork UNIX-CLIENT:\&quot;$DISPLAY\&quot;</span><br></pre></td></tr></table></figure><p><strong>注意这个进程一直是运行状态，不要中断它。</strong></p><h3 id="容器配置">容器配置</h3><p>让我们查看<strong>主机 OS 上的 IP 地址</strong>：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ifconfig | grep -Eo &#x27;inet (addr:)?([0-9]*\.)&#123;3&#125;[0-9]*&#x27;</span><br></pre></td></tr></table></figure><p>第2个是我的mac ip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">inet 127.0.0.1</span><br><span class="line">inet 192.168.3.2</span><br></pre></td></tr></table></figure><p>因此，<strong>容器内</strong>设置环境变量指向这个 IP 地址（由于退出容器后不会保存环境变量，因此每次进入容器都要执行这个命令）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export DISPLAY=192.168.3.2:0</span><br></pre></td></tr></table></figure><p>至此，如果没有问题，我们运行显示图片的程序就可以成功了。</p><p>技巧1： 在docker run 时设置环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -e DISPLAY=192.168.3.2:0 [image_id]</span><br></pre></td></tr></table></figure><p>技巧2： 在docker-compose时写入环境变量</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;3&#x27;</span></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">show_image:</span></span><br><span class="line">    <span class="attr">image:</span> [<span class="string">image_id</span>]</span><br><span class="line">    <span class="attr">command:</span> <span class="string">bash</span> <span class="string">-c</span> <span class="string">&quot;python main.py&quot;</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&quot;DISPLAY=192.168.3.2:0&quot;</span></span><br></pre></td></tr></table></figure><h2 id="Linux上运行的docker容器显示图像">Linux上运行的docker容器显示图像</h2><h3 id="解决方案-2">解决方案</h3><p>运行docker时共享<code>/tmp/.X11-unix</code>这个文件夹</p><h3 id="准备工作-2">准备工作</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#安装xserver</span></span><br><span class="line">sudo apt install x11-xserver-utils</span><br><span class="line"><span class="comment">#许可所有用户都可访问xserver    注意加号前应有空格</span></span><br><span class="line">xhost +</span><br><span class="line"><span class="comment"># 查看当前显示的环境变量值 (要在显示屏查看，其他ssh终端不行) </span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$DISPLAY</span> </span><br></pre></td></tr></table></figure><p>我的是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:11.0</span><br></pre></td></tr></table></figure><h3 id="容器配置-2">容器配置</h3><p>使用image创建docker容器时，通过-v参数设置docker内外路径挂载，使显示xserver设备的socket文件在docker内也可以访问。并通过-e参数设置docker内的DISPLAY参数和宿主机一致。</p><p>技巧1：在创建docker容器时，添加选项如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-v /tmp/.X11-unix:/tmp/.X11-unix</span><br><span class="line">-e DISPLAY=:11.0</span><br><span class="line"><span class="comment">#例如：</span></span><br><span class="line">docker run -itd --name 容器名 -h 容器主机名 --privileged \</span><br><span class="line">           -v /tmp/.X11-unix:/tmp/.X11-unix  \</span><br><span class="line">           -e DISPLAY=:11.0 镜像名或id /bin/bash</span><br></pre></td></tr></table></figure><p>技巧2： 使用docker-compose</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">version: <span class="string">&#x27;3&#x27;</span></span><br><span class="line">services:</span><br><span class="line">  show_image:</span><br><span class="line">    image: show_image_docker</span><br><span class="line">    volumes:</span><br><span class="line">        - /tmp/.X11-unix:/tmp/.X11-unix</span><br><span class="line">    <span class="built_in">command</span>: bash -c <span class="string">&quot;python main.py&quot;</span></span><br><span class="line">    environment:</span><br><span class="line">      - <span class="string">&quot;DISPLAY=:0&quot;</span></span><br></pre></td></tr></table></figure><h2 id="运行Github例子">运行Github例子</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 做好上述准备工作</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/QiangZiBro/docker-tutorial</span><br><span class="line"><span class="built_in">cd</span> docker-tutorial/run_gui_from_container</span><br><span class="line">bash setup.sh <span class="comment"># 生成docker-compose.yml文件</span></span><br><span class="line">make build</span><br><span class="line">make up</span><br></pre></td></tr></table></figure><h2 id="参考资料">参考资料</h2><p>[ 1 ] : <a href="https://www.cnblogs.com/noluye/p/11405358.html">https://www.cnblogs.com/noluye/p/11405358.html</a></p><p>[ 2 ] : <a href="https://blog.csdn.net/a806689294/article/details/111462627">https://blog.csdn.net/a806689294/article/details/111462627</a></p>]]></content>
    
    
    <summary type="html">&lt;h1&gt;宿主机上运行Docker容器gui&lt;/h1&gt;
&lt;h2 id=&quot;导言&quot;&gt;导言&lt;/h2&gt;
&lt;p&gt;问：我想在容器里运行一个带&lt;code&gt;cv2.show()&lt;/code&gt;/&lt;code&gt;plt.show()&lt;/code&gt;/各种图形显示的程序，该怎么做？&lt;/p&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="https://qiangzibro.com/tags/Linux/"/>
    
    <category term="Docker" scheme="https://qiangzibro.com/tags/Docker/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu深度学习环境构建</title>
    <link href="https://qiangzibro.com/2021/08/09/Ubuntu-install/"/>
    <id>https://qiangzibro.com/2021/08/09/Ubuntu-install/</id>
    <published>2021-08-09T07:16:47.000Z</published>
    <updated>2021-09-16T16:54:23.937Z</updated>
    
    <content type="html"><![CDATA[<h1 id="零前言">零、前言</h1><blockquote><p>本文总结了在Ubuntu上的深度学习环境配置方法，大部分可类比到其他机型、系统上。尽管笔者装过不少系统，但鲜有总结方法经验。之前即没有形成一个体系成笔记记录下来，也没有形成自己的dotfiles使得能方便地移植到其他环境中。这造成的结果就是，每次换系统都要花大量时间进行折腾。为了加速上手新系统的速度而成此文，并初步构建了自己的dotfiles，目前能够在mac和linux上同步使用。谨以此文致敬在机器上折腾的青春~</p></blockquote><span id="more"></span><p>实验室师兄毕业，笔者接管服务器一台，开始了维护机器的脏乱累之旅。中间经历了</p><p>拆 <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/69266485.jpg" alt="69266485" /></p><p>拆</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/69305996.jpg" alt="" /><figcaption>69305996</figcaption></figure><p>以及出了问题蹲在一角研究到深夜的时刻...</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/69425003.jpg" alt="" /><figcaption>69425003</figcaption></figure><p>Anyway，对一个Unix爱好者来讲，这是痛并快乐着的。</p><h2 id="机器型号">机器型号</h2><p>笔者安装的第一台机器为戴尔Precision 7920塔式工作站，原本系统为windows，直接重装成Ubuntu18.04.04。第二台为一个组装机，两个2080Ti显卡，安装的系统和上一台一样。</p><h1 id="一必要配置">一、必要配置</h1><h2 id="远程桌面安装">1.1 远程桌面安装</h2><p>远程桌面安装其实不难，一个安装脚本就能搞定xrdp桌面的安装，笔者尝试了多种远程桌面的方式，虽然安装时挺折腾，但最后都成功了： - XRDP( ✨✨✨推荐) 我的<a href="https://blog.csdn.net/Qiang_brother/article/details/107497630">博客</a> ，开源<a href="https://c-nergy.be/blog/?p=14888">代码</a>，代码的<a href="https://c-nergy.be/blog/?p=14888">使用方法</a> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># go to http://www.c-nergy.be/products.html</span></span><br><span class="line">wget http://c-nergy.be/downloads/xRDP/xrdp-installer-1.2.zip</span><br><span class="line">unzip xrdp-installer-1.2.zip</span><br><span class="line">bash xrdp-installer-1.2.sh</span><br></pre></td></tr></table></figure></p><p>安装之后发现和原版的远程桌面一样，这是我比较喜欢的桌面，初用体验是太卡。</p><ul><li>No machine ( ✨✨推荐) 参考同上，这个方案还不错，但目前发现只能一个人连接（意思是需要氪金）。安装参考了<a href="%5Bhttps://blog.csdn.net/TaylorMei/article/details/107067216%5D(https://blog.csdn.net/TaylorMei/article/details/107067216)">这篇博客</a>，并且还要按<a href="%5Bhttps://www.jianshu.com/p/ba4a529c0c47%5D(https://www.jianshu.com/p/ba4a529c0c47)">这篇博客</a>来配置，方可正常使用。使用之余感慨Unix软件还是商业的做的漂亮...</li><li>VNC, 根据这个<a href="%5Bhttps://www.cnblogs.com/storyline/articles/11974392.html%5D(https://www.cnblogs.com/storyline/articles/11974392.html)">教程</a>装好了，个人感受使用体验一般般，遂再也没用过。</li><li>续：从<a href="%5Bhttps://github.com/zakurachan/xrdp-ubuntu/blob/master/src/xrdp.sh%5D(https://github.com/zakurachan/xrdp-ubuntu/blob/master/src/xrdp.sh)">github</a> 找到的脚本，仅供参考 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;=================================&quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot; Installing firefox / xrdp / etc &quot;</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;=================================&quot;</span></span><br><span class="line">sudo apt-get update -y </span><br><span class="line">sudo apt-get install -y xfce4 xfce4-goodies</span><br><span class="line">sudo apt-get install -y firefox</span><br><span class="line">sudo apt-get install -y xrdp</span><br><span class="line"><span class="built_in">echo</span> xfce4-session &gt;~/.xsession</span><br><span class="line">sudo service xrdp start</span><br></pre></td></tr></table></figure></li></ul><h2 id="相关镜像源配置">1.2 相关镜像源配置</h2><p>尽管下一条解决了这个问题，但是还是建议配好镜像源，毕竟快~ 笔者目前经常需要<code>apt</code>, <code>conda</code>, <code>pip</code>，docker等进行联网下载，因此镜像源是必须要配置的。源头可以使用<a href="%5Bhttps://mirror.tuna.tsinghua.edu.cn/help/ubuntu/%5D(https://mirror.tuna.tsinghua.edu.cn/help/ubuntu/)">清华源</a>，建议把配置操作自动化成脚本。</p><h2 id="命令行冲浪配置">1.3 命令行冲浪配置</h2><p>有些时候必须要科学地使用命令行，比如用<code>git</code>从github上克隆项目，否则一些配置安装要等个几天几夜。笔者不喜欢点击网页的下载按钮，毕竟，命令行下载那么方便！ <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注：提前装好了miniconda 的环境</span></span><br><span class="line"><span class="comment"># 1.前期配置</span></span><br><span class="line">pip install shadowsocks</span><br><span class="line">sudo apt install privoxy</span><br><span class="line">sed -i <span class="string">&quot;s|cleanup|reset|g&quot;</span> /usr/miniconda3/lib/python3.7/site-packages/shadowsocks/crypto/openssl.py <span class="comment"># openssl bug，换一下变量名就可以了</span></span><br><span class="line"><span class="comment"># 2.接着配置privoxy 略</span></span><br><span class="line">sudo systemctl start privoxy</span><br><span class="line"><span class="comment"># 3.启动</span></span><br><span class="line">sslocal -c ss.json  <span class="comment"># 配置文件</span></span><br><span class="line"><span class="built_in">export</span> http_proxy=127.0.0.1:1087</span><br><span class="line"><span class="built_in">export</span> https_proxy=127.0.0.1:1087</span><br><span class="line"><span class="comment"># done</span></span><br></pre></td></tr></table></figure></p><h2 id="网络配置">1.4 网络配置</h2><p>笔者最开始ip相关配置是直接在图形界面设置好的，因此没有使用命令行。图形界面配置一般不会有问题。中间笔者配第二台机器的时候，把子网掩码写错了，外界网站一直连不上，为此又折腾命令行的相关网络配置。查找资料的时候发现ubuntu管理网络的命令比较繁杂，ubuntu18.04.04使用的是<code>netplan</code>。 网络的配置写在<code>/etc/netplan/01-network-manager-all.yaml</code>这个文件。如果你想通过配置文件和命令行的方式来配置的话，可以编辑这个文件，初始内容如下</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/68060119.png" alt="" /><figcaption>68060119.png</figcaption></figure><p>renderer这一行表示你想通过图形界面配置网络，如果是的那么后面就不用写了。通过文件来管理网络，笔者从网上找到的一个例子如下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Let NetworkManager manage all devices on this system</span></span><br><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line">  <span class="comment"># renderer: NetworkManager</span></span><br><span class="line">  ethernets:</span><br><span class="line">          ens33:</span><br><span class="line">                  addresses: [192.168.0.111/24]</span><br><span class="line">                  gateway4: 192.168.0.1</span><br><span class="line">                  nameservers:</span><br><span class="line">                        addresses: [192.168.0.1]</span><br></pre></td></tr></table></figure><p>要注意yaml文件的同级缩进一致，以及和自己的网络各种配置保持一致。填错一个配置，可能会坑你一些时间！ ## 1.5 ssh安装 我装的ubuntu18.04没有ssh服务端，还需要安装，才能从外界ssh连入。运行下面两行，ssh可以直接用啦。<a href="https://www.cnblogs.com/linuxAndMcu/p/10766589.html">参考</a> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y openssh-client openssh-server</span><br><span class="line">sudo service ssh start</span><br></pre></td></tr></table></figure> ## 1.6 创建用户和组</p><p>管理用户和组是系统管理员最基本的要求</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">groupadd 组名 <span class="comment"># 新增组，只能是一个组，建多个用循环</span></span><br><span class="line">adduser 成员名 <span class="comment"># 新增成员</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 把成员加到组里去</span></span><br><span class="line">adduser 成员名 组名 <span class="comment"># 这个操作更简单</span></span><br><span class="line">usermod -a -G 组名 成员名 <span class="comment"># 等价</span></span><br><span class="line"><span class="comment"># 改变login shell为zsh</span></span><br><span class="line">chsh --shell /usr/bin/zsh qiangzibro</span><br><span class="line"></span><br><span class="line"><span class="comment"># 当然还可以在建用户时就把上两条做好</span></span><br><span class="line"><span class="comment"># 例：建用户名为小刚的用户，并把他加到专业团队和篮球队这两个队，-s指定shell为zsh，-m指定创建家目录</span></span><br><span class="line">useradd  -G 专业团队，篮球队 -m -s /bin/zsh 小刚</span><br></pre></td></tr></table></figure><ul><li>将所有用户添加到<code>deepones</code>组下 参考了一篇国外<a href="%5Bhttps://mike632t.wordpress.com/2013/10/13/adding-all-users-to-a-group/%5D(https://mike632t.wordpress.com/2013/10/13/adding-all-users-to-a-group/)">博客</a></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ID <span class="keyword">in</span> $(cat /etc/passwd | grep /home | cut -d <span class="string">&#x27;:&#x27;</span> -f1)</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    (sudo adduser <span class="variable">$ID</span> deepones);</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>直接用下面这种方式也很简单</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ID <span class="keyword">in</span>  `ls /home`; \</span><br><span class="line"><span class="keyword">do</span> (sudo adduser <span class="variable">$ID</span> deepones);<span class="keyword">done</span></span><br></pre></td></tr></table></figure><p>最后，笔者写了一个用来建用户和组的小<a href="https://github.com/QiangZiBro/Qdotfiles/blob/master/scripts/setup_users.sh">脚本</a>，只需要输入相关用户名、组名，就可以创建之并相关联。目前的情况是，实验室的成员放到一个组里，我给取的名字叫做deepones。为了使用docker，还需要将所有人放在docker组里，这样做解决了docker要用sudo的问题，也就是说，你不用sudo也能用docker命令了。当然，为了有管理员权限，还需要将所有人放在sudo组里。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="function"><span class="title">setup_groups</span></span>()&#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;🌝 Create user groups...&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> GROUPNAME <span class="keyword">in</span> docker deepones</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        getent group <span class="variable">$GROUPNAME</span> 2&gt;&amp;1 &gt;/dev/null &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;INFO: <span class="variable">$GROUPNAME</span> already exists&quot;</span>|| groupadd <span class="variable">$GROUPNAME</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="title">create_user</span></span>()&#123;</span><br><span class="line">    <span class="comment">#----------------------------------------------------------------------------------</span></span><br><span class="line">    <span class="comment"># 创建一个用户，并进行组设置、shell设置</span></span><br><span class="line">    <span class="comment">#----------------------------------------------------------------------------------</span></span><br><span class="line">    [ -z <span class="variable">$1</span> ] &amp;&amp; <span class="built_in">echo</span> <span class="string">&quot;No user name input and abort!&quot;</span> &amp;&amp; <span class="built_in">exit</span> 0</span><br><span class="line">    USERNAME=<span class="variable">$1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> [ -d <span class="string">&quot;/home/<span class="variable">$USERNAME</span>&quot;</span> ]</span><br><span class="line">    <span class="keyword">then</span></span><br><span class="line">        <span class="built_in">printf</span> <span class="string">&quot;INFO: User \&quot;<span class="variable">$USERNAME</span>\&quot; already exists\n&quot;</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="comment"># -G 该用户的其他组还应该属于的组，可以有多个</span></span><br><span class="line">        <span class="comment"># -m 创建用户的家目录</span></span><br><span class="line">        <span class="comment"># -s 该用户的登录shell</span></span><br><span class="line">        <span class="comment"># -p 该用户的密码</span></span><br><span class="line">        useradd  -G docker,deepones,sudo -m -s /bin/zsh <span class="variable">$USERNAME</span></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$USERNAME</span>:<span class="variable">$USERNAME</span>&quot;</span> | chpasswd</span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">create_users</span></span>() &#123;</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;🌝 Creating users...&quot;</span></span><br><span class="line">    <span class="keyword">for</span> user <span class="keyword">in</span> qiangzibro daxiongpro haochen</span><br><span class="line">    <span class="keyword">do</span></span><br><span class="line">        create_user <span class="variable">$user</span></span><br><span class="line">    <span class="keyword">done</span></span><br><span class="line">&#125;</span><br><span class="line">setup_groups</span><br><span class="line">create_users</span><br></pre></td></tr></table></figure><blockquote><h3 id="ubuntu显式地创建成员-useradd">Ubuntu显式地创建成员 useradd</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;useradd -rm -d /home/ubuntu -s /bin/bash -g root -G sudo -u 1001 ubuntu</span><br></pre></td></tr></table></figure><p><code>useradd</code> options (see: <code>man useradd</code>):</p><ul><li><code>-r</code>, <code>--system</code> Create a system account. see: <a href="https://unix.stackexchange.com/q/213101/21471">Implications creating <em>system accounts</em></a></li><li><code>-m</code>, <code>--create-home</code> Create the user's home directory.</li><li><code>-d</code>, <code>--home-dir HOME_DIR</code> Home directory of the new account.</li><li><code>-s</code>, <code>--shell SHELL</code> Login shell of the new account.</li><li><code>-g</code>, <code>--gid GROUP</code> Name or ID of the primary group.</li><li><code>-G</code>, <code>--groups GROUPS</code> List of supplementary groups.</li><li><code>-u</code>, <code>--uid UID</code> Specify user ID. see: <a href="https://medium.com/@mccode/understanding-how-uid-and-gid-work-in-docker-containers-c37a01d01cf">Understanding how uid and gid work in Docker containers</a></li></ul></blockquote><h2 id="硬盘自动加载">1.7 硬盘自动加载</h2><h4 id="新硬盘分区">新硬盘分区</h4><p>实验室新买了两块2TB硬盘，放进机器后进行了分区、创建文件系统、开机自启设置操作，才能够进行使用。ubuntu的<a href="https://help.ubuntu.com/community/InstallingANewHardDrive">官方文档</a>是个不错的参考。</p><p>首先使用下面命令查看硬盘以及分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fdisk -l</span><br><span class="line">lsblk <span class="comment"># 也可</span></span><br></pre></td></tr></table></figure><p>比如我们找到了这个硬盘叫<code>/dev/sdc</code>，那么首先对其分区</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fdisk /dev/sdc <span class="comment"># 对2TB硬盘进行分区，sd后面具体实际根据fdisk -l来看</span></span><br></pre></td></tr></table></figure><p>再进行格式化</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mkfs.ext4 /dev/sdc</span><br><span class="line"><span class="comment"># 格式化时可以指定磁盘的block size和Inode size</span></span><br><span class="line">mkfs.ext4 -b 4096 -I 256</span><br><span class="line"></span><br><span class="line"><span class="comment"># 【存疑】不使用这个会报错</span></span><br><span class="line">partprobe /dev/sdc </span><br></pre></td></tr></table></figure><h4 id="手动挂载硬盘">手动挂载硬盘</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /mnt/2TB <span class="comment"># 创建挂载点</span></span><br><span class="line">mount /dev/sdb /mnt/2TB <span class="comment"># 挂载</span></span><br></pre></td></tr></table></figure><h4 id="开机时自动挂载硬盘">开机时自动挂载硬盘</h4><p>打开<code>/etc/fstab</code>，对要开机自动加载的硬盘设置如下的格式</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/70558222.png" alt="" /><figcaption>70558222.png</figcaption></figure><h4 id="做软链接可选">做软链接（可选）</h4><p>我希望在每个硬盘下都建立了以用户为名字的文件，并建立了软链接到所有用户家目录。这样每个用户的家目录下面都可以看到对应硬盘的文件夹，同时又不会公用一个文件夹。像这样：</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/54072768.png" alt="" /><figcaption>54072768.png</figcaption></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> hardware <span class="keyword">in</span> `realpath *TB*`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">        hardware_name=`basename <span class="variable">$hardware</span>`</span><br><span class="line">        <span class="keyword">for</span> user <span class="keyword">in</span> `ls /home`</span><br><span class="line">        <span class="keyword">do</span></span><br><span class="line">                dir=<span class="string">&quot;<span class="variable">$hardware</span>&quot;</span>/<span class="string">&quot;<span class="variable">$user</span>&quot;</span></span><br><span class="line">                linkdir=/home/<span class="string">&quot;<span class="variable">$user</span>&quot;</span>/<span class="string">&quot;<span class="variable">$hardware_name</span>&quot;</span></span><br><span class="line"></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$dir</span> --&gt; <span class="variable">$linkdir</span>&quot;</span></span><br><span class="line">                mkdir -p <span class="variable">$dir</span></span><br><span class="line">                ln -s <span class="variable">$dir</span> <span class="variable">$linkdir</span></span><br><span class="line">                </span><br><span class="line">                chown -R <span class="string">&quot;<span class="variable">$user</span>&quot;</span>:deepones   <span class="variable">$dir</span></span><br><span class="line">                chown -R <span class="string">&quot;<span class="variable">$user</span>&quot;</span>:deepones -h <span class="variable">$linkdir</span></span><br><span class="line">        <span class="keyword">done</span></span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure><h4 id="遇到的问题">遇到的问题</h4><p>发现2TB的硬盘<code>/dev/sda1</code>被挂载了<code>/boot/efi</code>上，导致的情况就是这个硬盘暂时不能被格式化，也不能被直接挂载和使用了。</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20200925105809886.png" alt="" /><figcaption>image-20200925105809886</figcaption></figure><p>而我之前装的系统，根目录和efi都是挂载在固态硬盘里的，这里面<code>/dev/sda</code>是固态硬盘</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20200925105928294.png" alt="" /><figcaption>image-20200925105928294</figcaption></figure><p>【怎么解决？】要想使用这个硬盘，必须要解除掉<code>/boot/efi</code>的占用，把它挂载到另外一个地方</p><h1 id="二软件安装">二、软件安装</h1><h2 id="dotfiles的哲学">2.0 dotfiles的哲学</h2><p>一台空机器往往需要一些必备的工具，干活起来才会更“<strong>舒服</strong>”。不同人喜欢不同的软件，不同的配置。笔者也有自己的一套习惯，比如命令行终端的ohmyzsh，编辑文件使用neovim再加上自己的vimrc等等。而在新机器手动安装不同的软件、配置往往会花掉我们很多功夫。想要加速这个过程，可以编写自己的安装脚本，又或者使用容器技术，使得在任何环境下都有同样的配置。在知乎大神<a href="%5Bhttps://www.zhihu.com/people/skywind3000%5D(https://www.zhihu.com/people/skywind3000/columns)">韦易笑</a>的文章下，我建立自己的<a href="%5Bhttps://github.com/QiangZiBro/Qdotfiles%5D(https://github.com/QiangZiBro/Qdotfiles)">Qdotfiles</a>，并自动化了配置和安装的过程，只需下面一个命令： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/QiangZiBro/Qdotfiles/master/scripts/bootstrap.sh)</span>&quot;</span></span><br></pre></td></tr></table></figure> 并写了一个Dockerfile，让我的配置在容器里也能测试成功，这个过程中联系了一波docker的使用。要注意的是，Qdotfiles还处于个人维护阶段，直接拿到自己的系统使用也许仍然会有一些问题，但是可以使用容器，进行一些小的尝试。 下面常见的安装，都会总结到<a href="%5Bhttps://github.com/QiangZiBro/Qdotfiles%5D(https://github.com/QiangZiBro/Qdotfiles)">Qdotfile</a>项目里。</p><h2 id="zsh">2.1 zsh</h2><h3 id="oh-my-zsh">oh my zsh</h3><p>以前一直想装一次ohmyzsh，所有用户使用，后来读了<a href="%5Bhttps://stackoverflow.com/questions/43026839/how-do-i-set-the-default-zshrc-oh-my-zsh-for-users%5D(https://stackoverflow.com/questions/43026839/how-do-i-set-the-default-zshrc-oh-my-zsh-for-users)">这条</a>建议后，发现没有必要。ohmyzsh是一套配置，它的核心还是zsh，每个用户各安装各自的配置即可。安装方式： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh -c <span class="string">&quot;<span class="subst">$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>&quot;</span></span><br></pre></td></tr></table></figure></p><p>上面一条安装完了，想改变用户的登录shell为zsh，使用</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo  chsh <span class="variable">$USER</span> -s $(<span class="built_in">which</span> zsh)</span><br></pre></td></tr></table></figure><h3 id="插件管理">插件管理</h3><p>使用zplug，官方给的安装命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -sL --proto-redir -all,https https://raw.githubusercontent.com/zplug/installer/master/installer.zsh | zsh</span><br></pre></td></tr></table></figure><p>将类似于下面的语句放在<code>~/.zshrc</code>里面，我用的插件有</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">zplug <span class="string">&#x27;plugins/git&#x27;</span>, from:oh-my-zsh, <span class="keyword">if</span>:<span class="string">&#x27;which git&#x27;</span></span><br><span class="line">zplug romkatv/powerlevel10k, as:theme, depth:1</span><br><span class="line"><span class="comment"># zplug &quot;plugins/vi-mode&quot;, from:oh-my-zsh</span></span><br><span class="line">zplug <span class="string">&#x27;zsh-users/zsh-autosuggestions&#x27;</span></span><br><span class="line">zplug <span class="string">&#x27;zsh-users/zsh-completions&#x27;</span>, defer:2</span><br><span class="line">zplug <span class="string">&#x27;zsh-users/zsh-history-substring-search&#x27;</span></span><br><span class="line">zplug <span class="string">&#x27;zsh-users/zsh-syntax-highlighting&#x27;</span>, defer:2</span><br></pre></td></tr></table></figure><h2 id="替换你的cd命令-z.lua">2.2 替换你的cd命令 z.lua</h2><p>从skywind3000大佬那里安利的工具</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/skywind3000/z.lua /usr/softwares/z.lua</span><br><span class="line">sudo apt install -y lua5.3</span><br><span class="line">sudo ln -s /usr/bin/lua5.3 /usr/bin/lua</span><br><span class="line"><span class="comment">#接着在.zshrc添加</span></span><br><span class="line"><span class="built_in">eval</span> <span class="string">&quot;<span class="subst">$(lua5.3 /usr/softwares/z.lua/z.lua --init zsh)</span>&quot;</span></span><br></pre></td></tr></table></figure><blockquote><p>Note：笔者后来用了zsh-autosuggestions插件后，发现用z的机会也少了。不过各有千秋，目录跳转比刀耕火种的cd好多了，哈哈！</p></blockquote><h2 id="miniconda">2.3 miniconda</h2><p>安装脚本来自<a href="https://github.com/QiangZiBro/Qdotfiles/blob/b98304139a4e26cf8276ce3d60dc7fb138f08bcb/conda/install.sh#L23-L33">我的dotfiles</a>，我将miniconda直接安装在了<code>/usr</code>文件夹，其实安装在<code>/usr/softwares</code>下更好，不过无伤大雅 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda_linux=~/.Qdotfiles/downloads/miniconda3_linux.sh</span><br><span class="line">wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O <span class="variable">$conda_linux</span></span><br><span class="line">sudo bash <span class="variable">$conda_linux</span> -p /usr/miniconda3 -b -u</span><br></pre></td></tr></table></figure> - conda安装后，将各个常见的pytorch版本创建了一遍 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> &#123;12..17&#125;</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    conda create -n torch<span class="variable">$i</span> python=3.7 -y</span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure> 再从<a href="%5Bhttps://pytorch.org/get-started/locally/%5D(https://pytorch.org/get-started/locally/)">官网</a>下载对应的包。 - 使用Tips 为每一个项目单独创一个环境，不同环境不要混用。比如自己项目需要torch12版本，以及其他依赖包，可以首先克隆torch12这个环境： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda create -n 项目名称 --<span class="built_in">clone</span> torch12</span><br></pre></td></tr></table></figure> 激活环境并在这个环境下进行构建： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate  项目名称</span><br><span class="line">conda install ...</span><br><span class="line">pip install ...</span><br></pre></td></tr></table></figure> ## 2.4 nvim 我写的安装<a href="https://github.com/QiangZiBro/Qdotfiles/blob/b98304139a4e26cf8276ce3d60dc7fb138f08bcb/neovim/install.sh#L3-L22">脚本</a>，包括了 - 下载 - 安装 - 插件配置</p><p>等操作。更多常用软件安装，会总结在自己的dotfiles里。</p><h2 id="cuda驱动安装">2.5 CUDA驱动安装</h2><p>查看GPU版本 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  ~ lspci | grep -i nvidia</span><br><span class="line">3b:00.0 VGA compatible controller: NVIDIA Corporation GP100GL [Quadro GP100] (rev a1)</span><br><span class="line">3b:00.1 Audio device: NVIDIA Corporation Device 0fb1 (rev a1)</span><br></pre></td></tr></table></figure> ### 2.5.1 成功安装方式</p><ul><li><p>第一步：安装必备软件，官方推荐的库 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y g++ freeglut3-dev build-essential libx11-dev libxmu-dev libxi-dev libglu1-mesa libglu1-mesa-dev</span><br></pre></td></tr></table></figure></p></li><li><p>第二步：<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#runfile-nouveau">禁用nouveau</a>，这是官方文档的步骤，并且还要重启。连在一起我写了如下脚本，可以直接运行 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1</span></span><br><span class="line">cat &lt;&lt; <span class="string">EOF &gt;&gt;/etc/modprobe.d/blacklist-nouveau.conf</span></span><br><span class="line"><span class="string">blacklist nouveau</span></span><br><span class="line"><span class="string">options nouveau modeset=0</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"><span class="comment"># 2</span></span><br><span class="line">update-initramfs -u</span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line">reboot</span><br></pre></td></tr></table></figure></p></li><li><p>第三步：在BIOS里<strong>禁用secure boot</strong></p></li><li><p>第四步【2080Ti版本】：在<a href="https://developer.nvidia.com/cuda-downloads">官网下载地址</a><strong>下载cuda驱动</strong></p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20200924184743807.png" alt="" /><figcaption>image-20200924184743807</figcaption></figure></li></ul><p>在上面选好对应的选项，bash命令给你的安装方式了。文件有3G多，开了命令行代理还下了一个小时</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run</span><br><span class="line">sudo sh cuda_11.1.0_455.23.05_linux.run</span><br></pre></td></tr></table></figure><p>安装就是一路accept之后就装好了</p><figure><img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/image-20200924213610919.png" alt="" /><figcaption>image-20200924213610919</figcaption></figure><blockquote><p>太长不看版：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#/etc/profile添加</span></span><br><span class="line"><span class="built_in">export</span> PATH=/usr/<span class="built_in">local</span>/cuda-11.1/bin<span class="variable">$&#123;PATH:+:<span class="variable">$&#123;PATH&#125;</span>&#125;</span></span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=/usr/<span class="built_in">local</span>/cuda-11.1/lib64<span class="variable">$&#123;LD_LIBRARY_PATH:+:<span class="variable">$&#123;LD_LIBRARY_PATH&#125;</span>&#125;</span></span><br></pre></td></tr></table></figure><p>分析下提示：</p><ol type="1"><li>官方推荐的库还有没装，需要装参考第一步。安装cuda驱动后他们在当前目录放了一些cuda代码样例，这些例子应该是依赖这些库</li><li>PATH需要包含<code>/usr/local/cuda-11.1/bin</code>这个路径，这个好办，在<code>/etc/profile</code>里面写入<code>export PATH=/usr/local/cuda-11.1/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;</code>，就明明白白安排了环境变量</li><li><code>LD_LIBRARY_PATH</code>这个变量要包含<code>/usr/local/cuda-11.1/lib64</code>路径，解决的方式上面也给了，那我们也是一样写export语句：<code>export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64$&#123;LD_LIBRARY_PATH:+:$&#123;LD_LIBRARY_PATH&#125;&#125;</code></li><li>配置好环境变量后，你可以打印出来看看对不对：</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="variable">$LD_LIBRARY_PATH</span></span><br><span class="line"><span class="comment">#/usr/local/cuda-11.1/lib64</span></span><br><span class="line"><span class="built_in">echo</span> <span class="variable">$PATH</span></span><br><span class="line"><span class="comment">#/usr/local/cuda-11.1/bin:/usr/miniconda3/bin:/usr/miniconda3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games</span></span><br></pre></td></tr></table></figure><ol start="5" type="1"><li>还可以用<code>nvidia-smi</code>检查一下GPU状态，如果正常运行，那就基本没问题了。</li></ol></blockquote><h3 id="失败安装方式">2.5.2 失败安装方式</h3><p>留个纪念吧，致敬我在上面浪费掉的时间</p><p><font color=red>失败原因：没有下载对正确的驱动，参考上面的链接进行下载</font></p><p><font color=red>流程复现</font>：直接进入英伟达官网，就开始选择驱动进行安装。看了<a href="%5Bhttps://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#abstract%5D(https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#abstract)">官方安装步骤文档</a>，我采用runfile安装的方式，<font color=red>盲目地下载了</font><a href="%5Bhttps://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=runfilelocal%5D(https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;target_distro=Ubuntu&amp;target_version=1804&amp;target_type=runfilelocal)">官网首页给的安装包</a> ，这个文件有2G多，下载到了<code>/usr/softwares/downloads/</code>下，照着官方文档的步骤安装，没有成功。 <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/69996576.png" alt="69996576.png" /> 报错： <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/70067327.png" alt="70067327.png" /> 打开这个日志文件 <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/70101642.png" alt="70101642.png" /> 注意到官网说GP100支持cuda10.2，我装的是cuda11.0 <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/71404346.png" alt="71404346.png" /> 再去装10.2，仍以失败告终。</p><h3 id="报错">2.5.3 报错</h3><h4 id="错误1">错误1</h4><p>每次意外断电都会遇到的情况，头大！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NVIDIA-SMI has failed because it couldn&#x27;t communicate with the NVIDIA driver. </span><br><span class="line">Make sure that the latest NVIDIA driver is installed and running.</span><br></pre></td></tr></table></figure><p><a href="https://zhuanlan.zhihu.com/p/89714824">解决方案</a></p><ul><li>第一步：首先看nvidia驱动具体版本号</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ls /usr/src | grep nvidia</span><br><span class="line"><span class="comment"># 我的是nvidia-455.23.05</span></span><br></pre></td></tr></table></figure><ul><li>第二步：用 <code>nvcc -V</code> 看了一下驱动还在，用下面的方法应该顺利解决问题</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install dkms</span><br><span class="line">sudo dkms install -m nvidia -v 455.23.05</span><br></pre></td></tr></table></figure><p>因为这个方法就已经解决问题了，所以更多的没探索下去了。</p><blockquote><p>我写了一个脚本直接联动了查询和配置（可能有问题，仅供参考）</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo dkms install -m nvidia -v `ls /usr/src | grep nvidia | sed <span class="string">&#x27;s|nvidia-||&#x27;</span>`</span><br></pre></td></tr></table></figure></blockquote><h4 id="错误2">错误2</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to initialize NVML: Driver/library version mismatch</span><br></pre></td></tr></table></figure><p><u>解决方案</u></p><ol type="1"><li>首先看显卡驱动版本</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat /proc/driver/nvidia/version</span><br></pre></td></tr></table></figure><p>我的是450</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">NVRM version: NVIDIA UNIX x86_64 Kernel Module  450.102.04  Tue Dec 29 06:51:23 UTC 2020</span><br><span class="line">GCC version:  gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)</span><br></pre></td></tr></table></figure><p>那么安装：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install nvidia-driver-450</span><br></pre></td></tr></table></figure><p>接下来又报<strong>错误1</strong>，那么按照<strong>错误1</strong>的解决方式做，就成功了。</p><h4 id="错误3">错误3</h4><p>3080Ti的错误</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Unable to determine the device handle for GPU 0000:03:00.0: GPU is lost.  Reboot the system to recover this GPU</span><br></pre></td></tr></table></figure><h2 id="cudnn安装">2.6 cudnn安装</h2><p>在官网https://developer.nvidia.com/cudnn注册账号并下载，我直接使用Google账号登录。选择下载cuDNN Library for Linux</p><p>可以看到，对于不同的CUDA，历史有一堆cudnn</p><figure><img src="imgs/ubuntu_install_imgs/image-20200929024402667.png" alt="" /><figcaption>image-20200929024402667</figcaption></figure><p>我选了第一个的cuDNN Library for Linux (x86_64)，直接wget就可以</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1 下载</span></span><br><span class="line"><span class="comment"># 2 解压</span></span><br><span class="line">tar xvzf 你的下载包</span><br><span class="line"><span class="comment"># 3. 复制</span></span><br><span class="line">sudo cp cuda/include/* /usr/<span class="built_in">local</span>/cuda-11.1/include</span><br><span class="line">sudo cp cuda/lib64/* /usr/<span class="built_in">local</span>/cuda-11.1/lib64</span><br></pre></td></tr></table></figure><h2 id="tmux-配置">2.7 tmux 配置</h2><p>tmux是一个优秀的终端复用软件，如果您经常使用终端，建议马上使用它！相信我你不会后悔。 - 首先安装 <code>sudo apt install tmux -y</code> - 安装好了就可以使用了，但为了更美（装）观（x）怎能止步于此！下载插件管理器 <code>git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm</code> - 在配置文件<code>~/.tmux.conf</code>里写上你需要的插件，笔者使用了onedark主题，目前觉得还不错。 笔者目前的配置文件<a href="https://github.com/QiangZiBro/Qdotfiles/blob/master/tmux/.tmux.conf">内容</a> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Open in same directory</span></span><br><span class="line"><span class="built_in">bind</span> c new-window -c <span class="string">&quot;#&#123;pane_current_path&#125;&quot;</span></span><br><span class="line"><span class="built_in">bind</span> <span class="string">&#x27;&quot;&#x27;</span> split-window -c <span class="string">&quot;#&#123;pane_current_path&#125;&quot;</span></span><br><span class="line"><span class="built_in">bind</span> % split-window -h -c <span class="string">&quot;#&#123;pane_current_path&#125;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># List of plugins</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">&#x27;tmux-plugins/tpm&#x27;</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">&#x27;tmux-plugins/tmux-sensible&#x27;</span></span><br><span class="line"><span class="built_in">set</span> -g @plugin <span class="string">&#x27;odedlaz/tmux-onedark-theme&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Other examples:</span></span><br><span class="line"><span class="comment"># set -g @plugin &#x27;github_username/plugin_name&#x27;</span></span><br><span class="line"><span class="comment"># set -g @plugin &#x27;git@github.com:user/plugin&#x27;</span></span><br><span class="line"><span class="comment"># set -g @plugin &#x27;git@bitbucket.com:user/plugin&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize TMUX plugin manager (keep this line at the very bottom of tmux.conf)</span></span><br><span class="line">run <span class="string">&#x27;~/.tmux/plugins/tpm/tpm&#x27;</span></span><br></pre></td></tr></table></figure> - <code>tmux source ~/.tmux.conf</code>让配置生效 - 生效后，还不能立即看到效果，这是因为没下载插件，只需要打开tmux，然后<code>&lt;prefix&gt; I</code>就可以安装插件。<code>&lt;prefix&gt;</code>是tmux的前缀键，默认是<code>Ctrl+B</code> 其他命令： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;prefix&gt; U 更新所有已安装插件</span><br><span class="line">&lt;prefix&gt; Alt U 移除所有插件列表中不存在的插件</span><br></pre></td></tr></table></figure></p><h2 id="显卡驱动安装">2.8 显卡驱动安装</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. https://www.nvidia.cn/Download/index.aspx?lang=cn 找到bin文件安装包</span></span><br><span class="line"><span class="comment"># 2. disable the graphical target, which is what keeps the display manager running:</span></span><br><span class="line">systemctl isolate multi-user.target</span><br><span class="line"><span class="comment"># 3. unload the Nvidia drivers </span></span><br><span class="line">modprobe -r nvidia-drm</span><br><span class="line"><span class="comment"># 4. 运行可执行文件，注意参数</span></span><br><span class="line">./NVIDIA-Linux-x86_64-450.80.02.run --no-cc-version-check</span><br></pre></td></tr></table></figure><h1 id="三-docker服务部署">三 docker服务部署</h1><p>服务器配好了，配置一些服务供日常使用，下面是经常用的几个： ## 3.1 gitlab 参考韦大佬的<a href="%5Bhttps://zhuanlan.zhihu.com/p/49499229%5D(https://zhuanlan.zhihu.com/p/49499229)">文章</a>，真的只要半分钟！ ### 搭建 搭建一个gitlab其实非常简单，只需要半分钟，前提是用对合适的工具, 这个工具就是docker，参考搭建<a href="%5Bhttps://zhuanlan.zhihu.com/p/49499229%5D(https://zhuanlan.zhihu.com/p/49499229)">教程</a>。作为管理员，搭建好之后直接<code>docker-compose up -d</code>就可以舒舒服服放在后台运行了。</p><h3 id="使用">使用</h3><ol type="1"><li>首先注册一个账号 <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/47921521.png" alt="47921521.png" /> 接着登录就ok</li><li>免密使用 使用https和ssh连接都可以，笔者使用的是https方式，进行下面的配置可以免得每次push都要输用户名和密码。在mac和Linux的<code>~/.git-credentials</code>里写入账号密码 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ~/.git-credentials</span></span><br><span class="line">https://你的名字:你的密码@你的ip地址:8443   </span><br></pre></td></tr></table></figure> 让配置生效，不然会发现还是要输密码。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global credential.helper store</span><br></pre></td></tr></table></figure> 3.屏蔽自签证书的验证，不然会报http错误<code>git SSL certificate problem</code>。</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.sslVerify <span class="string">&quot;false&quot;</span></span><br></pre></td></tr></table></figure><h2 id="overleaf">3.2 overleaf</h2><p>参考<a href="https://zhuanlan.zhihu.com/p/150827584">知乎文章</a>。 &gt;Overleaf是开源的在线Latex编辑器软件，个人用户可以在Overleaf官网注册并免费使用Overleaf，Overleaf官网还具有Review等团队协作功能。但是Overleaf官网在国内的访问速度不佳，科学上网后速度才满足日常需求。因此，对于科研团队来说，在自己的服务器上部署Overleaf，从此为整个团队都省去了安装Latex各种包的繁琐，多么幸福的事。需要说明的事，目前开源的个人版本的Overleaf功能没有Overleaf官网齐全，也许还有些小bug，但是就目前的使用来说，足够日常使用了。</p><p>我对docker compose文件改了两个地方，一个是映射端口，另一个是挂载目录： <img src="https://gitee.com/qiangzibro/uPic/raw/master/uPic/72125117.png" alt="72125117.png" /></p><h1 id="四-后话">四 后话</h1><p>建议每位学习计算机的小伙伴都学习一下linux，因为了解之后，对许多方向（比如做深度学习、后端开发等等）同学的工作非常方便。你可以不用纠结开发系统和娱乐系统之间的定夺，linux系统就用来做开发好了，两者兼得mac了解一下​?:smile:</p><h1 id="五-参考与问题">五 参考与问题</h1><h2 id="应该把软件装在哪个地方">应该把软件装在哪个地方？</h2><p>参考了<a href="https://askubuntu.com/questions/6897/where-to-install-programs">这篇文章</a>，了解到一般情况下，我们知道的软件，可以联系管理员装在/usr/local或者 /opt/。我现在选用的方式是，把软件装在<code>/usr/softwares</code>，然后给这个文件夹赋给一个组，组员都能访问到。</p><hr /><p><strong>再更</strong></p><p>阮一峰写过一篇刨根问底的<a href="http://www.ruanyifeng.com/blog/2012/02/a_history_of_unix_directory_structure.html">文章</a>，讲解了linux里面目录结构的来历，有兴趣可以看看。总结下来是</p><blockquote><p>　　<strong>/</strong>：存放系统程序，也就是At&amp;t开发的Unix程序。</p><p>　　<strong>/usr</strong>：存放Unix系统商（比如IBM和HP）开发的程序。</p><p>　　<strong>/usr/local</strong>：存放用户自己安装的程序。</p><p>　　<strong>/opt</strong>：在某些系统，用于存放第三方厂商开发的程序，所以取名为option，意为"选装"。</p></blockquote><ul><li><p>新用户创建 <a href="https://www.tecmint.com/manage-users-and-groups-in-linux/">https://www.tecmint.com/manage-users-and-groups-in-linux/</a></p></li><li><p>共享文件夹的创建 <a href="https://www.tecmint.com/create-a-shared-directory-in-linux/">https://www.tecmint.com/create-a-shared-directory-in-linux/</a></p></li><li><p>戴尔工作站（Precision 7920）安装双系统win10+ubuntu18.04 <a href="https://blog.csdn.net/jcsm__/article/details/105937544">https://blog.csdn.net/jcsm__/article/details/105937544</a></p></li><li><p>Linux有哪些命令行神器值得使用？ <a href="https://mp.weixin.qq.com/s/Mn5Vlftwm_mSt3RY-rI8dw">https://mp.weixin.qq.com/s/Mn5Vlftwm_mSt3RY-rI8dw</a></p></li><li><p>ubuntu18.04 安装NVIDIA显卡驱动与 cuda10 环境https://blog.csdn.net/qq997843911/article/details/85039021</p></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;零前言&quot;&gt;零、前言&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;本文总结了在Ubuntu上的深度学习环境配置方法，大部分可类比到其他机型、系统上。尽管笔者装过不少系统，但鲜有总结方法经验。之前即没有形成一个体系成笔记记录下来，也没有形成自己的dotfiles使得能方便地移植到其他环境中。这造成的结果就是，每次换系统都要花大量时间进行折腾。为了加速上手新系统的速度而成此文，并初步构建了自己的dotfiles，目前能够在mac和linux上同步使用。谨以此文致敬在机器上折腾的青春~&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    
    <category term="Linux" scheme="https://qiangzibro.com/tags/Linux/"/>
    
  </entry>
  
</feed>
